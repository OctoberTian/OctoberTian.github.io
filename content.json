{"meta":{"title":"October Blog","subtitle":"十月博客","description":"","author":"October","url":"http://www.octber.xyz","root":"/"},"pages":[{"title":"2019.8","date":"2019-08-28T12:55:53.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"diary/2019-8.html","permalink":"http://www.octber.xyz/diary/2019-8.html","excerpt":"","text":"2019.8.28{ “date”: “2019.8.28”, “title”: “人生弱点”, “content”: “行百里者半九十，学之不深，浅尝辄止，终不能成大事。“}， { “date”: “2019.8.28”, “title”: “无题”, “content”: “这是最好的时代,这是最差的时代,我们一无所有,我们巍然矗立“}"},{"title":"关于 十月Oct 的个人博客","date":"2019-05-20T14:29:15.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"about/index.html","permalink":"http://www.octber.xyz/about/index.html","excerpt":"","text":"关于 我为什么写博客？ 我一直都有写日记的习惯，喜欢把每天遇到的事情记下来，也喜欢思考，曾经也写过很多日记，然而现在回想起来，这些日记除了纸质版的可能还在，电子版的应该都丢的差不多了。于是我买了自己的学生服务器，搭建了wordpress，很多主题，很好看。 作为一个程序员，也写了很多技术博客，虽然被百度收录了四十几篇，但是貌似百度直接查是查不到的，我的权重太低？？还是怎么回事。只能通过百度搜索“site:blog.octber.xyz”来查到，当然没有人会这么查一篇博文，自然也就成了我个人的博客了，没有人看，也没有人评论。 wordpress有很大的缺点 是什么让我慢慢讨厌wordpress，是因为我在写博文的时候，图片插入不方便，我不能通过复制粘贴进文章这样方便，而且上传的图片会压缩成小分辨率，导致我的文章的图片不仅不美观，还费时间。 最关键的是，我懒得备份，备份不仅仅要导出文章，还要备份数据库。也正是因为这样，我的windows被多次木马攻击后，mysql服务不能启动，当然被攻击的根本原因还是因为我当时采用的是windows的服务器，本来就容易收到攻击，邮件每天收到受到攻击的信息，我烦了。 Hexo确实值得一用 作为一个程序员，有自己的技术博客很重要，尤其是对开源社区做出贡献，于是我注意到Hexo+Github Pages的方式，刚开始只是因为对Github Pages感兴趣而入手，最后发现Hexo最吸引人的是它采用静态页面部署会带来不需要数据库服务，不需要后台服务，所以就不需要备份，所有的文章通过Markdown书写，就在自己电脑本地，只要你不删，电脑不丢，怎么都不会丢的吧。 由于Github Pages确实有点点慢，我选择了Coding Pages，后来觉得还是不好， 继续部署到自己的服务器上，将301转发到https，认证了百度站长的https站点，也算有了一个较为专业的选择。 没人看就自己写 博文本来就是写给自己看的，并不需要别人的点赞评论作为动力，能够帮助到别人确实很高兴，不过提升自我才是最重要的，很多知识和坑，往往只有自己亲身经历的时候才能知道，而且极其容易遗忘，很多东西每次做都要Google或者Baidu一下，这就显得非常难受。写在自己的博客里，写的过程整理思路，记得牢固，万一忘了，找自己的东西就显得理直气壮。 关于拿来主义 作为学生党（我是2016年入学，2020年大学毕业），拿来主义确实多一点，大多数地方还是会标注来源，如果确实有侵犯产权的地方，还请发邮件给我925474088@qq.com，其实我自己原创还是很多的，值得一看。 记录生活，同时提升自我编程修养 这就是我的目的，仅此而已。"}],"posts":[{"title":"深入理解JVM-学习与实践（1）","slug":"深入理解JVM-学习与实践（1）","date":"2020-03-04T15:05:27.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2020/03/04/深入理解JVM-学习与实践（1）/","link":"","permalink":"http://www.octber.xyz/2020/03/04/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%881%EF%BC%89/","excerpt":"前言《深入理解JVM虚拟机-JVM高级特性与最佳实践（周志明）第三版》是我一直都想钻研的一本书，作为一个Java后端开发路线的程序员，这些基础是有必要打好的，目前我还处于学习阶段，作为一名在校大学生，将来发展的路途还很遥远。 将这本书提上日程，也作为督促自己学习的一个重要节点，希望自己能坚持下去。","text":"前言《深入理解JVM虚拟机-JVM高级特性与最佳实践（周志明）第三版》是我一直都想钻研的一本书，作为一个Java后端开发路线的程序员，这些基础是有必要打好的，目前我还处于学习阶段，作为一名在校大学生，将来发展的路途还很遥远。 将这本书提上日程，也作为督促自己学习的一个重要节点，希望自己能坚持下去。 书籍标识 深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）周志明 著 ISBN：978-7-111-64124-7本书纸版由机械工业出版社于2019年出版，电子版由华章分社（北京华章图文信息有限公司，北京奥维博世图书发行有限公司）全球范围内制作与发行。 声明 我日后本系列内容基于本教材，如有侵权，请联系我删除。 目录 前言致谢 第一部分 走近Java 第1章 走近Java1.1 概述1.2 Java技术体系1.3 Java发展史1.4 Java虚拟机家族1.4.1 虚拟机始祖：Sun Classic/Exact VM1.4.2 武林盟主：HotSpot VM1.4.3 小家碧玉：Mobile/Embedded VM1.4.4 天下第二：BEA JRockit/IBM J9 VM1.4.5 软硬合璧：BEA Liquid VM/Azul VM1.4.6 挑战者：Apache Harmony/Google Android DalvikVM1.4.7 没有成功，但并非失败：Microsoft JVM及其他1.4.8 百家争鸣1.5 展望Java技术的未来1.5.1 无语言倾向1.5.2 新一代即时编译器1.5.3 向Native迈进1.5.4 灵活的胖子1.5.5 语言语法持续增强1.6 实战：自己编译JDK1.6.1 获取源码1.6.2 系统需求1.6.3 构建编译环境1.6.4 进行编译1.6.5 在IDE工具中进行源码调试1.7 本章小结第二部分 自动内存管理第2章 Java内存区域与内存溢出异常2.1 概述2.2 运行时数据区域2.2.1 程序计数器2.2.2 Java虚拟机栈2.2.3 本地方法栈2.2.4 Java堆2.2.5 方法区2.2.6 运行时常量池2.2.7 直接内存2.3 HotSpot虚拟机对象探秘2.3.1 对象的创建2.3.2 对象的内存布局2.3.3 对象的访问定位2.4 实战：OutOfMemoryError异常2.4.1 Java堆溢出2.4.2 虚拟机栈和本地方法栈溢出2.4.3 方法区和运行时常量池溢出2.4.4 本机直接内存溢出2.5 本章小结第3章 垃圾收集器与内存分配策略3.1 概述3.2 对象已死？3.2.1 引用计数算法3.2.2 可达性分析算法3.2.3 再谈引用3.2.4 生存还是死亡？3.2.5 回收方法区3.3 垃圾收集算法3.3.1 分代收集理论3.3.2 标记-清除算法3.3.3 标记-复制算法3.3.4 标记-整理算法3.4 HotSpot的算法细节实现3.4.1 根节点枚举3.4.2 安全点3.4.3 安全区域3.4.4 记忆集与卡表3.4.5 写屏障3.4.6 并发的可达性分析3.5 经典垃圾收集器3.5.1 Serial收集器3.5.2 ParNew收集器3.5.3 Parallel Scavenge收集器3.5.4 Serial Old收集器3.5.5 Parallel Old收集器3.5.6 CMS收集器3.5.7 Garbage First收集器3.6 低延迟垃圾收集器3.6.1 Shenandoah收集器3.6.2 ZGC收集器3.7 选择合适的垃圾收集器3.7.1 Epsilon收集器3.7.2 收集器的权衡3.7.3 虚拟机及垃圾收集器日志3.7.4 垃圾收集器参数总结3.8 实战：内存分配与回收策略3.8.1 对象优先在Eden分配3.8.2 大对象直接进入老年代3.8.3 长期存活的对象将进入老年代3.8.4 动态对象年龄判定3.8.5 空间分配担保3.9 本章小结第4章 虚拟机性能监控、故障处理工具4.1 概述4.2 基础故障处理工具4.2.1 jps：虚拟机进程状况工具4.2.2 jstat：虚拟机统计信息监视工具4.2.3 jinfo：Java配置信息工具4.2.4 jmap：Java内存映像工具4.2.5 jhat：虚拟机堆转储快照分析工具4.2.6 jstack：Java堆栈跟踪工具4.2.7 基础工具总结4.3 可视化故障处理工具4.3.1 JHSDB：基于服务性代理的调试工具4.3.2 JConsole：Java监视与管理控制台4.3.3 VisualVM：多合-故障处理工具4.3.4 Java Mission Control：可持续在线的监控工具4.4 HotSpot虚拟机插件及工具4.5 本章小结第5章 调优案例分析与实战5.1 概述5.2 案例分析5.2.1 大内存硬件上的程序部署策略5.2.2 集群间同步导致的内存溢出5.2.3 堆外内存导致的溢出错误5.2.4 外部命令导致系统缓慢5.2.5 服务器虚拟机进程崩溃5.2.6 不恰当数据结构导致内存占用过大5.2.7 由Windows虚拟内存导致的长时间停顿5.2.8 由安全点导致长时间停顿5.3 实战：Eclipse运行速度调优5.3.1 调优前的程序运行状态5.3.2 升级JDK版本的性能变化及兼容问题5.3.3 编译时间和类加载时间的优化5.3.4 调整内存设置控制垃圾收集频率5.3.5 选择收集器降低延迟5.4 本章小结第三部分 虚拟机执行子系统第6章 类文件结构6.1 概述6.2 无关性的基石6.3 Class类文件的结构6.3.1 魔数与Class文件的版本6.3.2 常量池6.3.3 访问标志6.3.4 类索引、父类索引与接口索引集合6.3.5 字段表集合6.3.6 方法表集合6.3.7 属性表集合6.4 字节码指令简介6.4.1 字节码与数据类型6.4.2 加载和存储指令6.4.3 运算指令6.4.4 类型转换指令6.4.5 对象创建与访问指令6.4.6 操作数栈管理指令6.4.7 控制转移指令6.4.8 方法调用和返回指令6.4.9 异常处理指令6.4.10 同步指令6.5 公有设计，私有实现6.6 Class文件结构的发展6.7 本章小结第7章 虚拟机类加载机制7.1 概述7.2 类加载的时机7.3 类加载的过程7.3.1 加载7.3.2 验证7.3.3 准备7.3.4 解析7.3.5 初始化7.4 类加载器7.4.1 类与类加载器7.4.2 双亲委派模型7.4.3 破坏双亲委派模型7.5 Java模块化系统7.5.1 模块的兼容性7.5.2 模块化下的类加载器7.6 本章小结第8章 虚拟机字节码执行引擎8.1 概述8.2 运行时栈帧结构8.2.1 局部变量表8.2.2 操作数栈8.2.3 动态连接8.2.4 方法返回地址8.2.5 附加信息8.3 方法调用8.3.1 解析8.3.2 分派8.4 动态类型语言支持8.4.1 动态类型语言8.4.2 Java与动态类型8.4.3 java.lang.invoke包8.4.4 invokedynamic指令8.4.5 实战：掌控方法分派规则8.5 基于栈的字节码解释执行引擎8.5.1 解释执行8.5.2 基于栈的指令集与基于寄存器的指令集8.5.3 基于栈的解释器执行过程8.6 本章小结第9章 类加载及执行子系统的案例与实战9.1 概述9.2 案例分析9.2.1 Tomcat：正统的类加载器架构9.2.2 OSGi：灵活的类加载器架构9.2.3 字节码生成技术与动态代理的实现9.2.4 Backport工具：Java的时光机器9.3 实战：自己动手实现远程执行功能9.3.1 目标9.3.2 思路9.3.3 实现9.3.4 验证9.4 本章小结第四部分 程序编译与代码优化第10章 前端编译与优化10.1 概述10.2 Javac编译器10.2.1 Javac的源码与调试10.2.2 解析与填充符号表10.2.3 注解处理器10.2.4 语义分析与字节码生成10.3 Java语法糖的味道10.3.1 泛型10.3.2 自动装箱、拆箱与遍历循环10.3.3 条件编译10.4 实战：插入式注解处理器10.4.1 实战目标10.4.2 代码实现10.4.3 运行与测试10.4.4 其他应用案例10.5 本章小结第11章 后端编译与优化11.1 概述11.2 即时编译器11.2.1 解释器与编译器11.2.2 编译对象与触发条件11.2.3 编译过程11.2.4 实战：查看及分析即时编译结果11.3 提前编译器11.3.1 提前编译的优劣得失11.3.2 实战：Jaotc的提前编译11.4 编译器优化技术11.4.1 优化技术概览11.4.2 方法内联11.4.3 逃逸分析11.4.4 公共子表达式消除11.4.5 数组边界检查消除11.5 实战：深入理解Graal编译器11.5.1 历史背景11.5.2 构建编译调试环境11.5.3 JVMCI编译器接口11.5.4 代码中间表示11.5.5 代码优化与生成11.6 本章小结第五部分 高效并发第12章 Java内存模型与线程12.1 概述12.2 硬件的效率与一致性12.3 Java内存模型12.3.1 主内存与工作内存12.3.2 内存间交互操作12.3.3 对于volatile型变量的特殊规则12.3.4 针对long和double型变量的特殊规则12.3.5 原子性、可见性与有序性12.3.6 先行发生原则12.4 Java与线程12.4.1 线程的实现12.4.2 Java线程调度12.4.3 状态转换12.5 Java与协程12.5.1 内核线程的局限12.5.2 协程的复苏12.5.3 Java的解决方案12.6 本章小结第13章 线程安全与锁优化13.1 概述13.2 线程安全13.2.1 Java语言中的线程安全13.2.2 线程安全的实现方法13.3 锁优化13.3.1 自旋锁与自适应自旋13.3.2 锁消除13.3.3 锁粗化13.3.4 轻量级锁13.3.5 偏向锁13.4 本章小结附录A 在Windows系统下编译OpenJDK 6附录B 展望Java技术的未来（2013年版）附录C 虚拟机字节码指令表附录D 对象查询语言（OQL）简介附录E JDK历史版本轨迹","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"DeepLearning4J(二)：简易一元线性回归","slug":"DeepLearning4J-二-：简易一元线性回归","date":"2020-01-22T04:24:18.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2020/01/22/DeepLearning4J-二-：简易一元线性回归/","link":"","permalink":"http://www.octber.xyz/2020/01/22/DeepLearning4J-%E4%BA%8C-%EF%BC%9A%E7%AE%80%E6%98%93%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","excerpt":"前言本节学习简易一元线性回归","text":"前言本节学习简易一元线性回归 考虑一个模型，用数据去计算一个y=ax+b其中a和b的值，比如我们输入(1,1)(2,2) 这就是一个一层的神经网络 神经网络的配置我们需要配置神经网络的超参数-&gt;为什么叫超参数呢？ 超参数 -&gt; 用于辅助模型学习参数的参数 -&gt; hyper-parameter -&gt; 超参数学习的参数是什么？ y = ax + b其中的x,y是已知的，这是用于神经网络的训练样本。参数 a,b是未知的，所以a,b是我们神经网络需要学习的参数同时我们需要配置超参数来辅助神经网络学习到a 和 b这两个参数 seed 随机种子 -&gt; 随机数生成通常需要一个起点，我们所生成的随机数都是伪随机数。 因为神经网络训练时，模型的初试权重和偏置是随机生成的,我们需要随机数种子保证每次初始化的权重大体一致,这样可以保证模型结果的可复现性,只有模型结果可复现-&gt;进行神经网络的调参-&gt;我们的调参对于模型效果提升是有意义的 optimizationAlgo 优化算法使用。最常见:OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT 1234567891011/** * Optimization algorithm to use * @author Adam Gibson * */public enum OptimizationAlgorithm &#123; LINE_GRADIENT_DESCENT, CONJUGATE_GRADIENT, LBFGS, STOCHASTIC_GRADIENT_DESCENT&#125; weightInit 对神经网络的权重进行随机初始化,随机的权重要比全0的权重对神经网络训练更有意义 1234567891011121314151617181920212223public enum WeightInit &#123; DISTRIBUTION, ZERO, ONES, SIGMOID_UNIFORM, NORMAL, LECUN_NORMAL, UNIFORM, XAVIER, XAVIER_UNIFORM, XAVIER_FAN_IN, XAVIER_LEGACY RELU, RELU_UNIFORM, IDENTITY, LECUN_UNIFORM, VAR_SCALING_NORMAL_FAN_IN, VAR_SCALING_NORMAL_FAN_OUT, VAR_SCALING_NORMAL_FAN_AVG, VAR_SCALING_UNIFORM_FAN_IN, VAR_SCALING_UNIFORM_FAN_OUT, VAR_SCALING_UNIFORM_FAN_AVG&#125; updater 优化算法 —————————分割线————————— 完整代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class SingleRegression &#123; //随机数种子，用于结果复现 private static final int seed = 12345; //对于每个miniBatch的迭代次数 private static final int iterations = 10; //epoch数量(全部数据的训练次数) private static final int nEpochs = 20; //一共生成多少样本点 private static final int nSamples = 1000; //Batch size: i.e., each epoch has nSamples/batchSize parameter updates private static final int batchSize = 100; //网络模型学习率 private static final double learningRate = 0.01; //随机数据生成的范围 private static int MIN_RANGE = 0; private static int MAX_RANGE = 3; private static final Random rng = new Random(seed); public static void main(String[] args) &#123; //Create the network int numInput = 1; int numOutputs = 1; /** * 神经网络的配置 我们需要配置神经网络的超参数-&gt;为什么叫超参数呢？ 超参数 -&gt; 用于辅助模型学习参数的参数 -&gt; hyper-parameter -&gt; 超参数 学习的参数是什么？ y = ax + b 其中的x,y是已知的，这是用于神经网络的训练样本。 参数 a,b是未知的，所以a,b是我们神经网络需要学习的参数 同时我们需要配置超参数来辅助神经网络学习到a 和 b这两个参数 */ MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder() /** * 随机种子 -&gt; 随机数生成通常需要一个起点，我们所生成的随机数都是伪随机数。 * 因为神经网络训练时，模型的初试权重和偏置是随机生成的 * 我们需要随机数种子保证每次初始化的权重大体一致 * 这样可以保证模型结果的可复现性 * 只有模型结果可复现-&gt;进行神经网络的调参-&gt;我们的调参对于模型效果提升是有意义的 */ .seed(seed) /** * 找方向 */ .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT) /** * 对神经网络的权重进行随机初始化 * 随机的权重要比全0的权重对神经网络训练更有意义 */ .weightInit(WeightInit.XAVIER) /** * 优化算法 * tf,keras -&gt; optimizer * 迈步子 * * 学习率迈步子的大小 * 去吴恩达-&gt;网易云课堂-&gt;微专业 */ .updater(new Sgd(learningRate)) .list() .layer(0, new OutputLayer.Builder(LossFunctions.LossFunction.MSE) /** * y = x * None */ .activation(Activation.IDENTITY) /** * 上一层输出 */ .nIn(numInput) /** * 当前层神经单元的个数 */ .nOut(numOutputs).build()) /** * 预训练 */ .pretrain(false) /** * 反向传播 */ .backprop(true).build(); // 使用 MultiLayerNetwork 对我们的 conf 进行一个包装 // 对神经网络进行了构建 MultiLayerNetwork net = new MultiLayerNetwork(conf); // 必须调用 init() 方法 // 是对于模型参数的初始化 net.init(); System.out.println(net.summary()); /** * 有监听器，用于监听我们神经网络训练时候的状态 * 主要是用于监听我们神经网络训练时候的损失函数的得分 * 目前参数为1，则说明网络每训练一次，就会打印一次损失函数的得分 */// net.setListeners(new ScoreIterationListener(1)); DataSetIterator iterator = getTrainingData(batchSize, rng); // 后面就是进行训练了 &#125;&#125;","categories":[{"name":"/java","slug":"java","permalink":"http://www.octber.xyz/categories/java/"}],"tags":[{"name":"dl4j","slug":"dl4j","permalink":"http://www.octber.xyz/tags/dl4j/"}]},{"title":"DeepLearning4J(一)：入门","slug":"DeepLearning4J-一-：入门","date":"2020-01-21T15:20:49.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2020/01/21/DeepLearning4J-一-：入门/","link":"","permalink":"http://www.octber.xyz/2020/01/21/DeepLearning4J-%E4%B8%80-%EF%BC%9A%E5%85%A5%E9%97%A8/","excerpt":"前言这一系列博文我将学习DeepLearning4J深度学习的一系列知识，依托于一个毕业设计项目：基于深度学习图像识别分析的X光骨龄检测与分析。选择dl4j的主要原因是因为个人喜欢Java变成，对python不感冒，而dl4j是一个企业级应用水准的深度学习框架，完全可以胜任这项任务。","text":"前言这一系列博文我将学习DeepLearning4J深度学习的一系列知识，依托于一个毕业设计项目：基于深度学习图像识别分析的X光骨龄检测与分析。选择dl4j的主要原因是因为个人喜欢Java变成，对python不感冒，而dl4j是一个企业级应用水准的深度学习框架，完全可以胜任这项任务。 资源 dl4j官网： https://deeplearning4j.org/ dl4j的Git地址： https://github.com/deeplearning4j dl4j官方中文快速入门： https://deeplearning4j.org/cn/quickstart 教程Git地址: https://github.com/sjsdfg/dl4j-tutorials 优秀博客: https://blog.csdn.net/u011669700/article/details/80139619 入门知识-Lesson 01两种存储方式： C Order行邮箱存储 F Order列优先储存 而Dl4j所有的矩阵运算都是F Order进行存储并且进行计算的 基础类 INDArray这是一个可序列化的接口类 创建 1Interface for an ndarray 简称 INDArray 它主要可以创建一些基本的多元数组: 123456789101112131415161718192021222324/* 构造一个3行5列的全0 ndarray */System.out.println(&quot;构造一个3行5列的全0 ndarray&quot;);INDArray zeros = Nd4j.zeros(3, 5);System.out.println(zeros);/* 构造一个3行5列的全1 ndarray */System.out.println(&quot;构造一个3行5列的全1 ndarray&quot;);INDArray ones = Nd4j.ones(3, 5);System.out.println(ones);/* 构造一个3行5列，数组元素均为随机产生的ndarray */System.out.println(&quot;构造一个3行5列，数组元素均为随机产生的ndarray&quot;);INDArray rands = Nd4j.rand(3, 5);System.out.println(rands);/* 构造一个3行5列，数组元素服从高斯分布（平均值为0，标准差为1）的ndarray */System.out.println(&quot;构造一个3行5列，数组元素服从高斯分布（平均值为0，标准差为1）的ndarray&quot;);INDArray randns = Nd4j.randn(3, 5);System.out.println(randns);/* 给一个一维数据，根据shape创造ndarray */System.out.println(&quot;给一个一维数据，根据shape创造ndarray&quot;);INDArray array1 = Nd4j.create(new float[]&#123;2, 2, 2, 2&#125;, new int[]&#123;1, 4&#125;);System.out.println(array1);INDArray array2 = Nd4j.create(new float[]&#123;2, 2, 2, 2&#125;, new int[]&#123;2, 2&#125;);System.out.println(array2); 输出的结果为: 1234567891011121314151617181920构造一个3行5列的全0 ndarray[[ 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0]]构造一个3行5列的全1 ndarray[[ 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [ 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [ 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]]构造一个3行5列，数组元素均为随机产生的ndarray[[ 0.9616, 0.9450, 0.5324, 0.4563, 0.5084], [ 0.8097, 0.9463, 0.8487, 0.1333, 0.4296], [ 0.5177, 0.0301, 0.6035, 0.7891, 0.0182]]构造一个3行5列，数组元素服从高斯分布（平均值为0，标准差为1）的ndarray[[ 1.0183, -2.1546, 0.7305, -0.3929, -1.1482], [ -2.0195, 1.2381, -0.6725, -1.1822, -0.4341], [ -0.1106, -1.9217, -0.1923, -0.4366, 0.2219]]给一个一维数据，根据shape创造ndarray[[ 2.0000, 2.0000, 2.0000, 2.0000]][[ 2.0000, 2.0000], [ 2.0000, 2.0000]] 设置和修改/遍历样例代码: 12345678910111213141516171819202122232425262728293031INDArray nd = Nd4j.create(new float[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12&#125;, new int[]&#123;2, 6&#125;);System.out.println(&quot;打印原有数组&quot;);System.out.println(nd);/* 获取指定索引的值 */System.out.println(&quot;获取数组下标为0, 3的值&quot;);double value = nd.getDouble(0, 3);System.out.println(value);/* 修改指定索引的值 */System.out.println(&quot;修改数组下标为0, 3的值&quot;);//scalar 标量nd.putScalar(0, 3, 100);System.out.println(nd);/* 使用索引迭代器遍历ndarray，使用c order */System.out.println(&quot;使用索引迭代器遍历ndarray&quot;);NdIndexIterator iter = new NdIndexIterator(2, 6);while (iter.hasNext()) &#123; long[] nextIndex = iter.next(); double nextVal = nd.getDouble(nextIndex); System.out.println(nextVal);&#125; 输出结果为: 123456789101112131415161718192021打印原有数组[[ 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000], [ 7.0000, 8.0000, 9.0000, 10.0000, 11.0000, 12.0000]]获取数组下标为0, 3的值4.0修改数组下标为0, 3的值[[ 1.0000, 2.0000, 3.0000, 100.0000, 5.0000, 6.0000], [ 7.0000, 8.0000, 9.0000, 10.0000, 11.0000, 12.0000]]使用索引迭代器遍历ndarray1.02.03.0100.05.06.07.08.09.010.011.012.0 获取行,获取并且设置数组部分样例代码: 1234567891011121314151617181920212223242526INDArray nd = Nd4j.create(new float[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12&#125;, new int[]&#123;2, 6&#125;);System.out.println(&quot;原始数组&quot;);System.out.println(nd);/* 获取一行 */System.out.println(&quot;获取数组中的一行&quot;);INDArray singleRow = nd.getRow(0);System.out.println(singleRow);/* 获取多行 */System.out.println(&quot;获取数组中的多行&quot;);INDArray multiRows = nd.getRows(0, 1);System.out.println(multiRows);/* 替换其中的一行 */System.out.println(&quot;替换原有数组中的一行&quot;);INDArray replaceRow = Nd4j.create(new float[]&#123;1, 3, 5, 7, 9, 11&#125;);nd.putRow(0, replaceRow);System.out.println(nd); 输出结果: 1234567891011原始数组[[ 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000], [ 7.0000, 8.0000, 9.0000, 10.0000, 11.0000, 12.0000]]获取数组中的一行[[ 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000]]获取数组中的多行[[ 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000], [ 7.0000, 8.0000, 9.0000, 10.0000, 11.0000, 12.0000]]替换原有数组中的一行[[ 1.0000, 3.0000, 5.0000, 7.0000, 9.0000, 11.0000], [ 7.0000, 8.0000, 9.0000, 10.0000, 11.0000, 12.0000]] 矩阵操作样例代码: 12345678910111213141516171819202122232425// 1x2的行向量INDArray nd = Nd4j.create(new float[]&#123;1,2&#125;,new int[]&#123;1, 2&#125;);// 2x1的列向量INDArray nd2 = Nd4j.create(new float[]&#123;3,4&#125;,new int[]&#123;2, 1&#125;); //vector as column// 创造两个2x2的矩阵INDArray nd3 = Nd4j.create(new float[]&#123;1,3,2,4&#125;,new int[]&#123;2,2&#125;); //elements arranged column majorINDArray nd4 = Nd4j.create(new float[]&#123;3,4,5,6&#125;,new int[]&#123;2, 2&#125;);//打印System.out.println(nd);System.out.println(nd2);System.out.println(nd3);//1x2 and 2x1 -&gt; 1x1INDArray ndv = nd.mmul(nd2);System.out.println(ndv + &quot;, shape = &quot; + Arrays.toString(ndv.shape()));//1x2 and 2x2 -&gt; 1x2ndv = nd.mmul(nd4);System.out.println(ndv + &quot;, shape = &quot; + Arrays.toString(ndv.shape()));//2x2 and 2x2 -&gt; 2x2ndv = nd3.mmul(nd4);System.out.println(ndv + &quot;, shape = &quot; + Arrays.toString(ndv.shape())); 输出结果: 123456789[[ 1.0000, 2.0000]][3.0000, 4.0000][[ 1.0000, 3.0000], [ 2.0000, 4.0000]]11.0000, shape = [1, 1][[ 13.0000, 16.0000]], shape = [1, 2][[ 18.0000, 22.0000], [ 26.0000, 32.0000]], shape = [2, 2] Lesson 01总结Deeplearning4j - ND4j方法快速索引 ND4J和ND4S是JVM的科学计算库，并为生产环境设计，亦即例程运行速度快，RAM要求低。 主要特点： 多用途多维数组对象 多平台功能，包括GPU 线性代数和信号处理功能 由于易用性上存在的缺口，Java、Scala和Clojure编程人员无法充分利用NumPy或Matlab等数据分析方面最强大的工具。Breeze等其他库则不支持多维数组或张量，而这却是深度学习和其他任务的关键。ND4J和ND4S正得到国家级实验室的使用，以完成气候建模等任务。这类任务要求完成计算密集的模拟运算。 ND4J在开源、分布式、支持GPU的库内，为JVM带来了符合直觉的、Python编程人员所用的科学计算工具。在结构上，ND4J与SLF4J相似。ND4J让生产环境下的工程师能够轻松将算法和界面移植到Java和Scala体系内的其他库内。创建ndarray 12345678创建值全为0： Nd4j.zeros(nRows, nCols) Nd4j.zeros(int...)创建值全为1： Nd4j.ones(nRows, nCols)复制NDArray： arr.dup()创建一个行向量或者列向量： myRow = Nd4j.create(myDoubleArr)， myCol = Nd4j.create(myDoubleArr,new int[]&#123;10,1&#125;)使用 double[][] 创建二维 NDArray : Nd4j.create(double[][])从行或者列进行 NDArray 堆叠：Nd4j.hstack(INDArray...) Nd4j.vstack(INDArray...)创建元素服从正太分布的 NDArray： Nd4j.rand(int,int) Nd4j.rand(int[])普通 （0,1）范围的 NDArray: Nd4j.randn(int,int) Nd4j.randn(int[]) 获取 NDArray 的属性 123456获取维度： rank()只对二维 NDArray 有用的方法，获取行和列数： rows() columns()第 i 个维度的长度：size(i)获取 NDArray 的形状： shape()获取所有元素的个数： arr.length()判断 NDArray 的类型： isMatrix() isVector() isRowVector() isRowVector() 获取或者设定特定的值 123获取第 i 行，第 j 列的数值：arr.getDouble(i,j)获取超过三维 NDArray 的值： arr.getDouble(int[])对特定位置进行赋值：arr.putScalar(int[],double) 张量操作 123456加上一个值： arr1.add(myDouble)减去一个值：arr1.sub(myDouble)乘以一个值：arr.mul(myDouble)除以一个值：arr.div(myDouble)减法反操作（scalar - arr1）：arr1.rsub(myDouble)除法反操作（scalar / arr1）：arr1.rdiv(myDouble) 元素（Element-Wise）操作 12345加：arr1.add(arr2)减：arr1.sub(arr2)乘：arr1.mul(arr2)除：arr1.div(arr2)赋值：arr1.assign(arr2) 规约操作 1234所有元素的和：arr.sumNumber()所有元素的乘积：arr.prod()L1或者L2范数：arr.norm1() arr.norm2()所有元素的标准差：arr.stdNumber() 线性代数操作 1234矩阵乘法：arr1.mmul(arr2)矩阵转置：transpose()获取对角矩阵：Nd4j.diag(INDArray)矩阵求逆：InvertMatrix.invert(INDArray,boolean) 获取 NDArray 一部分 1234获取一行（仅用于2维 NDArray）：getRow(int)获取多行（仅用于2维 NDArray）：getRows(int...)设置一行（仅用于2维 NDArray）：putRow(int,INDArray)获取前三行，所有列的值：Nd4j.create(0).get(NDArrayIndex.interval(0,3),NDArrayIndex.all()); 元素级变换（Tanh, Sigmoid, Sin, Log etc） 123使用 Transform :Transforms.sin(INDArray) Transforms.log(INDArray) Transforms.sigmoid(INDArray)方法1： Nd4j.getExecutioner().execAndReturn(new Tanh(INDArray))方法2： Nd4j.getExecutioner().execAndReturn(Nd4j.getOpFactory().createTransform(&quot;tanh&quot;,INDArray)) 转载自本文为CSDN博主「寒沧」的原创文章 项目配置Pom配置如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org&lt;/groupId&gt; &lt;artifactId&gt;dl4j-tutorials&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;!-- Change the nd4j.backend property to nd4j-cuda-9.2 to use CUDA GPUs --&gt; &lt;!-- CPU使用 nd4j-native-platform --&gt; &lt;!-- GPU使用 nd4j-cuda-9.2-platform--&gt; &lt;nd4j.backend&gt;nd4j-native-platform&lt;/nd4j.backend&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;shadedClassifier&gt;bin&lt;/shadedClassifier&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;nd4j.version&gt;1.0.0-beta2&lt;/nd4j.version&gt; &lt;dl4j.version&gt;1.0.0-beta2&lt;/dl4j.version&gt; &lt;datavec.version&gt;1.0.0-beta2&lt;/datavec.version&gt; &lt;arbiter.version&gt;1.0.0-beta2&lt;/arbiter.version&gt; &lt;rl4j.version&gt;1.0.0-beta2&lt;/rl4j.version&gt; &lt;!-- For Spark examples: change the _1 to _2 to switch between Spark 1 and Spark 2 --&gt; &lt;dl4j.spark.version&gt;1.0.0-beta2_spark_1&lt;/dl4j.spark.version&gt; &lt;datavec.spark.version&gt;1.0.0-beta2_spark_1&lt;/datavec.spark.version&gt; &lt;jcommander.version&gt;1.27&lt;/jcommander.version&gt; &lt;!-- Scala binary version: DL4J&#x27;s Spark and UI functionality are released with both Scala 2.10 and 2.11 support --&gt; &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt; &lt;guava.version&gt;19.0&lt;/guava.version&gt; &lt;logback.version&gt;1.1.7&lt;/logback.version&gt; &lt;jfreechart.version&gt;1.0.13&lt;/jfreechart.version&gt; &lt;jcommon.version&gt;1.0.23&lt;/jcommon.version&gt; &lt;maven-shade-plugin.version&gt;2.4.3&lt;/maven-shade-plugin.version&gt; &lt;exec-maven-plugin.version&gt;1.4.0&lt;/exec-maven-plugin.version&gt; &lt;maven.minimum.version&gt;3.3.1&lt;/maven.minimum.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.nd4j&lt;/groupId&gt; &lt;artifactId&gt;nd4j-native-platform&lt;/artifactId&gt; &lt;version&gt;$&#123;nd4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.nd4j&lt;/groupId&gt; &lt;artifactId&gt;nd4j-cuda-9.2&lt;/artifactId&gt; &lt;version&gt;$&#123;nd4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- ND4J backend. You need one in every DL4J project. Normally define artifactId as either &quot;nd4j-native-platform&quot; or &quot;nd4j-cuda-7.5-platform&quot; --&gt; &lt;dependency&gt; &lt;groupId&gt;org.nd4j&lt;/groupId&gt; &lt;artifactId&gt;$&#123;nd4j.backend&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;nd4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt; &lt;artifactId&gt;deeplearning4j-cuda-9.2&lt;/artifactId&gt; &lt;version&gt;$&#123;dl4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Core DL4J functionality --&gt; &lt;dependency&gt; &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt; &lt;artifactId&gt;deeplearning4j-core&lt;/artifactId&gt; &lt;version&gt;$&#123;dl4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt; &lt;artifactId&gt;deeplearning4j-nlp&lt;/artifactId&gt; &lt;version&gt;$&#123;dl4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt; &lt;artifactId&gt;deeplearning4j-zoo&lt;/artifactId&gt; &lt;version&gt;$&#123;dl4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- deeplearning4j-ui is used for HistogramIterationListener + visualization: see http://deeplearning4j.org/visualization --&gt; &lt;dependency&gt; &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt; &lt;artifactId&gt;deeplearning4j-ui_$&#123;scala.binary.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;dl4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Force guava versions for using UI/HistogramIterationListener --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;$&#123;guava.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- datavec-data-codec: used only in video example for loading video data --&gt; &lt;dependency&gt; &lt;artifactId&gt;datavec-data-codec&lt;/artifactId&gt; &lt;groupId&gt;org.datavec&lt;/groupId&gt; &lt;version&gt;$&#123;datavec.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Used in the feedforward/classification/MLP* and feedforward/regression/RegressionMathFunctions example --&gt; &lt;dependency&gt; &lt;groupId&gt;jfree&lt;/groupId&gt; &lt;artifactId&gt;jfreechart&lt;/artifactId&gt; &lt;version&gt;$&#123;jfreechart.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jfree&lt;/groupId&gt; &lt;artifactId&gt;jcommon&lt;/artifactId&gt; &lt;version&gt;$&#123;jcommon.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Used for downloading data in some of the examples --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.3.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;exec-maven-plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;exec&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;executable&gt;java&lt;/executable&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-shade-plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt; &lt;shadedClassifierName&gt;$&#123;shadedClassifier&#125;&lt;/shadedClassifierName&gt; &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;org/datanucleus/**&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;reference.conf&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"dl4f","slug":"dl4f","permalink":"http://www.octber.xyz/tags/dl4f/"}]},{"title":"2019.9.12日报","slug":"2019-9-12日报","date":"2019-09-12T09:32:45.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/2019-9-12日报/","link":"","permalink":"http://www.octber.xyz/2019/09/12/2019-9-12%E6%97%A5%E6%8A%A5/","excerpt":"前言[TOC]","text":"前言[TOC] 1. 任务与任务进度/工时说明 今天主要任务为测试，下面说一下测试中发现的问题，已经提交到测试发现问题一览中 1.1 测试问题：银行间联系人 问题：银行间联系人新增【联系电话】格式校验问题 1.2 测试问题：干系人信息 问题：干系人信息修改中【评级展望】下拉框选中后显示“输入的不是整数格式” 2. 已解决的问题 测试 3. 未解决的问题4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"JVM系列(十):类加载器","slug":"JVM系列-十-类加载器","date":"2019-09-12T02:05:41.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-十-类加载器/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E5%8D%81-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(九):类加载的过程","slug":"JVM系列-九-类加载的过程","date":"2019-09-12T02:04:55.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-九-类加载的过程/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E4%B9%9D-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E8%BF%87%E7%A8%8B/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(八):类加载的时机","slug":"JVM系列-八-类加载的时机","date":"2019-09-12T02:04:05.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-八-类加载的时机/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E5%85%AB-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E6%97%B6%E6%9C%BA/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(七):类文件结构","slug":"JVM系列-七-类文件结构","date":"2019-09-12T02:03:15.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-七-类文件结构/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E4%B8%83-%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(六):JVM性能调优","slug":"JVM系列-六-JVM性能调优","date":"2019-09-12T02:02:43.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-六-JVM性能调优/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E5%85%AD-JVM%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(五):内存分配与回收策略","slug":"JVM系列-五-内存分配与回收策略","date":"2019-09-12T02:02:06.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-五-内存分配与回收策略/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E4%BA%94-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(四):HotSpot垃圾回收器","slug":"JVM系列-四-HotSpot垃圾回收器","date":"2019-09-12T02:01:13.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-四-HotSpot垃圾回收器/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E5%9B%9B-HotSpot%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(三):垃圾收集策略与算法","slug":"JVM系列-三-垃圾收集策略与算法","date":"2019-09-12T02:00:52.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-三-垃圾收集策略与算法/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E4%B8%89-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AD%96%E7%95%A5%E4%B8%8E%E7%AE%97%E6%B3%95/","excerpt":"前言垃圾收集策略与算法程序计数器、虚拟机栈、本地方法栈随线程而生，也随线程而灭；栈帧随着方法的开始而入栈，随着方法的结束而出栈。这几个区域的内存分配和回收都具有确定性，在这几个区域内不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。 而对于 Java 堆和方法区，我们只有在程序运行期间才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的正是这部分内存。","text":"前言垃圾收集策略与算法程序计数器、虚拟机栈、本地方法栈随线程而生，也随线程而灭；栈帧随着方法的开始而入栈，随着方法的结束而出栈。这几个区域的内存分配和回收都具有确定性，在这几个区域内不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。 而对于 Java 堆和方法区，我们只有在程序运行期间才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的正是这部分内存。 判定对象是否存活若一个对象不被任何对象或变量引用，那么它就是无效对象，需要被回收。 引用计数法在对象头维护着一个 counter 计数器，对象被引用一次则计数器 +1；若引用失效则计数器 -1。当计数器为 0 时，就认为该对象无效了。 引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法。但是主流的 Java 虚拟机里没有选用引用计数算法来管理内存，主要是因为它很难解决对象之间循环引用的问题。 举个栗子👉对象 objA 和 objB 都有字段 instance，令 objA.instance = objB 并且 objB.instance = objA，由于它们互相引用着对方，导致它们的引用计数都不为 0，于是引用计数算法无法通知 GC 收集器回收它们。 可达性分析法所有和 GC Roots 直接或间接关联的对象都是有效对象，和 GC Roots 没有关联的对象就是无效对象。 GC Roots 是指： Java 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈中引用的对象 方法区中常量引用的对象 方法区中类静态属性引用的对象 GC Roots 并不包括堆中对象所引用的对象，这样就不会有循环引用的问题。 引用的种类判定对象是否存活与“引用”有关。在 JDK 1.2 以前，Java 中的引用定义很传统，一个对象只有被引用或者没有被引用两种状态，我们希望能描述这一类对象：当内存空间还足够时，则保留在内存中；如果内存空间在进行垃圾手收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。 在 JDK 1.2 之后，Java 对引用的概念进行了扩充，将引用分为了以下四种。不同的引用类型，主要体现的是对象不同的可达性状态reachable和垃圾收集的影响。 强引用（Strong Reference）类似 “Object obj = new Object()” 这类的引用，就是强引用，只要强引用存在，垃圾收集器永远不会回收被引用的对象。但是，如果我们错误地保持了强引用，比如：赋值给了 static 变量，那么对象在很长一段时间内不会被回收，会产生内存泄漏。 软引用（Soft Reference）软引用是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 弱引用（Weak Reference）弱引用的强度比软引用更弱一些。当 JVM 进行垃圾回收时，无论内存是否充足，都会回收只被弱引用关联的对象。 虚引用（Phantom Reference）虚引用也称幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响。它仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制。 回收堆中无效对象对于可达性分析中不可达的对象，也并不是没有存活的可能。 判定 finalize() 是否有必要执行JVM 会判断此对象是否有必要执行 finalize() 方法，如果对象没有覆盖 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，那么视为“没有必要执行”。那么对象基本上就真的被回收了。 如果对象被判定为有必要执行 finalize() 方法，那么对象会被放入一个 F-Queue 队列中，虚拟机会以较低的优先级执行这些 finalize()方法，但不会确保所有的 finalize() 方法都会执行结束。如果 finalize() 方法出现耗时操作，虚拟机就直接停止指向该方法，将对象清除。 对象重生或死亡如果在执行 finalize() 方法时，将 this 赋给了某一个引用，那么该对象就重生了。如果没有，那么就会被垃圾收集器清除。 任何一个对象的 finalize() 方法只会被系统自动调用一次，如果对象面临下一次回收，它的 finalize() 方法不会被再次执行，想继续在 finalize() 中自救就失效了。 回收方法区内存方法区中存放生命周期较长的类信息、常量、静态变量，每次垃圾收集只有少量的垃圾被清除。方法区中主要清除两种垃圾： 废弃常量 无用的类 判定废弃常量只要常量池中的常量不被任何变量或对象引用，那么这些常量就会被清除掉。比如，一个字符串 “bingo” 进入了常量池，但是当前系统没有任何一个 String 对象引用常量池中的 “bingo” 常量，也没有其它地方引用这个字面量，必要的话，”bingo”常量会被清理出常量池。 判定无用的类判定一个类是否是“无用的类”，条件较为苛刻。 该类的所有对象都已经被清除 加载该类的 ClassLoader 已经被回收 该类的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 一个类被虚拟机加载进方法区，那么在堆中就会有一个代表该类的对象：java.lang.Class。这个对象在类被加载进方法区时创建，在方法区该类被删除时清除。 垃圾收集算法学会了如何判定无效对象、无用类、废弃常量之后，剩余工作就是回收这些垃圾。常见的垃圾收集算法有以下几个： 标记-清除算法标记的过程是：遍历所有的 GC Roots，然后将所有 GC Roots 可达的对象标记为存活的对象。 清除的过程将遍历堆中所有的对象，将没有标记的对象全部清除掉。与此同时，清除那些被标记过的对象的标记，以便下次的垃圾回收。 这种方法有两个不足： 效率问题：标记和清除两个过程的效率都不高。 空间问题：标记清除之后会产生大量不连续的内存碎片，碎片太多可能导致以后需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法（新生代）为了解决效率问题，“复制”收集算法出现了。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块内存用完，需要进行垃圾收集时，就将存活者的对象复制到另一块上面，然后将第一块内存全部清除。这种算法有优有劣： 优点：不会有内存碎片的问题。 缺点：内存缩小为原来的一半，浪费空间。 为了解决空间利用率问题，可以将内存分为三块： Eden、From Survivor、To Survivor，比例是 8:1:1，每次使用 Eden 和其中一块 Survivor。回收时，将 Eden 和 Survivor 中还存活的对象一次性复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才使用的 Survivor 空间。这样只有 10% 的内存被浪费。 但是我们无法保证每次回收都只有不多于 10% 的对象存活，当 Survivor 空间不够，需要依赖其他内存（指老年代）进行分配担保。 分配担保为对象分配内存空间时，如果 Eden+Survivor 中空闲区域无法装下该对象，会触发 MinorGC 进行垃圾收集。但如果 Minor GC 过后依然有超过 10% 的对象存活，这样存活的对象直接通过分配担保机制进入老年代，然后再将新对象存入 Eden 区。 标记-整理算法（老年代）标记：它的第一个阶段与标记/清除算法是一模一样的，均是遍历 GC Roots，然后将存活的对象标记。 整理：移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。因此，第二阶段才称为整理阶段。 这是一种老年代的垃圾收集算法。老年代的对象一般寿命比较长，因此每次垃圾回收会有大量对象存活，如果采用复制算法，每次需要复制大量存活的对象，效率很低。 分代收集算法根据对象存活周期的不同，将内存划分为几块。一般是把 Java 堆分为新生代和老年代，针对各个年代的特点采用最适当的收集算法。 新生代：复制算法 老年代：标记-清除算法、标记-整理算法 （完）","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(二):HotSpot虚拟机对象","slug":"JVM系列-二-HotSpot虚拟机对象","date":"2019-09-12T02:00:29.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-二-HotSpot虚拟机对象/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E4%BA%8C-HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1/","excerpt":"前言","text":"前言","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM系列(一):JVM内存结构","slug":"JVM系列-一-JVM内存结构","date":"2019-09-12T01:58:20.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM系列-一-JVM内存结构/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E7%B3%BB%E5%88%97-%E4%B8%80-JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"前言Java 虚拟机的内存空间分为 5 个部分： 程序计数器 Java 虚拟机栈 本地方法栈 堆 方法区 JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。","text":"前言Java 虚拟机的内存空间分为 5 个部分： 程序计数器 Java 虚拟机栈 本地方法栈 堆 方法区 JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。 程序计数器（PC 寄存器）程序计数器的定义程序计数器是一块较小的内存空间，是当前线程正在执行的那条字节码指令的地址。若当前线程正在执行的是一个本地方法，那么此时程序计数器为Undefined。 程序计数器的作用 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了。 程序计数器的特点 是一块较小的内存空间。 线程私有，每条线程都有自己的程序计数器。 生命周期：随着线程的创建而创建，随着线程的结束而销毁。 是唯一一个不会出现OutOfMemoryError的内存区域。 Java 虚拟机栈（Java 栈）Java 虚拟机栈的定义Java 虚拟机栈是描述 Java 方法运行过程的内存模型。 Java 虚拟机栈会为每一个即将运行的 Java 方法创建一块叫做“栈帧”的区域，用于存放该方法运行过程中的一些信息，如： 局部变量表 操作数栈 动态链接 方法出口信息 …… 压栈出栈过程当方法运行过程中需要创建局部变量时，就将局部变量的值存入栈帧中的局部变量表中。 Java 虚拟机栈的栈顶的栈帧是当前正在执行的活动栈，也就是当前正在执行的方法，PC 寄存器也会指向这个地址。只有这个活动的栈帧的本地变量可以被操作数栈使用，当在这个栈帧中调用另一个方法，与之对应的栈帧又会被创建，新创建的栈帧压入栈顶，变为当前的活动栈帧。 方法结束后，当前栈帧被移出，栈帧的返回值变成新的活动栈帧中操作数栈的一个操作数。如果没有返回值，那么新的活动栈帧中操作数栈的操作数没有变化。 由于Java 虚拟机栈是与线程对应的，数据不是线程共享的，因此不用关心数据一致性问题，也不会存在同步锁的问题。 Java 虚拟机栈的特点 局部变量表随着栈帧的创建而创建，它的大小在编译时确定，创建时只需分配事先规定的大小即可。在方法运行过程中，局部变量表的大小不会发生改变。 Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError 若 Java 虚拟机栈的大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度时，抛出 StackOverFlowError 异常。 OutOfMemoryError 若允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展时，抛出 OutOfMemoryError 异常。 Java 虚拟机栈也是线程私有，随着线程创建而创建，随着线程的结束而销毁。 出现 StackOverFlowError 时，内存空间可能还有很多。 本地方法栈（C 栈）本地方法栈的定义本地方法栈是为 JVM 运行 Native 方法准备的空间，由于很多 Native 方法都是用 C 语言实现的，所以它通常又叫 C 栈。它与 Java 虚拟机栈实现的功能类似，只不过本地方法栈是描述本地方法运行过程的内存模型。 栈帧变化过程本地方法被执行时，在本地方法栈也会创建一块栈帧，用于存放该方法的局部变量表、操作数栈、动态链接、方法出口信息等。 方法执行结束后，相应的栈帧也会出栈，并释放内存空间。也会抛出 StackOverFlowError 和 OutOfMemoryError 异常。 如果 Java 虚拟机本身不支持 Native 方法，或是本身不依赖于传统栈，那么可以不提供本地方法栈。如果支持本地方法栈，那么这个栈一般会在线程创建的时候按线程分配。 堆堆的定义堆是用来存放对象的内存空间，几乎所有的对象都存储在堆中。 堆的特点 线程共享，整个 Java 虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。 在虚拟机启动时创建。 是垃圾回收的主要场所。 进一步可分为：新生代(Eden区 From Survior To Survivor)、老年代。 不同的区域存放不同生命周期的对象，这样可以根据不同的区域使用不同的垃圾回收算法，更具有针对性。 堆的大小既可以固定也可以扩展，但对于主流的虚拟机，堆的大小是可扩展的，因此当线程请求分配内存，但堆已满，且内存已无法再扩展时，就抛出 OutOfMemoryError 异常。 Java 堆所使用的内存不需要保证是连续的。而由于堆是被所有线程共享的，所以对它的访问需要注意同步问题，方法和对应的属性都需要保证一致性。 方法区方法区的定义Java 虚拟机规范中定义方法区是堆的一个逻辑部分。方法区存放以下信息： 已经被虚拟机加载的类信息 常量 静态变量 即时编译器编译后的代码 方法区的特点 线程共享。 方法区是堆的一个逻辑部分，因此和堆一样，都是线程共享的。整个虚拟机中只有一个方法区。 永久代。 方法区中的信息一般需要长期存在，而且它又是堆的逻辑分区，因此用堆的划分方法，把方法区称为“永久代”。 内存回收效率低。 方法区中的信息一般需要长期存在，回收一遍之后可能只有少量信息无效。主要回收目标是：对常量池的回收；对类型的卸载。 Java 虚拟机规范对方法区的要求比较宽松。 和堆一样，允许固定大小，也允许动态扩展，还允许不实现垃圾回收。 运行时常量池方法区中存放：类信息、常量、静态变量、即时编译器编译后的代码。常量就存放在运行时常量池中。 当类被 Java 虚拟机加载后， .class 文件中的常量就存放在方法区的运行时常量池中。而且在运行期间，可以向常量池中添加新的常量。如 String 类的 intern() 方法就能在运行期间向常量池中添加字符串常量。 直接内存（堆外内存）直接内存是除 Java 虚拟机之外的内存，但也可能被 Java 使用。 操作直接内存在 NIO 中引入了一种基于通道和缓冲的 IO 方式。它可以通过调用本地方法直接分配 Java 虚拟机之外的内存，然后通过一个存储在堆中的DirectByteBuffer对象直接操作该内存，而无须先将外部内存中的数据复制到堆中再进行操作，从而提高了数据操作的效率。 直接内存的大小不受 Java 虚拟机控制，但既然是内存，当内存不足时就会抛出 OutOfMemoryError 异常。 直接内存与堆内存比较 直接内存申请空间耗费更高的性能 直接内存读取 IO 的性能要优于普通的堆内存。 直接内存作用链： 本地 IO -&gt; 直接内存 -&gt; 本地 IO 堆内存作用链：本地 IO -&gt; 直接内存 -&gt; 非直接内存 -&gt; 直接内存 -&gt; 本地 IO 服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。 （完）","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"JVM原理系列详解","slug":"JVM原理系列详解","date":"2019-09-12T01:37:46.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/12/JVM原理系列详解/","link":"","permalink":"http://www.octber.xyz/2019/09/12/JVM%E5%8E%9F%E7%90%86%E7%B3%BB%E5%88%97%E8%AF%A6%E8%A7%A3/","excerpt":"前言本系列博文将详细介绍JVM系列知识，内容大多来自GitHub牛人的总结和观点，加上本人的思考，特此留念。 特别鸣谢：doocs","text":"前言本系列博文将详细介绍JVM系列知识，内容大多来自GitHub牛人的总结和观点，加上本人的思考，特此留念。 特别鸣谢：doocs 这里仅仅记录了一些笔者认为需要重点掌握的 JVM 知识点，如果你想更加全面地了解 JVM 底层原理，可以阅读周志明老师《深入理解Java虚拟机——JVM高级特性与最佳实践(第2版)》全书。 清单 JVM 原理系列详解 目录 链接：十月博客-JVM 最后更新日期：2019-09-12 09:37:46 目录 JVM内存结构 HotSpot 虚拟机对象探秘 垃圾收集策略与算法 HotSpot 垃圾收集器 内存分配与回收策略 JVM 性能调优 类文件结构 类加载的时机 类加载的过程 类加载器","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"2019.9.11日报","slug":"2019-9-11日报","date":"2019-09-11T12:40:07.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/2019-9-11日报/","link":"","permalink":"http://www.octber.xyz/2019/09/11/2019-9-11%E6%97%A5%E6%8A%A5/","excerpt":"前言[TOC]","text":"前言[TOC] 1. 任务与任务进度/工时说明1.1 测试：开户修改与详情页 问题： 详情页开户流程显示有问题，与对应内容不符合 解决进度： 100% 1.2 测试：提交-复核 工作流中各个环节状态确认 问题： 复核通过/拒绝后首页待办仍然显示 解决进度： 100% 1.3 测试： 场外模块其他功能 问题： 除部分样式问题，暂无发现其他问题 1.4 测试： 开户、修改开户信息中信息对应问题 问题： 页面加载速度不同，响应结果不同 解决进度： 100% 2. 已解决的问题测试中发现的问题 3. 未解决的问题4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"redis的并发竞争","slug":"redis的并发竞争","date":"2019-09-11T11:26:30.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/redis的并发竞争/","link":"","permalink":"http://www.octber.xyz/2019/09/11/redis%E7%9A%84%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89/","excerpt":"前言 特别鸣谢 石杉的架构笔记 redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？ 这个也是线上非常常见的一个问题，就是多客户端同时并发写一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。 而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。","text":"前言 特别鸣谢 石杉的架构笔记 redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？ 这个也是线上非常常见的一个问题，就是多客户端同时并发写一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。 而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。 某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。 你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。 每次要写之前，先判断一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.octber.xyz/tags/Redis/"}]},{"title":"redis 的雪崩、穿透和击穿","slug":"redis-的雪崩、穿透和击穿","date":"2019-09-11T11:20:20.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/redis-的雪崩、穿透和击穿/","link":"","permalink":"http://www.octber.xyz/2019/09/11/redis-%E7%9A%84%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E5%92%8C%E5%87%BB%E7%A9%BF/","excerpt":"前言 特别鸣谢 石杉的架构笔记 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？","text":"前言 特别鸣谢 石杉的架构笔记 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？ 缓存雪崩对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。 这就是缓存雪崩。 大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。 缓存雪崩的事前事中事后的解决方案如下。 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。 限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。 好处： 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。 缓存穿透对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。 黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。 举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。 解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。 缓存击穿缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.octber.xyz/tags/Redis/"}]},{"title":"如何保证缓存与数据库的双写一致性?","slug":"如何保证缓存与数据库的双写一致性","date":"2019-09-11T10:51:16.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/如何保证缓存与数据库的双写一致性/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/","excerpt":"前言 特别鸣谢 石杉的架构笔记 如何保证缓存与数据库的双写一致性？你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？","text":"前言 特别鸣谢 石杉的架构笔记 如何保证缓存与数据库的双写一致性？你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？ 问题剖析一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。 串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。 Cache Aside Pattern最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 更新的时候，先更新数据库，然后再删除缓存。 为什么是删除缓存，而不是更新缓存？ 原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。 比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。 另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？ 举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。 其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。 最初级的缓存不一致问题及解决方案问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。 解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。 比较复杂的数据不一致问题分析数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了… 为什么上亿流量高并发场景下，缓存会出现这个问题？ 只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。 解决方案如下： 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。 待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 高并发的场景下，该解决方案要注意的问题： 读请求长时阻塞 由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。 该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。 另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致读请求的长时阻塞。 一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。 如果一个内存队列中可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。 其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。 我们来实际粗略测算一下。 如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。 经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。 读请求并发量过高 这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。 但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。 多服务实例部署的请求路由 可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相同的服务实例上。 比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。 热点商品的路由问题，导致请求的倾斜 万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"我们为什么要使用缓存机制？","slug":"我们为什么要使用缓存机制？","date":"2019-09-11T10:42:08.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/我们为什么要使用缓存机制？/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E6%88%91%E4%BB%AC%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%EF%BC%9F/","excerpt":"前言 特别鸣谢 石杉的架构笔记 项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？","text":"前言 特别鸣谢 石杉的架构笔记 项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？ 面试官心理分析这个问题，互联网公司必问，要是一个人连缓存都不太清楚，那确实比较尴尬。 只要问到缓存，上来第一个问题，肯定是先问问你项目哪里用了缓存？为啥要用？不用行不行？如果用了以后可能会有什么不良的后果？ 这就是看看你对缓存这个东西背后有没有思考，如果你就是傻乎乎的瞎用，没法给面试官一个合理的解答，那面试官对你印象肯定不太好，觉得你平时思考太少，就知道干活儿。 面试题剖析项目中缓存是如何使用的？这个，需要结合自己项目的业务来。 我：用缓存的目的很简单，为了高性能和高并发，由于缓存是走内存的，内存天然就支撑高并发。在我的项目中采用Redis进行缓存处理，由于用户很多数据在请求一次过后很长时间几乎不会发生改变，针对这些数据合理使用缓存就可以优化用户前端的使用体验。 为什么要用缓存？用缓存，主要有两个用途：高性能、高并发。 高性能假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？ 缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。 就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。 高并发mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 2000QPS 也开始容易报警了。 所以要是你有个系统，高峰期一秒钟过来的请求有 1万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 key-value 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。 缓存是走内存的，内存天然就支撑高并发。 用了缓存之后会有什么不良后果？常见的缓存问题有以下几个： 缓存与数据库双写不一致 缓存雪崩、缓存穿透 缓存并发竞争 后面再详细说明。","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"消息队列的顺序性问题","slug":"消息队列的顺序性问题","date":"2019-09-11T10:18:25.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/消息队列的顺序性问题/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7%E9%97%AE%E9%A2%98/","excerpt":"前言 特别鸣谢 石杉的架构笔记 其实这个也是用 MQ 的时候必问的话题，第一看看你了不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这是生产系统中常见的问题。","text":"前言 特别鸣谢 石杉的架构笔记 其实这个也是用 MQ 的时候必问的话题，第一看看你了不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这是生产系统中常见的问题。 问题场景先看看顺序会错乱的俩场景： RabbitMQ：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。 Kafka：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.octber.xyz/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.octber.xyz/tags/RabbitMQ/"}]},{"title":"消息队列的幂等性","slug":"消息队列的幂等性","date":"2019-09-11T09:01:54.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/消息队列的幂等性/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7/","excerpt":"前言 特别鸣谢 石杉的架构笔记 如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？","text":"前言 特别鸣谢 石杉的架构笔记 如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？ 问题描述举个栗子。 有这么个场景。数据 1/2/3 依次进入 kafka，kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 offset=153 的这条数据，刚准备去提交 offset 到 zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，kafka 也就不知道你已经消费了 offset=153 这条数据。那么重启之后，消费者会找 kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。 如果消费者干的事儿是拿一条数据就往数据库里写一条，会导致说，你可能就把数据 1/2 在数据库里插入了 2 次，那么数据就错啦。 解决思路其实还是得结合业务来思考，我这里给几个思路： 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。 当然，如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。 我： 在我的应用中，保证幂等性，避免重复消费，其实就是对于一个功能子系统（如插入订单数据）而言，在插入前根据唯一标识（如订单id）进行查重，重复则更新数据。实际上我通过使用Redis的Set数据集，保证了天然的幂等性，经过Redis这一层高速缓存的天然幂等性过滤，实际入库的数据就不会存在脏数据。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.octber.xyz/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.octber.xyz/tags/RabbitMQ/"}]},{"title":"消息队列的消息丢失问题","slug":"消息队列的消息丢失问题","date":"2019-09-11T08:34:14.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/消息队列的消息丢失问题/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/","excerpt":"前言 特别鸣谢 石杉的架构笔记 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？","text":"前言 特别鸣谢 石杉的架构笔记 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？ RabbitMQ 生产者弄丢了数据生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。 此时可以选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。 123456789101112// 开启事务channel.txSelecttry &#123; // 这里发送消息&#125; catch (Exception e) &#123; channel.txRollback // 这里再次重发这条消息&#125;// 提交事务channel.txCommit 但是问题是，RabbitMQ 事务机制（同步）一搞，基本上吞吐量会下来，因为太耗性能。 所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。 事务机制和 confirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。 所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。 RabbitMQ 弄丢了数据就是 RabbitMQ 自己弄丢了数据，这个你必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。 设置持久化有两个步骤： 创建 queue 的时候将其设置为持久化这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。 第二个是发送消息的时候将消息的 deliveryMode 设置为 2就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。 必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。 注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。 所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。 消费端弄丢了数据RabbitMQ 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。 这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.octber.xyz/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.octber.xyz/tags/RabbitMQ/"}]},{"title":"消息队列的高可用问题","slug":"消息队列的高可用问题","date":"2019-09-11T08:07:40.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/消息队列的高可用问题/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E9%97%AE%E9%A2%98/","excerpt":"前言 特别鸣谢 石杉的架构笔记 在“为什么使用消息MQ？”一问中我提到，消息队列的高可用问题是一个重大的问题，作为中间桥梁的MQ，一旦崩溃，整个系统就无法正常运作。","text":"前言 特别鸣谢 石杉的架构笔记 在“为什么使用消息MQ？”一问中我提到，消息队列的高可用问题是一个重大的问题，作为中间桥梁的MQ，一旦崩溃，整个系统就无法正常运作。 RabbitMQ 的高可用性RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。 RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。 单机模式单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的😄，没人生产用单机模式。 普通集群模式（无高可用性）普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。 这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。 而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。 所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。 镜像集群模式（高可用性）这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。 那么如何开启这个镜像集群模式呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。 这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就没有扩展性可言了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？ Kafka 的高可用性Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。 这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。 实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。 Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。 比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。 Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。 这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。 写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为） 消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。 看到这里，相信你大致明白了 Kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 Kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.octber.xyz/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.octber.xyz/tags/RabbitMQ/"}]},{"title":"为什么使用MQ？","slug":"为什么使用MQ？","date":"2019-09-11T07:33:44.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/11/为什么使用MQ？/","link":"","permalink":"http://www.octber.xyz/2019/09/11/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8MQ%EF%BC%9F/","excerpt":"前言 特别鸣谢 石杉的架构笔记 结合我曾经做的一个项目，谈谈我为什么用得上RabbitMQ","text":"前言 特别鸣谢 石杉的架构笔记 结合我曾经做的一个项目，谈谈我为什么用得上RabbitMQ 为什么使用消息队列其实就是消息队列都有哪些使用场景，然后项目里具体是什么场景。 面试官问这个问题，期望的一个回答是说，有个什么业务场景，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。 先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：解耦、异步、削峰。 解耦看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃…… 在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！ 如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。 总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。 面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。 我： 在我的小超市小程序的运作中，客户下单和实际的处理是分离的，如果将客户下单等操作和业务逻辑（比如生成订单、通知第三方物流、减库存等、打印、发送短信、发送邮件）耦合在一起，在高并发场景下会造成系统缓慢甚至崩溃的问题（一个功能异常整个流程失败的问题），那么我使用RabbitMQ消息队列只需要在下单时，发布消息到对应的队列中去，让实际的打印、发送短信、发送邮件等系统订阅队列中的消息，在高并发场景下各司其职，就可以完美的解决这个问题。 异步再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。 一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。 如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！ 我：正如上面说说，发送短信，库存操作，订单处理等业务十分耗时，但是对于用户来说下单最迫切的需求是记录下单数据并执行支付操作，只要满足库存够，支付金额够就可以了，那么我们就可以将核心业务与其他耗时业务分离，进行异步操作，在用户下单完成后再进行耗时操作，并且这些耗时的业务操作即便失败，也有足够的时间与条件去做处理，并不影响用户体验。 削峰每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。 一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。 但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。 如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。 这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。 我： 在我的系统中并不需要考虑这个问题，基于我所做的系统最高的并发量也不足5k，所以几乎不存在削峰的问题，但是由于我使用的是学生服务器搭载，所以实际承受能力也较低，在使用jmeter压力测试时有相应测试，效果良好。 消息队列有什么优缺点优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。 缺点有以下几个： 系统可用性降低系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以点击这里查看。 系统复杂度提高硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。 一致性问题A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。 所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。 Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？ 特性 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，比 RocketMQ、Kafka 低一个数量级 同 ActiveMQ 10 万级，支撑高吞吐 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic 数量对吞吐量的影响 topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 时效性 ms 级 微秒级，这是 RabbitMQ 的一大特点，延迟最低 ms 级 延迟在 ms 级以内 可用性 高，基于主从架构实现高可用 同 ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到 0 丢失 同 RocketMQ 功能支持 MQ 领域的功能极其完备 基于 erlang 开发，并发能力很强，性能极好，延时很低 MQ 功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.octber.xyz/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.octber.xyz/tags/RabbitMQ/"}]},{"title":"2019.9.10日报","slug":"2019-9-10日报","date":"2019-09-10T01:56:55.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/10/2019-9-10日报/","link":"","permalink":"http://www.octber.xyz/2019/09/10/2019-9-10%E6%97%A5%E6%8A%A5/","excerpt":"前言[TOC]","text":"前言[TOC] 1. 任务与任务进度/工时说明 测试发现问题与及时解决 1.1 [重构] 销售渠道对接信息 问题描述: dev中引用bgb的服务 解决方案: 将接口转移到bgb中,前端引用bgb中的服务 解决进度: 100% 1.2 [新页面] 分红(强赎/强增强减)流水查询 任务描述: 三个Tab页,显示三个查询页面 进度: 100% 1.3 [测试] 资金调整及复核 发现问题: 数据库表date字段不应该为主键-&gt;已解决 工作流提交应该全部放在后端处理,不应该在前端处理 进度: 100% 2. 已解决的问题 1.1 [重构] 销售渠道对接信息 1.2 [新页面] 分红(强赎/强增强减)流水查询 1.3 [测试] 资金调整及复核 3. 未解决的问题无 4. 进度延迟原因说明5. 分红(强赎,强增强减)流水查询 备注: 字段对应关系,以便于前端准确显示 5.1 分红查询 部门编号 company_id 部门简称 company_name 部门全称 company_name 导入日期 create_time_stamp 销售渠道 agency_code-&gt;agency_name TA确认编号 ta_serial_id 确认日期 date 权益登记日 equity_reg_date 除权日 xr_date 分红日/发放日 dividend_date 到账日 cash_date 基金代码 fund_code 基金编号 fund_id 基金名称 fund_name 交易账户 fund_trade_account 基金账户 fund_account 红利/红利再投资基数(登记份额) reg_share 分红方式 bonus_type DefDividendMethod0-红利转投1-现金分红 基金账户红利再投资基金份数（含冻结）dicidend_share 冻结再投资份额 frozen_shares 基金账户红利资金（含冻结）dividend_bala 每笔交易确认金额 confirmed_amount 手续费 charge 5.2 强赎 部门编号 部门简称 部门全称 导入日期 date 销售渠道 agency_code-&gt;agency_name 确认日期 transaction_cfmdate TA确认编号 ta_serialno 业务类型: 强赎 到账日 cash_date 基金代码 fund_id 基金名称 fund_name 交易账户 fund_trade_account 基金账户 fund_account 确认份额 confirmed_vol 确认金额 confirmed_amount 手续费 charge 净值 nav 5.3 强增强减 部门编号 部门简称 部门全称 导入日期 销售渠道 确认日期 TA确认编号 ta_serialno 业务类型: 强增强减 基金代码 基金名称 交易账户 基金账户 确认份额 手续费 净值","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.9.9日报","slug":"2019-9-9日报","date":"2019-09-09T12:40:19.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/09/2019-9-9日报/","link":"","permalink":"http://www.octber.xyz/2019/09/09/2019-9-9%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.9.9日报 [TOC]","text":"前言2019.9.9日报 [TOC] 1. 任务与任务进度/工时说明1.1 销售渠道对接信息管理 内容： 一览、增加、删除、详情、修改 进度： 100% 1.2 发现Bug并解决 通过和涛哥确认，发现并解决资金复核中存在的问题 公司树查询接口位置迁移 修改销售渠道和销售渠道对接信息相关companyId的操作 进度： 100% 2. 已解决的问题1.1 销售渠道对接信息管理3. 未解决的问题4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"Redis-从接触到上瘾","slug":"Redis-从接触到上瘾","date":"2019-09-08T03:31:35.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/08/Redis-从接触到上瘾/","link":"","permalink":"http://www.octber.xyz/2019/09/08/Redis-%E4%BB%8E%E6%8E%A5%E8%A7%A6%E5%88%B0%E4%B8%8A%E7%98%BE/","excerpt":"前言 接触Redis也有一年多了，很多项目中也很方便的使用到，可以说Redis确实十分的方便，不需要自定义SQL语句，就可以完成自动化的键值对储存与高效的使用，可以说是开箱即用，使用过后我们还需要对Redis有一个深入的理解，今天就来做一个总结。","text":"前言 接触Redis也有一年多了，很多项目中也很方便的使用到，可以说Redis确实十分的方便，不需要自定义SQL语句，就可以完成自动化的键值对储存与高效的使用，可以说是开箱即用，使用过后我们还需要对Redis有一个深入的理解，今天就来做一个总结。 什么是Redis，他有什么优缺点？ Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。 因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能。 比方说用他的List来做FIFO双向链表，实现一个轻量级的高性能消息队列服务，用他的Set可以做高性能的tag系统等等。 另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis相比memcached有哪些优势？ (1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 (2) redis的速度比memcached快很多 (3) redis可以持久化其数据 Redis支持哪几种数据类型？ String、List、Set、Sorted Set、hashes Redis主要消耗什么物理资源？ 内存 Redis的全称是什么？ Remote Dictionary Server。 Redis有哪几种数据淘汰策略？ noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外） allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。 volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。 allkeys-random: 回收随机的键使得新添加的数据有空间存放。 volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。 volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。 Redis官方为什么不提供Windows版本？ 因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。 一个字符串类型的值能存储最大容量是多少？ 512M 为什么Redis需要把所有数据放到内存中？ Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。 所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。 在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 Redis集群方案应该怎么做？都有哪些方案？1.codis 目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。 2.redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。 3.在业务代码层实现几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。 Redis集群方案什么情况下会导致整个集群不可用？ 有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。 MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？ redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。 Redis有哪些适合的场景？（1）会话缓存（Session Cache） 最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 （2）全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 （3）队列 Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 （4）排行榜/计数器 Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。 所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 （5）发布/订阅 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！ Redis支持的Java客户端都有哪些？官方推荐用哪个？ Redisson、Jedis、lettuce等等，官方推荐使用Redisson。 Redis和Redisson有什么关系？ Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。 Jedis与Redisson对比有什么优缺点？ Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持； Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。 Redis如何设置密码及验证密码？ 设置密码：config set requirepass 123456 授权密码：auth 123456 说说Redis哈希槽的概念？ Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。 Redis集群的主从复制模型是怎样的？ 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品. Redis集群会有写操作丢失吗？为什么？ Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。 Redis集群之间是如何复制的？ 异步复制 Redis集群最大节点个数是多少？ 16384个 Redis集群如何选择数据库？Redis集群目前无法做数据库选择，默认在0数据库。 怎么测试Redis的连通性？ping Redis中的管道有什么用？ 一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。 这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多POP3协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。 怎么理解Redis事务？ 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 Redis事务相关的命令有哪几个？ MULTI、EXEC、DISCARD、WATCH Redis key的过期时间和永久有效分别怎么设置？ EXPIRE和PERSIST命令。 Redis如何做内存优化？ 尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。 比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面。 Redis回收进程如何工作的？ 一个客户端运行了新的命令，添加了新的数据。 Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。 一个新的命令被执行，等等。 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。 如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://www.octber.xyz/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.octber.xyz/tags/Redis/"}]},{"title":"2019.9.6-7日报","slug":"2019-9-7日报","date":"2019-09-06T09:22:12.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/06/2019-9-7日报/","link":"","permalink":"http://www.octber.xyz/2019/09/06/2019-9-7%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.9.5日报 [TOC]","text":"前言2019.9.5日报 [TOC] 1. 任务与任务进度/工时说明 学习操作流的流程和操作标识使用方法 1.1 资金调整 内容： 添加操作标识控制、添加工作流、写一个详情页 进度： 100% 1.2 资金复核 内容： 添加操作标识控制、添加工作流、复用一个详情页 进度： 100% 2. 已解决的问题任务中问题全部解决 3. 未解决的问题4. 进度延迟原因说明5. 操作标识、工作流5.1 操作标识JSON 对应编号、路由、标识名等 123456789101112131415161718192021222324file: OTC_TOPERATEFLAG.json&#123; &quot;company_id&quot;: 0, &quot;use_flag&quot;: &quot;1&quot;, &quot;am4_operate_flag&quot;: 451001, &quot;am4_operate_caption&quot;: &quot;复核详情&quot;, &quot;show_order&quot;: 1, &quot;data_method&quot;: &quot;show&quot;, &quot;operator_mode&quot;: &quot;1&quot;, &quot;group_caption&quot;: &quot;业务操作&quot;, &quot;subsys_no&quot;: 3345, &quot;is_process&quot;: 1, &quot;am4_operate_caption_eng&quot;: &quot;show&quot;, &quot;url&quot;: &quot;/otc/adjustAndReview/adjustFund/edit&quot;, &quot;business_type&quot;: &quot;&quot;, &quot;icon&quot;: &quot;&quot;, &quot;is_operate_button&quot;: &quot;1&quot; &#125;file: OTC_TOPERATEFORMENU.json&#123; &quot;company_id&quot;: 0, &quot;am4_operate_flag&quot;: 451001, &quot;menu_code&quot;: &quot;080405&quot;&#125; 5.2 操作标识配置 清空对应system表，运行项目，导入数据库 “基础组-操作标志流程配置”中进行“分配流程”（工作流模板需要建立） “基础柱-用户管理”中进行权限配置操作标志 5.3 前端逻辑 混入 1234import queryGrid from &#x27;@/mixins/querygrid&#x27;;import gridPage from &#x27;@/mixins/gridpage&#x27;;...mixins: [queryGrid, gridPage],","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.9.5日报","slug":"2019-9-5日报","date":"2019-09-05T12:47:39.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/05/2019-9-5日报/","link":"","permalink":"http://www.octber.xyz/2019/09/05/2019-9-5%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.9.5日报 [TOC]","text":"前言2019.9.5日报 [TOC] 1. 任务与任务进度/工时说明 信息查询 模块基本完成，剩余部分小细节适当调整即可 1.1 持仓份额查询（修改） 内容: 修改页面样式、后台查询逻辑重构（之前的后台逻辑bug） 进度: 100% 1.2 账户申请查询（复用与调整） 内容: 复用之前的页面并修改检索条件与表格列 进度: 100% 1.3 交易申请查询 内容: 有前端页面可以复用一部分，增添部门检索项，重写后端接口 进度: 100% 1.4 交易确认查询 内容: 无可复用页面，完成确认查询任务 进度: 100% 1.5 资金复核 内容: 重构前端页面，并使用工作流与操作标识控制 进度: 20% 1.6 账户类业务申报记录（调整与修改） 内容: 使用工作流、操作标识，与账户申请查询做复用调整 进度: 100% 2. 已解决的问题任务中问题全部解决 3. 未解决的问题 资金复核工作流和操作标识方面 4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.9.3日报","slug":"2019-9-3日报","date":"2019-09-03T12:17:51.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/03/2019-9-3日报/","link":"","permalink":"http://www.octber.xyz/2019/09/03/2019-9-3%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.9.3日报 [TOC]","text":"前言2019.9.3日报 [TOC] 1. 任务与任务进度/工时说明1.1 协助杨鑫进行工作流相关任务1.2 资金调整逻辑修改 备注: 由之前的不需要复核，到需要复核 进度: 100% 1.3 资金复核页面 备注: 差工作流方面调整 进度: 80% 1.4 行情转换机调整 备注: 按照最新要求修改 进度: 100% 2. 已解决的问题任务中问题全部解决 3. 未解决的问题 资金复核工作流方面 4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.9.2日报","slug":"2019-9-2日报","date":"2019-09-02T12:25:28.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/09/02/2019-9-2日报/","link":"","permalink":"http://www.octber.xyz/2019/09/02/2019-9-2%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.30日报 [TOC]","text":"前言2019.8.30日报 [TOC] 1. 任务与任务进度/工时说明1.1 市场信息测试 进度：100% 1.2 账号信息、开户等继续测试 进度: 发现的均已解决 100% 1.3 资金复核 前端完成一半 进度：20% 2. 已解决的问题任务中问题全部解决 周会提出的问题：页面样式 开户流程测试 转换及任务信息记录 3. 未解决的问题 资金复核 4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.31日报","slug":"2019-8-31日报","date":"2019-08-31T01:04:17.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/31/2019-8-31日报/","link":"","permalink":"http://www.octber.xyz/2019/08/31/2019-8-31%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.30日报 [TOC]","text":"前言2019.8.30日报 [TOC] 1. 任务与任务进度/工时说明1.1 写过的所有页面样式调优 解决周会上提到的问题：按照模板的样式为参考对页面样式进行调整，保持一致。 进度：100% 1.2 开户流程测试发现问题与解决 备注: 与杨鑫针对开户过程中发现的问题讨论，并及时修复Bug 进度: 发现的均已解决 100% 1.3 转换机任务中信息记录JobExcute修改 经过邓斯对这块内容的封装调整，修改对应代码 进度：100% 1.4 学习专业名词 抽时间看看一些专业名词，结合业务流程，加深理解 2. 已解决的问题任务中问题全部解决 周会提出的问题：页面样式 开户流程测试 转换及任务信息记录 3. 未解决的问题4. 进度延迟原因说明5. 【学习记录】积累专业词汇5.1 持仓在实物交割或者现金交割到期之前，投资者可以根据市场行情和个人意愿，自愿地决定买入或卖出期货合约。而投资者（做多或做空）没有作交割月份和数量相等的逆向操作（卖出或买入），持有期货合约，则称之为“持仓”。在黄金等商品期货操作中，无论是买还是卖，凡是新建头寸都叫建仓。操作者建仓之后手中就持有头寸，这就叫持仓。 在期货交易中，无论是买还是卖，凡是新建头寸都叫开仓。交易者建仓之后手中就持有头寸，这就叫持仓。 对于持仓量的算法，国内是这样计算的，持仓量的增加代表资金流入期货市场，反之，代表资金流出期货市场。对价格的影响要结合成交量一起分析。 5.2 交割交割是结算过程中，投资者与证券商之间的资金结算。沪深两市除B股外的上市交易证券（A股、基金、债券），都实行T+1交割制度。T+1制度是指当日买入的股票不能在当日卖出，资金收付与证券交割只能在成交日的下一个营业日进行，不能在当日从帐户中提取现金。 新旧交替时结清手续;移交 买卖双方结清手续 [1 投资者应注意的是，T+1制度当日买入的证券当日不能卖出，而当日卖出的股票是可以买入的。 投资者进行证券委托买卖以后，应及时办理交割手续，如发现有疑问,可在一定期限内（一般为3天），向证券营业部提出质疑。对于因此而产生的损失，如果证据确凿，理由充分，完全可以要求证券营业部进行赔偿。 交易双方过户交易货币的所有权的实际交付行为。 交割概念来源于期货实物交割现金交割 交割单是用来记录交割的具体交易情况的单据. 5.2.1 实物交割是指期货合约的买卖双方于合约到期时，根据交易所制订的规则和程序，通过期货合约标的物的所有权转移，将到期未平仓合约进行了结的行为。商品期货交易一般采用实物交割的方式。 5.2.2 现金交割是指到期未平仓期货合约进行交割时，用结算价格来计算未平仓合约的盈亏，以现金支付的方式最终了结期货合约的交割方式。这种交割方式主要用于金融期货等期货标的物无法进行实物交割的期货合约，如股票指数期货合约等。国外一些交易所也探索将现金交割的方式用于商品期货。我国商品期货市场不允许进行 现金交割。 5.2.3 交割方式 T+1交割：是指达成交易后，相应的资金交收与证券交收在成交日的下一个营业日（T+1）完成。目前我国的A股、基金券、债券等采用这种交收方式。 T+3交割：目前我国对B股（人民币特种股票）实行T+3交割交收方式。 为了保证到期合约交割的顺利进行，要求在交割时客户交易账户必须留有足够交割的保证金。因此采取自最后交易日的前五个交易日起，以每个交易日10%的幅度，逐日递增。 客户持仓保证金，直至最后交易日为止。这个时间区域称作交割保证金追加期，简称交割期。 附注：最后交易日：进入交割月合约最后允许交易的交易日，规定为每自然月的最后一个交易日。 T+0交割:实时交易 并非股市的撮合交易，只要想成交就以现价成交，没有时间的限制 没有等待成交的被动的情况出现。当天不限次数，不用等到第二天，当天可以连续操作超短。 5.2.4 交割主体对于“交割”，只有法人也就是企业，才有资格进行保值、交割，对于一般个人，只能选择投机。 5.2.5 交割月份交割月份是交易人在期货到期时按照合约规定交出或接受证券的月份。一般地，交割月份的第一个交易日被指定为第一通知日。从这一天开始，买者会随时收到一张交收通知单。当买者收到通知单时，即要付出合约款项。有的交易所允许买卖双方在交割月份的任意一天交割。若买者抢着在第一个通知日收货时，可能造成价格上升;反之，若卖者抢着在第一个通知日交货，可能造成买客匆忙回吐和价格下跌。 5.3 期货合约 期货合约是指由期货交易所统一制定的、规定在将来某一特定的时间和地点交割一定数量和质量商品的标准化合约。 期货合约是买方同意在一段指定时间之后按特定价格接收某种资产，卖方同意在一段指定时间之后按特定价格交付某种资产的协议。双方同意将来交易时使用的价格称为期货价格。双方将来必须进行交易的指定日期称为结算日或交割日。双方同意交换的资产称为“标的”。如果投资者通过买入期货合约（即同意在将来日期买入）在市场上取得一个头寸，称多头头寸或在期货上做多。相反，如果投资者取得的头寸是卖出期货合约（即承担将来卖出的合约责任），称空头头寸或在期货上做空。 5.4 头寸 头寸（position）也称为“头衬”就是款项的意思，是金融界及商业界的流行用语。头寸指投资者拥有或借用的资金数量。 头寸是一种市场约定，承诺买卖合约的最初部位，买进合约者是多头，处于盼涨部位；卖出合约者为空头，处于盼跌部位。 如果银行在当日的全部收付款中收入大于支出款项，就称为“多头寸”，如果付出款项大于收入款项，就称为“缺头寸”。对预计这一类头寸的多与少的行为称为”轧头寸”。到处想方设法调进款项的行为称为“调头寸”。如果暂时未用的款项大于需用量时称为“头寸松”，如果资金需求量大于闲置量时就称为“头寸紧”。 [1] 头寸是金融行业常用到的一个词，在金融、证券、股票、期货交易中经常用到。 比如在期货交易中建仓时,买入期货合约后所持有的头寸叫多头头寸,简称多头;卖出期货合约后所持有的头寸叫空头头寸,简称空头。商品未平仓多头合约与未平仓空头合约之间的差额就叫做净头寸。只是在期货交易中有这种做法，在现货交易中还没有这种做法。 5.5 期货交易 期货交易的全过程可以概括为建仓、持仓、平仓或实物交割 5.6 平仓平仓是源于商品期货交易的一个术语，指的是期货买卖的一方为对销以前买进或卖出的期货合约而进行的成交行为。平仓是在股票交易中，多头将所买进的股票卖出，或空头买回所卖出股票行为的统称。 6 《开放式基金业务数据交换协议》阅读6.1 协议范围本标准规定了场外开放式基金、证券公司大集合产品（文中简称“基金”）相关业务中机构之间进行数据交换时所采用的数据格式、数据定义和数据内容，证券期货经营机构管理的其它资管产品、私募基金相关业务可参照本标准进行数据交换。资管产品在沪深证券交易所场内数据交换参照交易所相关规定。 笔记： 场外基金： 普通开放基金都属于场外基金，也就是每天只有一个净值作为申购赎回的价格。而封闭，LOF ETF这些基金是场内交易基金，她的价格跟股票一样，盘中随时在变化。场外就理解成为股票交易市场外,就是银行、证券公司的代销,基金公司的直销方式,也就是熟悉的开放式基金销售渠道。 场内基金 和场外申购一样，场内购买（买入）的也可以分红，但是有一点区别，场内购买的基金分红只能是现金分红，不能红利再投入，场外的可以红利再投入。可以赎回的，在场内购买的基金，也可以在场内赎回，赎回价格以收市后公司公布的当天净值为赎回价格。买入（股票方式）与申购（基金方式），卖出与赎回不同。 注意选择你的交易方式，以及选择基金的正确代码，如：510880交易是场内市价，510881是净值申购 LOF基金与ETF基金,即能在场内交易,也能在场外进行申购和赎回。 TODO：场内场外的区别单独记录一篇学习日志吧 6.2 术语及定义 基金业务当事人 fund business party 与基金业务处理的相关的所有机构与个人。 基金发起人 fund founder-member 以基金的成立为目的，并按照规定的设立条件和程序设立基金的机构。 基金管理人 fund manager 依法从事投资基金管理的基金管理公司。 基金托管人 fund custodian 依法保管基金资产、监督管理人投资活动的机构。 注册（过户）登记人 transfer agent 负责基金投资人账户保管、交易记录保存、代理分红、投资人账户报告、登记基金份数等服务的机构，简称TA。 笔记： TA账户：TA的英文是Transfer Agent（过户代理），直译就是过户登记的意思。TA基金账户可通过基金代理机构开立，是注册与过户登记机构为投资者开立的用于记录投资者持有基金份额及其变动情况的账户。 基金交易账户： 基金交易账户是银行为投资者设立的用于在本行进行基金交易的账户。投资者通过银行代销网点办理基金业务时，必须先开立基金交易账户。该账户用于记载投资者进行基金交易活动的情况和所持有的基金份额。每个投资者只能申请开立一个基金交易。 关系： 1个投资者在一家基金管理公司只有1个TA账户，但是可以有多个交易账户，比如在农行开一个，在某证券公司开一个，2个交易账户都可以进行买卖交易，也可 以将基金从一个交易账户转到另一个交易账户，就是所谓的转托管。TA账户和交易账户是多对多的关系。1个投资者在银行只有一个交易账户，但是可以买多个基 金公司的基金，这时是1个交易账户 vs 多个TA账户。 再比如您要购买一个基金公司下属的某个基金的话，首先要开通基金交易账户，这个账户也可以在银行开通，是用来基金交易划拨资金的；其次您要开通该基金公司的TA账户，才可以购买其下属的基金一个基金公司一般有下属好多个基金，您只需要开通一次TA账户就可以购买下属所有基金，如A基金，您只需开通一下A基金公司的TA账户。 基金持有人 fund holder 持有证券投资基金份数的投资人。 基金销售人 fund saler 销售基金的法人或自然人。 业务种类 business type 基金业务处理中的所涉及到的业务类型。 基金账户 transfer agent account 注册登记人为基金投资人设立的基金账户，用于记录和保存持有人的基金单位份数。 开户 open an account 基金投资人申请设立注册登记基金账户的业务。 认购 subsribe 投资人在基金募集期间申请购买该基金的行为。 笔记： 认购是申请购买基金单位的行为。现以基金举例：在基金成立前的发行募集期内申请购买基金单位可以认购，购买价格为基金单位价格。 简单来说，就是基金还没成立，就申请要买了。 和申购的区别： 认购和申购都是申请购买基金单位的行为，其区别在于购买行为发生的时间框架和购买价格：在基金成立前的发行募集期内申请购买基金单位叫认购，购买价格为基金单位价格；在基金成立后申请购买基金单位叫申购，购买价格为当日基金单位净值。 申购 buy 投资人申请购买已经成立的基金的行为。基金管理人接到投资人的购买申请时，应按当日公布的基金份数净资产加减必要费用予以成交，基金托管人按规定与基金管理人办理交割与清算手续，注册登记人增加投资人账户的基金数量和基金的资产。 赎回 redeem 基金持有人申请基金管理人买回该投资人已购其管理的基金的行为。接到基金持有人赎回请求时，基金管理人应按当日公布的基金份数净资产加减必要费用予以成交，基金托管人按规定与基金管理人办理交割与清算手续，在规定期限内向基金持有人支付赎回资金，注册登记人减少基金持有人账户基金份数和基金的资产。 巨额赎回 vastly redeem 在基金的单个开放日，基金净赎回申请超过该基金总份数的一定比例时，就是巨额赎回。 预约赎回 preengage redeem 基金持有人为给基金管理人一定的时间办理赎回业务而提前发出的在未来某日赎回的申请。 分红 dividend 按基金契约的规定，基金管理人在每个会计年度将基金运作所得收益按一定的比例分配给基金持有人的行为。 登记日 register date 登记基金持有人按其所持基金享受基金分红权利的时点。 红利发放日 dividend date 向基金持有人拨付红利款项的日期。 红利再投资 dividend reinvestment 基金持有人将所持基金分得的现金红利自动申请转为持有该基金单位的投资活动。 非交易过户 transfer 基金赠与、继承、协助执行司法判决等有双方参与且涉及基金单位数量变化的过户业务。 基金转换 fund conversion 基金管理人向基金持有人提供的一种服务，即将基金持有人的某只基金转换为另一只基金的服务。 基金信息 fund information 有关基金本身的特征信息。 基金单位资产净值 net asset value 基金开放日闭市后基金资产净值除以当日基金单位的余额数量。 申购费 buy charge 投资人申购基金单位所需支付的费用。 赎回费 redemption charge 投资人赎回基金单位时所支付的费用。 账户管理费 account management charge 基金管理人向投资人收取的用于管理维护投资人基金账户的费用。 注册登记费 transfer agent charge 注册登记代理人根据“注册登记代理协议”向基金管理人收取的费用。 尾随佣金 rake-off 基金管理人给与基金代理销售人的销售业绩报酬。","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.30日报","slug":"2019-8-30日报","date":"2019-08-30T08:30:53.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/30/2019-8-30日报/","link":"","permalink":"http://www.octber.xyz/2019/08/30/2019-8-30%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.30日报 [TOC]","text":"前言2019.8.30日报 [TOC] 1. 任务与任务进度/工时说明1.1 账号类业务申报记录 进度: 100% 1.2 业务基础-账户管理-账号维护测试 备注: 这块流程比较多 进度: 50% 2. 已解决的问题任务中问题全部解决 账号类业务申报记录 测试任务 3. 未解决的问题 测试任务部分未完成 4. 进度延迟原因说明 账号类业务申报记录详情页重写了后台接口和前端页面，改动较大，详情页比较麻烦。","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.29日报","slug":"2019-8-29日报","date":"2019-08-29T08:56:43.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/29/2019-8-29日报/","link":"","permalink":"http://www.octber.xyz/2019/08/29/2019-8-29%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.29日报 [TOC]","text":"前言2019.8.29日报 [TOC] 1. 任务与任务进度/工时说明1.1 业务基础-账户管理-产品单元组合测试 进度: 100% 1.2 业务基础-账户管理-账号类业务申报记录测试 进度: 100% 1.3 【修改页面】账号类业务申报记录 进度: 60% 2. 已解决的问题任务中问题全部解决 测试文档编写 账号类业务申报记录 3. 未解决的问题 账号类业务申报记录详情弹窗 4. 进度延迟原因说明 测试任务看的久了一点，撰写文档比较费时间 5. [备注]账户类业务申报记录5.1 表格列与数据库对应 申请日期: 场外代销账户类申报表bgb_tagentaccountapp.date 确认日期: 场外代销账户类确认结果表bgb_tagentaccoutconfirm.date 订单编号: bgb_tagentaccountapp.otc_report_seq 复核状态: bgb_tagentaccountapp.status 字典表607051:未报2:待报3:正报4:已报5:申报成功6:申报失败7:部分申报成功8:确认有效（查询到正常返回基金账号后的状态）9:确认失败（查询基金账号的结果TA返回错误信息时的状态） 订单状态: 暂时没有 业务类型: bgb_tagentaccountapp.Busin_type 字典项目：61093 001:开立基金账户 （要用到）002:注销基金账户（要用到）003:账户信息修改（要用到）008:登记基金账户009:增开基金账户（要用到）101:开立基金账户确认102:注销基金账户确认103:账户信息修改确认108:登记基金账户确认109:增开基金账户确认 产品代码: bgb_tagentaccountapp.fund_id 产品简称: bgb_tagentaccountapp.fund_name 销售渠道: bgb_tagentaccountapp.agency_code 交易账号: bgb_tagentaccountapp.fund_trade_account 基金账号: bgb_tagentaccountapp.fund_account TA代码: bgb_tagentaccountapp.ta_code","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.28日报","slug":"2019-8-28日报","date":"2019-08-28T12:36:54.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/28/2019-8-28日报/","link":"","permalink":"http://www.octber.xyz/2019/08/28/2019-8-28%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.27日报 [TOC]","text":"前言2019.8.27日报 [TOC] 1. 任务与任务进度/工时说明1.1 业务基础-人员管理-法人信息测试 进度: 100% 1.2 业务基础-人员管理-经办人信息测试 进度: 100% 1.3 业务基础-账户管理-对手方银行账户信息测试 进度: 100% 1.4 初始化Fisp银行信息插入 生成JSON并在bgb启动时检测系统版本做插入操作 进度: 100% 1.5 行情转换机任务JobExcute记录 邓斯修改了JobExcute消息记录，方式用到的地方都需要修改 进度: 100% 2. 已解决的问题任务中问题全部解决 测试文档编写 初始化Fisp银行信息JSON生成代码与插入操作 3. 未解决的问题无未解决问题 4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.27日报","slug":"2019-8-27日报","date":"2019-08-27T01:00:38.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/27/2019-8-27日报/","link":"","permalink":"http://www.octber.xyz/2019/08/27/2019-8-27%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.27日报 [TOC]","text":"前言2019.8.27日报 [TOC] 1. 任务与任务进度/工时说明 今天提出与测试中发现的问题均已解决 1.1 场外-信息查询-产品信息查询测试 进度: 100% 1.2 业务基础-产品管理-产品信息测试 进度: 100% 1.3 业务基础-账户管理-fisp银行编码测试 进度: 100% 1.4 初始化场外业务类别表初始化插入 生成JSON并在otc启动时检测系统版本做插入操作 进度: 100% 2. 已解决的问题任务中问题全部解决 测试文档编写 初始化初始化场外业务类别JSON生成代码与插入操作 3. 未解决的问题无未解决问题 4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.26日报","slug":"2019-8-26日报","date":"2019-08-26T01:09:51.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/26/2019-8-26日报/","link":"","permalink":"http://www.octber.xyz/2019/08/26/2019-8-26%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.26日报 [TOC]","text":"前言2019.8.26日报 [TOC] 1. 任务与任务进度/工时说明 今天提出与测试中发现的问题均已解决 1.1 [BUG]行情转换机重复状态 进度: 100% 1.2 资金调整前端重构/后端查询逻辑 进度: 100% 1.3 增开基金账户 问题: 增开时哪些信息要入库确认 进度: 100% 1.4 份额调整/份额查询 问题: 前端/后端分页中由于对源码功能了解不足出现分页错误问题 进度: 100% 1.5 其他问题 问题: 如日期统一使用DateUtils等 进度: 100% 2. 已解决的问题任务中问题全部解决 3. 未解决的问题无未解决问题 4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.24日报","slug":"2019-8-24日报","date":"2019-08-24T01:14:19.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/24/2019-8-24日报/","link":"","permalink":"http://www.octber.xyz/2019/08/24/2019-8-24%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.24日报 [TOC]","text":"前言2019.8.24日报 [TOC] 1. 任务与任务进度/工时说明 今天改bug，改行情转换机 1.1 行情转换机问题 调整字段 添加分页 1.2 资产调整问题 2. 已解决的问题1.1 行情转换机1.2 资产调整（部分）3. 未解决的问题4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"volatile简析","slug":"volatile简析","date":"2019-08-23T06:27:05.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/23/volatile简析/","link":"","permalink":"http://www.octber.xyz/2019/08/23/volatile%E7%AE%80%E6%9E%90/","excerpt":"前言volatile简析，这个关键字虽然在多线程中起到了重要的作用而且使用便捷，但是真正了解他还是很难的 学习这位大神: HollisChuang","text":"前言volatile简析，这个关键字虽然在多线程中起到了重要的作用而且使用便捷，但是真正了解他还是很难的 学习这位大神: HollisChuang 本文就围绕volatile展开，主要介绍volatile的用法、volatile的原理，以及volatile是如何提供可见性和有序性保障的等。 volatile这个关键字，不仅仅在Java语言中有，在很多语言中都有的，而且其用法和语义也都是不尽相同的。尤其在C语言、C++以及Java中，都有volatile关键字。都可以用来声明变量或者对象。下面简单来介绍一下Java语言中的volatile关键字。 volatile的用法volatile通常被比喻成”轻量级的synchronized“，也是Java并发编程中比较重要的一个关键字。和synchronized不同，volatile是一个变量修饰符，只能用来修饰变量。无法修饰方法及代码块等。 volatile的用法比较简单，只需要在声明一个可能被多线程同时访问的变量时，使用volatile修饰就可以了。 1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 如以上代码，是一个比较典型的使用双重锁校验的形式实现单例的，其中使用volatile关键字修饰可能被多个线程同时访问到的singleton。 volatile的原理在再有人问你Java内存模型是什么，就把这篇文章发给他中我们曾经介绍过，为了提高处理器的执行速度，在处理器和内存之间增加了多级缓存来提升。但是由于引入了多级缓存，就存在缓存数据不一致问题。 但是，对于volatile变量，当对volatile变量进行写操作的时候，JVM会向处理器发送一条lock前缀的指令，将这个缓存中的变量回写到系统主存中。 但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议 缓存一致性协议：每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。 所以，如果一个变量被volatile所修饰的话，在每次数据变化之后，其值都会被强制刷入主存。而其他处理器的缓存由于遵守了缓存一致性协议，也会把这个变量的值从主存加载到自己的缓存中。这就保证了一个volatile在并发编程中，其值在多个缓存中是可见的。 volatile与可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 我们在再有人问你Java内存模型是什么，就把这篇文章发给他中分析过：Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。所以，就可能出现线程1改了某个变量的值，但是线程2不可见的情况。 前面的关于volatile的原理中介绍过了，Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 volatile与有序性有序性即程序执行的顺序按照代码的先后顺序执行。 我们在再有人问你Java内存模型是什么，就把这篇文章发给他中分析过：除了引入了时间片以外，由于处理器优化和指令重排等，CPU还可能对输入代码进行乱序执行，比如load-&gt;add-&gt;save 有可能被优化成load-&gt;save-&gt;add 。这就是可能存在有序性问题。 而volatile除了可以保证数据的可见性之外，还有一个强大的功能，那就是他可以禁止指令重排优化等。 普通的变量仅仅会保证在该方法的执行过程中所依赖的赋值结果的地方都能获得正确的结果，而不能保证变量的赋值操作的顺序与程序代码中的执行顺序一致。 volatile可以禁止指令重排，这就保证了代码的程序会严格按照代码的先后顺序执行。这就保证了有序性。被volatile修饰的变量的操作，会严格按照代码顺序执行，load-&gt;add-&gt;save 的执行顺序就是：load、add、save。 volatile与原子性原子性是指一个操作是不可中断的，要全部执行完成，要不就都不执行。 我们在Java的并发编程中的多线程问题到底是怎么回事儿？中分析过：线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。当一个线程获得时间片之后开始执行，在时间片耗尽之后，就会失去CPU使用权。所以在多线程场景下，由于时间片在线程间轮换，就会发生原子性问题。 在上一篇文章中，我们介绍synchronized的时候，提到过，为了保证原子性，需要通过字节码指令monitorenter和monitorexit，但是volatile和这两个指令之间是没有任何关系的。 所以，volatile是不能保证原子性的。 所以voatitle并不是万能的，要考虑以下两个场景使用 在以下两个场景中可以使用volatile来代替synchronized： 1、运算结果并不依赖变量的当前值，或者能够确保只有单一的线程会修改变量的值。 2、变量不需要与其他状态变量共同参与不变约束。 我们来看一下volatile和原子性的例子： 1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 以上代码比较简单，就是创建10个线程，然后分别执行1000次i++操作。正常情况下，程序的输出结果应该是10000，但是，多次执行的结果都小于10000。这其实就是volatile无法满足原子性的原因。 为什么会出现这种情况呢，那就是因为虽然volatile可以保证inc在多个线程之间的可见性。但是无法inc++的原子性。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"synchronized简析","slug":"synchronized简析","date":"2019-08-23T05:46:14.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/23/synchronized简析/","link":"","permalink":"http://www.octber.xyz/2019/08/23/synchronized%E7%AE%80%E6%9E%90/","excerpt":"前言synchronized简析，这个关键字虽然在多线程中起到了重要的作用而且使用便捷，但是真正了解他还是很难的 学习这位大神: HollisChuang Java语言为了解决并发编程中存在的原子性、可见性和有序性问题，提供了一系列和并发处理相关的关键字，比如synchronized、volatile、final、concurren包等。","text":"前言synchronized简析，这个关键字虽然在多线程中起到了重要的作用而且使用便捷，但是真正了解他还是很难的 学习这位大神: HollisChuang Java语言为了解决并发编程中存在的原子性、可见性和有序性问题，提供了一系列和并发处理相关的关键字，比如synchronized、volatile、final、concurren包等。 synchronized关键字在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案，看起来是“万能”的。的确，大部分并发控制操作都能使用synchronized来完成。 synchronized的用法synchronized是Java提供的一个并发控制的关键字。主要有两种用法，分别是同步方法和同步代码块。也就是说，synchronized既可以修饰方法也可以修饰代码块。 12345678910111213141516/** * @author Hollis 18/08/04. */public class SynchronizedDemo &#123; //同步方法 public synchronized void doSth()&#123; System.out.println(&quot;Hello World&quot;); &#125; //同步代码块 public void doSth1()&#123; synchronized (SynchronizedDemo.class)&#123; System.out.println(&quot;Hello World&quot;); &#125; &#125;&#125; 被synchronized修饰的代码块及方法，在同一时间，只能被单个线程访问。 synchronized的实现原理synchronized，是Java中用于解决并发情况下数据同步访问的一个很重要的关键字。当我们想要保证一个共享资源在同一时间只会被一个线程访问到时，我们可以在代码中使用synchronized关键字对类或者对象加锁。 在深入理解多线程（一）——Synchronized的实现原理中我曾经介绍过其实现原理，为了保证知识的完整性，这里再简单介绍一下，详细的内容请去原文阅读。 我们对上面的代码进行反编译，可以得到如下代码： 12345678910111213141516171819202122232425262728293031public synchronized void doSth(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String Hello World 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return public void doSth1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: ldc #5 // class com/hollis/SynchronizedTest 2: dup 3: astore_1 4: monitorenter 5: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #3 // String Hello World 10: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: aload_1 14: monitorexit 15: goto 23 18: astore_2 19: aload_1 20: monitorexit 21: aload_2 22: athrow 23: return 通过反编译后代码可以看出：对于同步方法，JVM采用ACC_SYNCHRONIZED标记符来实现同步。 对于同步代码块。JVM采用monitorenter、monitorexit两个指令来实现同步。 在The Java® Virtual Machine Specification中有关于同步方法和同步代码块的实现原理的介绍，我翻译成中文如下： 方法级的同步是隐式的。同步方法的常量池中会有一个ACC_SYNCHRONIZED标志。当某个线程要访问某个方法的时候，会检查是否有ACC_SYNCHRONIZED，如果有设置，则需要先获得监视器锁，然后开始执行方法，方法执行之后再释放监视器锁。这时如果其他线程来请求执行方法，会因为无法获得监视器锁而被阻断住。值得注意的是，如果在方法执行过程中，发生了异常，并且方法内部并没有处理该异常，那么在异常被抛到方法外面之前监视器锁会被自动释放。 同步代码块使用monitorenter和monitorexit两个指令实现。可以把执行monitorenter指令理解为加锁，执行monitorexit理解为释放锁。 每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0，当一个线程获得锁（执行monitorenter）后，该计数器自增变为 1 ，当同一个线程再次获得该对象的锁的时候，计数器再次自增。当同一个线程释放锁（执行monitorexit指令）的时候，计数器再自减。当计数器为0的时候。锁将被释放，其他线程便可以获得锁。 无论是ACC_SYNCHRONIZED还是monitorenter、monitorexit都是基于Monitor实现的，在Java虚拟机(HotSpot)中，Monitor是基于C++实现的，由ObjectMonitor实现。 ObjectMonitor类中提供了几个方法，如enter、exit、wait、notify、notifyAll等。sychronized加锁的时候，会调用objectMonitor的enter方法，解锁的时候会调用exit方法。（关于Monitor详见深入理解多线程（四）—— Moniter的实现原理） synchronized与原子性原子性是指一个操作是不可中断的，要全部执行完成，要不就都不执行。 我们在Java的并发编程中的多线程问题到底是怎么回事儿？中分析过：线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。当一个线程获得时间片之后开始执行，在时间片耗尽之后，就会失去CPU使用权。所以在多线程场景下，由于时间片在线程间轮换，就会发生原子性问题。 在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。前面中，介绍过，这两个字节码指令，在Java中对应的关键字就是synchronized。 通过monitorenter和monitorexit指令，可以保证被synchronized修饰的代码在同一时间只能被一个线程访问，在锁未释放之前，无法被其他线程访问到。因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。 线程1在执行monitorenter指令的时候，会对Monitor进行加锁，加锁后其他线程无法获得锁，除非线程1主动解锁。即使在执行过程中，由于某种原因，比如CPU时间片用完，线程1放弃了CPU，但是，他并没有进行解锁。而由于synchronized的锁是可重入的，下一个时间片还是只能被他自己获取到，还是会继续执行代码。直到所有代码执行完。这就保证了原子性。 synchronized与可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 我们在再有人问你Java内存模型是什么，就把这篇文章发给他。中分析过：Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。所以，就可能出现线程1改了某个变量的值，但是线程2不可见的情况。 前面我们介绍过，被synchronized修饰的代码，在开始执行时会加锁，执行完成后会进行解锁。而为了保证可见性，有一条规则是这样的：对一个变量解锁之前，必须先把此变量同步回主存中。这样解锁后，后续线程就可以访问到被修改后的值。 所以，synchronized关键字锁住的对象，其值是具有可见性的。 synchronized与有序性有序性即程序执行的顺序按照代码的先后顺序执行。 我们在再有人问你Java内存模型是什么，就把这篇文章发给他。中分析过：除了引入了时间片以外，由于处理器优化和指令重排等，CPU还可能对输入代码进行乱序执行，比如load-&gt;add-&gt;save 有可能被优化成load-&gt;save-&gt;add 。这就是可能存在有序性问题。 这里需要注意的是，synchronized是无法禁止指令重排和处理器优化的。也就是说，synchronized无法避免上述提到的问题。 那么，为什么还说synchronized也提供了有序性保证呢？ 这就要再把有序性的概念扩展一下了。Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有操作都是天然有序的。如果在一个线程中观察另一个线程，所有操作都是无序的。 以上这句话也是《深入理解Java虚拟机》中的原句，但是怎么理解呢？周志明并没有详细的解释。这里我简单扩展一下，这其实和as-if-serial语义有关。 as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），单线程程序的执行结果都不能被改变。编译器和处理器无论如何优化，都必须遵守as-if-serial语义。 这里不对as-if-serial语义详细展开了，简单说就是，as-if-serial语义保证了单线程中，指令重排是有一定的限制的，而只要编译器和处理器都遵守了这个语义，那么就可以认为单线程程序是按照顺序执行的。当然，实际上还是有重排的，只不过我们无须关心这种重排的干扰。 所以呢，由于synchronized修饰的代码，同一时间只能被同一线程访问。那么也就是单线程执行的。所以，可以保证其有序性。 synchronized与锁优化前面介绍了synchronized的用法、原理以及对并发编程的作用。是一个很好用的关键字。 synchronized其实是借助Monitor实现的，在加锁时会调用objectMonitor的enter方法，解锁的时候会调用exit方法。事实上，只有在JDK1.6之前，synchronized的实现才会直接调用ObjectMonitor的enter和exit，这种锁被称之为重量级锁。 所以，在JDK1.6中出现对锁进行了很多的优化，进而出现轻量级锁，偏向锁，锁消除，适应性自旋锁，锁粗化(自旋锁在1.4就有，只不过默认的是关闭的，jdk1.6是默认开启的)，这些操作都是为了在线程之间更高效的共享数据 ，解决竞争问题。 关于自旋锁、锁粗化和锁消除可以参考深入理解多线程（五）—— Java虚拟机的锁优化技术，关于轻量级锁和偏向锁，已经在排期规划中，我后面会有文章单独介绍，将独家发布在我的博客(http://www.hollischuang.com)和公众号(Hollis)中，敬请期待。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"2019.8.23日报","slug":"2019-8-23日报","date":"2019-08-23T05:07:42.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/23/2019-8-23日报/","link":"","permalink":"http://www.octber.xyz/2019/08/23/2019-8-23%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.23日报 [TOC]","text":"前言2019.8.23日报 [TOC] 1. 任务与任务进度/工时说明 今天主要活动是“测试”，和下午参加周会，优化处理了一下之前写的代码，改了一下发现的bug 1.1 开户等功能测试2. 已解决的问题3. 未解决的问题4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"Java内存模型-JMM","slug":"Java内存模型","date":"2019-08-23T05:06:59.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/23/Java内存模型/","link":"","permalink":"http://www.octber.xyz/2019/08/23/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"前言synchronized/volatile浅谈一文中谈到的Java内存模型，简析 学习这位大神: HollisChuang","text":"前言synchronized/volatile浅谈一文中谈到的Java内存模型，简析 学习这位大神: HollisChuang 内存模型的来源 内存模型，英文名Memory Model，他是一个很老的老古董了。他是与计算机硬件有关的一个概念。他的存在和硬件是息息相关的 CPU和缓存一致性我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存。 刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。 可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。 所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。 那么，程序的执行过程就变成了： 当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。 按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L3），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。 这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。 那么，在有了多级缓存之后，程序的执行就变成了： 当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。 单核CPU只含有一套L1，L2，L3缓存；如果CPU含有多个核心，即多核CPU，则每个核心都含有一套L1（甚至和L2）缓存，而共享L3（或者和L2）缓存。 下图为一个单CPU双核的缓存结构： （图片右边是一个形象化的示例） 随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。 单线程。cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。 单核CPU，多线程。进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。 多核CPU，多线程。每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的caehe中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。 在CPU和主存之间增加缓存，在多线程场景下就可能存在缓存一致性问题，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。 处理器优化和指令重排上面提到在CPU和主存之间增加缓存，在多线程场景下会存在缓存一致性问题。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是处理器优化。 除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做指令重排。 可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。 并发编程的问题前面说的和硬件有关的概念你可能听得有点蒙，还不知道他到底和软件有啥关系。但是关于并发编程的问题你应该有所了解，比如原子性问题，可见性问题和有序性问题。 其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。 这里简单回顾下这三个问题，并不准备深入展开，感兴趣的读者可以自行学习。我们说，并发编程，为了保证数据的安全，需要满足以下三个特性： 原子性是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性即程序执行的顺序按照代码的先后顺序执行。 有没有发现，缓存一致性问题其实就是可见性问题。而处理器优化是可以导致原子性问题的。指令重排即会导致有序性问题。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。 什么是内存模型前面提到的，缓存一致性问题、处理器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？ 最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。 所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。 为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。 内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。本文就不深入底层原理来展开介绍了，感兴趣的朋友可以自行学习。 什么是Java内存模型前面介绍过了计算机内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体的实现是如何的呢，不同的编程语言，在实现上可能有所不同。 我们知道，Java程序是需要运行在Java虚拟机上面的，Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。 提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由JSR-133: JavaTM Memory Model and Thread Specification 描述。感兴趣的可以参看下这份PDF文档（http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf） Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。 而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。 这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。 所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。 Java内存模型的实现了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如volatile、synchronized、final、concurren包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。 在开发多线程的代码的时候，我们可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。 本文并不准备把所有的关键字逐一介绍其用法，因为关于各个关键字的用法，网上有很多资料。读者可以自行学习。本文还有一个重点要介绍的就是，我们前面提到，并发编程要解决原子性、有序性和一致性的问题，我们就再来看下，在Java中，分别使用什么方式来保证。 原子性在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。在synchronized的实现原理文章中，介绍过，这两个字节码，在Java中对应的关键字就是synchronized。 因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。 可见性Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。 Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 除了volatile，Java中的synchronized和final两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。 有序性在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别： volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 好了，这里简单的介绍完了Java并发编程中解决原子性、可见性以及有序性可以使用的关键字。读者可能发现了，好像synchronized关键字是万能的，他可以同时满足以上三种特性，这其实也是很多人滥用synchronized的原因。 但是synchronized是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。 总结在读完本文之后，相信你应该了解了什么是Java内存模型、Java内存模型的作用以及Java中内存模型做了什么事情等。关于Java中这些和内存模型有关的关键字，希望读者还可以继续深入学习，并且自己写几个例子亲自体会一下。 可以参考《深入理解Java虚拟机》和《Java并发编程的艺术》两本书。 参考资料cpu缓存与多线程 浅析内存模型 内存模型 和 缓存一致性 并发编程——原子性，可见性和有序性 《深入理解Java虚拟机》","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"内存模型","slug":"内存模型","permalink":"http://www.octber.xyz/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}]},{"title":"Java8的Lambda表达式","slug":"Java8的Lambda表达式","date":"2019-08-22T12:44:49.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/22/Java8的Lambda表达式/","link":"","permalink":"http://www.octber.xyz/2019/08/22/Java8%E7%9A%84Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"前言👉Java8有一个非常显著的优势就是Lambda表达式,下面我们从十个例子来了解一下","text":"前言👉Java8有一个非常显著的优势就是Lambda表达式,下面我们从十个例子来了解一下 例1、用lambda表达式实现Runnable我开始使用Java 8时，首先做的就是使用lambda表达式替换匿名类，而实现Runnable接口是匿名类的最好示例。看一下Java 8之前的runnable实现方法，需要4行代码，而使用lambda表达式只需要一行代码。我们在这里做了什么呢？那就是用() -&gt; {}代码块替代了整个匿名类。 12345678910&#x2F;&#x2F; Java 8之前：new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;Before Java8, too much code for too little to do&quot;); &#125;&#125;).start();&#x2F;&#x2F;Java 8方式：new Thread( () -&gt; System.out.println(&quot;In Java8, Lambda expression rocks !!&quot;) ).start(); 输出： 12too much code, for too little to doLambda expression rocks !! 这个例子向我们展示了Java 8 lambda表达式的语法。你可以使用lambda写出如下代码： 123(params) -&gt; expression(params) -&gt; statement(params) -&gt; &#123; statements &#125; 例如，如果你的方法不对参数进行修改、重写，只是在控制台打印点东西的话，那么可以这样写： 1() -&gt; System.out.println(&quot;Hello Lambda Expressions&quot;); 如果你的方法接收两个参数，那么可以写成如下这样： 1(int even, int odd) -&gt; even + odd 顺便提一句，通常都会把lambda表达式内部变量的名字起得短一些。这样能使代码更简短，放在同一行。所以，在上述代码中，变量名选用a、b或者x、y会比even、odd要好。 例2、使用Java 8 lambda表达式进行事件处理如果你用过Swing API编程，你就会记得怎样写事件监听代码。这又是一个旧版本简单匿名类的经典用例，但现在可以不这样了。你可以用lambda表达式写出更好的事件监听代码，如下所示： 12345678910111213&#x2F;&#x2F; Java 8之前：JButton show &#x3D; new JButton(&quot;Show&quot;);show.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println(&quot;Event handling without lambda expression is boring&quot;); &#125;&#125;);&#x2F;&#x2F; Java 8方式：show.addActionListener((e) -&gt; &#123; System.out.println(&quot;Light, Camera, Action !! Lambda expressions Rocks&quot;);&#125;); Java开发者经常使用匿名类的另一个地方是为 Collections.sort() 定制 Comparator。在Java 8中，你可以用更可读的lambda表达式换掉丑陋的匿名类。我把这个留做练习，应该不难，可以按照我在使用lambda表达式实现 Runnable 和 ActionListener 的过程中的套路来做。 例3、使用lambda表达式对列表进行迭代如果你使过几年Java，你就知道针对集合类，最常见的操作就是进行迭代，并将业务逻辑应用于各个元素，例如处理订单、交易和事件的列表。由于Java是命令式语言，Java 8之前的所有循环代码都是顺序的，即可以对其元素进行并行化处理。如果你想做并行过滤，就需要自己写代码，这并不是那么容易。通过引入lambda表达式和默认方法，将做什么和怎么做的问题分开了，这意味着Java集合现在知道怎样做迭代，并可以在API层面对集合元素进行并行处理。下面的例子里，我将介绍如何在使用lambda或不使用lambda表达式的情况下迭代列表。你可以看到列表现在有了一个 forEach() 方法，它可以迭代所有对象，并将你的lambda代码应用在其中。 12345678910111213&#x2F;&#x2F; Java 8之前：List features &#x3D; Arrays.asList(&quot;Lambdas&quot;, &quot;Default Method&quot;, &quot;Stream API&quot;, &quot;Date and Time API&quot;);for (String feature : features) &#123; System.out.println(feature);&#125;&#x2F;&#x2F; Java 8之后：List features &#x3D; Arrays.asList(&quot;Lambdas&quot;, &quot;Default Method&quot;, &quot;Stream API&quot;, &quot;Date and Time API&quot;);features.forEach(n -&gt; System.out.println(n)); &#x2F;&#x2F; 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示，&#x2F;&#x2F; 看起来像C++的作用域解析运算符features.forEach(System.out::println); 输出： 1234LambdasDefault MethodStream APIDate and Time API 列表循环的最后一个例子展示了如何在Java 8中使用方法引用（method reference）。你可以看到C++里面的双冒号、范围解析操作符现在在Java 8中用来表示方法引用。 例4、使用lambda表达式和函数式接口Predicate除了在语言层面支持函数式编程风格，Java 8也添加了一个包，叫做 java.util.function。它包含了很多类，用来支持Java的函数式编程。其中一个便是Predicate，使用 java.util.function.Predicate 函数式接口以及lambda表达式，可以向API方法添加逻辑，用更少的代码支持更多的动态行为。下面是Java 8 Predicate 的例子，展示了过滤集合数据的多种常用方法。Predicate接口非常适用于做过滤。 1234567891011121314151617181920212223242526public static void main(args[])&#123; List languages &#x3D; Arrays.asList(&quot;Java&quot;, &quot;Scala&quot;, &quot;C++&quot;, &quot;Haskell&quot;, &quot;Lisp&quot;); System.out.println(&quot;Languages which starts with J :&quot;); filter(languages, (str)-&gt;str.startsWith(&quot;J&quot;)); System.out.println(&quot;Languages which ends with a &quot;); filter(languages, (str)-&gt;str.endsWith(&quot;a&quot;)); System.out.println(&quot;Print all languages :&quot;); filter(languages, (str)-&gt;true); System.out.println(&quot;Print no language : &quot;); filter(languages, (str)-&gt;false); System.out.println(&quot;Print language whose length greater than 4:&quot;); filter(languages, (str)-&gt;str.length() &gt; 4);&#125; public static void filter(List names, Predicate condition) &#123; for(String name: names) &#123; if(condition.test(name)) &#123; System.out.println(name + &quot; &quot;); &#125; &#125;&#125; 输出： 123456789101112131415Languages which starts with J :JavaLanguages which ends with aJavaScalaPrint all languages :JavaScalaC++HaskellLispPrint no language :Print language whose length greater than 4:ScalaHaskell 123456&#x2F;&#x2F; 更好的办法public static void filter(List names, Predicate condition) &#123; names.stream().filter((name) -&gt; (condition.test(name))).forEach((name) -&gt; &#123; System.out.println(name + &quot; &quot;); &#125;);&#125; 可以看到，Stream API的过滤方法也接受一个Predicate，这意味着可以将我们定制的 filter() 方法替换成写在里面的内联代码，这就是lambda表达式的魔力。另外，Predicate接口也允许进行多重条件的测试，下个例子将要讲到。 例5、如何在lambda表达式中加入Predicate上个例子说到，java.util.function.Predicate 允许将两个或更多的 Predicate 合成一个。它提供类似于逻辑操作符AND和OR的方法，名字叫做and()、or()和xor()，用于将传入 filter() 方法的条件合并起来。例如，要得到所有以J开始，长度为四个字母的语言，可以定义两个独立的 Predicate 示例分别表示每一个条件，然后用 Predicate.and() 方法将它们合并起来，如下所示： 1234567&#x2F;&#x2F; 甚至可以用and()、or()和xor()逻辑函数来合并Predicate，&#x2F;&#x2F; 例如要找到所有以J开始，长度为四个字母的名字，你可以合并两个Predicate并传入Predicate&lt;String&gt; startsWithJ &#x3D; (n) -&gt; n.startsWith(&quot;J&quot;);Predicate&lt;String&gt; fourLetterLong &#x3D; (n) -&gt; n.length() &#x3D;&#x3D; 4;names.stream() .filter(startsWithJ.and(fourLetterLong)) .forEach((n) -&gt; System.out.print(&quot;nName, which starts with &#39;J&#39; and four letter long is : &quot; + n)); 类似地，也可以使用 or() 和 xor() 方法。本例着重介绍了如下要点：可按需要将 Predicate 作为单独条件然后将其合并起来使用。简而言之，你可以以传统Java命令方式使用 Predicate 接口，也可以充分利用lambda表达式达到事半功倍的效果。 例6、Java 8中使用lambda表达式的Map和Reduce示例本例介绍最广为人知的函数式编程概念map。它允许你将对象进行转换。例如在本例中，我们将 costBeforeTax 列表的每个元素转换成为税后的值。我们将 x -&gt; x*x lambda表达式传到 map() 方法，后者将其应用到流中的每一个元素。然后用 forEach() 将列表元素打印出来。使用流API的收集器类，可以得到所有含税的开销。有 toList() 这样的方法将 map 或任何其他操作的结果合并起来。由于收集器在流上做终端操作，因此之后便不能重用流了。你甚至可以用流API的 reduce() 方法将所有数字合成一个，下一个例子将会讲到。 12345678910&#x2F;&#x2F; 不使用lambda表达式为每个订单加上12%的税List costBeforeTax &#x3D; Arrays.asList(100, 200, 300, 400, 500);for (Integer cost : costBeforeTax) &#123; double price &#x3D; cost + .12*cost; System.out.println(price);&#125; &#x2F;&#x2F; 使用lambda表达式List costBeforeTax &#x3D; Arrays.asList(100, 200, 300, 400, 500);costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).forEach(System.out::println); 输出： 12345678910112.0224.0336.0448.0560.0112.0224.0336.0448.0560.0 例6.2、Java 8中使用lambda表达式的Map和Reduce示例在上个例子中，可以看到map将集合类（例如列表）元素进行转换的。还有一个 reduce() 函数可以将所有值合并成一个。Map和Reduce操作是函数式编程的核心操作，因为其功能，reduce 又被称为折叠操作。另外，reduce 并不是一个新的操作，你有可能已经在使用它。SQL中类似 sum()、avg() 或者 count() 的聚集函数，实际上就是 reduce 操作，因为它们接收多个值并返回一个值。流API定义的 reduceh() 函数可以接受lambda表达式，并对所有值进行合并。IntStream这样的类有类似 average()、count()、sum() 的内建方法来做 reduce 操作，也有mapToLong()、mapToDouble() 方法来做转换。这并不会限制你，你可以用内建方法，也可以自己定义。在这个Java 8的Map Reduce示例里，我们首先对所有价格应用 12% 的VAT，然后用 reduce() 方法计算总和。 1234567891011121314&#x2F;&#x2F; 为每个订单加上12%的税&#x2F;&#x2F; 老方法：List costBeforeTax &#x3D; Arrays.asList(100, 200, 300, 400, 500);double total &#x3D; 0;for (Integer cost : costBeforeTax) &#123; double price &#x3D; cost + .12*cost; total &#x3D; total + price;&#125;System.out.println(&quot;Total : &quot; + total); &#x2F;&#x2F; 新方法：List costBeforeTax &#x3D; Arrays.asList(100, 200, 300, 400, 500);double bill &#x3D; costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println(&quot;Total : &quot; + bill); 输出： 12Total : 1680.0Total : 1680.0 例7、通过过滤创建一个String列表过滤是Java开发者在大规模集合上的一个常用操作，而现在使用lambda表达式和流API过滤大规模数据集合是惊人的简单。流提供了一个 filter() 方法，接受一个 Predicate 对象，即可以传入一个lambda表达式作为过滤逻辑。下面的例子是用lambda表达式过滤Java集合，将帮助理解。 123&#x2F;&#x2F; 创建一个字符串列表，每个字符串长度大于2List&lt;String&gt; filtered &#x3D; strList.stream().filter(x -&gt; x.length()&gt; 2).collect(Collectors.toList());System.out.printf(&quot;Original List : %s, filtered list : %s %n&quot;, strList, filtered); 输出： 1Original List : [abc, , bcd, , defg, jk], filtered list : [abc, bcd, defg] 另外，关于 filter() 方法有个常见误解。在现实生活中，做过滤的时候，通常会丢弃部分，但使用filter()方法则是获得一个新的列表，且其每个元素符合过滤原则。 例8、对列表的每个元素应用函数我们通常需要对列表的每个元素使用某个函数，例如逐一乘以某个数、除以某个数或者做其它操作。这些操作都很适合用 map() 方法，可以将转换逻辑以lambda表达式的形式放在 map() 方法里，就可以对集合的各个元素进行转换了，如下所示。 1234&#x2F;&#x2F; 将字符串换成大写并用逗号链接起来List&lt;String&gt; G7 &#x3D; Arrays.asList(&quot;USA&quot;, &quot;Japan&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Italy&quot;, &quot;U.K.&quot;,&quot;Canada&quot;);String G7Countries &#x3D; G7.stream().map(x -&gt; x.toUpperCase()).collect(Collectors.joining(&quot;, &quot;));System.out.println(G7Countries); 输出： 1USA, JAPAN, FRANCE, GERMANY, ITALY, U.K., CANADA 例9、复制不同的值，创建一个子列表本例展示了如何利用流的 distinct() 方法来对集合进行去重。 1234&#x2F;&#x2F; 用所有不同的数字创建一个正方形列表List&lt;Integer&gt; numbers &#x3D; Arrays.asList(9, 10, 3, 4, 7, 3, 4);List&lt;Integer&gt; distinct &#x3D; numbers.stream().map( i -&gt; i*i).distinct().collect(Collectors.toList());System.out.printf(&quot;Original List : %s, Square Without duplicates : %s %n&quot;, numbers, distinct); 输出： 1Original List : [9, 10, 3, 4, 7, 3, 4], Square Without duplicates : [81, 100, 9, 16, 49] 例10、计算集合元素的最大值、最小值、总和以及平均值IntStream、LongStream 和 DoubleStream 等流的类中，有个非常有用的方法叫做 summaryStatistics() 。可以返回 IntSummaryStatistics、LongSummaryStatistics 或者 DoubleSummaryStatistic s，描述流中元素的各种摘要数据。在本例中，我们用这个方法来计算列表的最大值和最小值。它也有 getSum() 和 getAverage() 方法来获得列表的所有元素的总和及平均值。 1234567&#x2F;&#x2F;获取数字的个数、最小值、最大值、总和以及平均值List&lt;Integer&gt; primes &#x3D; Arrays.asList(2, 3, 5, 7, 11, 13, 17, 19, 23, 29);IntSummaryStatistics stats &#x3D; primes.stream().mapToInt((x) -&gt; x).summaryStatistics();System.out.println(&quot;Highest prime number in List : &quot; + stats.getMax());System.out.println(&quot;Lowest prime number in List : &quot; + stats.getMin());System.out.println(&quot;Sum of all prime numbers : &quot; + stats.getSum());System.out.println(&quot;Average of all prime numbers : &quot; + stats.getAverage()); 输出： 1234Highest prime number in List : 29Lowest prime number in List : 2Sum of all prime numbers : 129Average of all prime numbers : 12.9 Lambda表达式 vs 匿名类既然lambda表达式即将正式取代Java代码中的匿名内部类，那么有必要对二者做一个比较分析。一个关键的不同点就是关键字 this。匿名类的 this 关键字指向匿名类，而lambda表达式的 this 关键字指向包围lambda表达式的类。另一个不同点是二者的编译方式。Java编译器将lambda表达式编译成类的私有方法。使用了Java 7的 invokedynamic 字节码指令来动态绑定这个方法。 Java 8 Lambda表达式要点10个Java lambda表达式、流API示例到目前为止我们看到了Java 8的10个lambda表达式，这对于新手来说是个合适的任务量，你可能需要亲自运行示例程序以便掌握。试着修改要求创建自己的例子，达到快速学习的目的。我还想建议大家使用Netbeans IDE来练习lambda表达式，它对Java 8支持良好。当把代码转换成函数式的时候，Netbeans会及时给你提示。只需跟着Netbeans的提示，就能很容易地把匿名类转换成lambda表达式。此外，如果你喜欢阅读，那么记得看一下Java 8的lambdas，实用函数式编程这本书（Java 8 Lambdas, pragmatic functional programming），作者是Richard Warburton，或者也可以看看Manning的Java 8实战（Java 8 in Action），这本书虽然还没出版，但我猜线上有第一章的免费pdf。不过，在你开始忙其它事情之前，先回顾一下Java 8的lambda表达式、默认方法和函数式接口的重点知识。 1）lambda表达式仅能放入如下代码：预定义使用了 @Functional 注释的函数式接口，自带一个抽象函数的方法，或者SAM（Single Abstract Method 单个抽象方法）类型。这些称为lambda表达式的目标类型，可以用作返回类型，或lambda目标代码的参数。例如，若一个方法接收Runnable、Comparable或者 Callable 接口，都有单个抽象方法，可以传入lambda表达式。类似的，如果一个方法接受声明于 java.util.function 包内的接口，例如 Predicate、Function、Consumer 或 Supplier，那么可以向其传lambda表达式。 2）lambda表达式内可以使用方法引用，仅当该方法不修改lambda表达式提供的参数。本例中的lambda表达式可以换为方法引用，因为这仅是一个参数相同的简单方法调用。 12list.forEach(n -&gt; System.out.println(n)); list.forEach(System.out::println); &#x2F;&#x2F; 使用方法引用 然而，若对参数有任何修改，则不能使用方法引用，而需键入完整地lambda表达式，如下所示： 1list.forEach((String s) -&gt; System.out.println(&quot;*&quot; + s + &quot;*&quot;)); 事实上，可以省略这里的lambda参数的类型声明，编译器可以从列表的类属性推测出来。 3）lambda内部可以使用静态、非静态和局部变量，这称为lambda内的变量捕获。 4）Lambda表达式在Java中又称为闭包或匿名函数，所以如果有同事把它叫闭包的时候，不用惊讶。 5）Lambda方法在编译器内部被翻译成私有方法，并派发 invokedynamic 字节码指令来进行调用。可以使用JDK中的 javap 工具来反编译class文件。使用 javap -p 或 javap -c -v 命令来看一看lambda表达式生成的字节码。大致应该长这样： 1private static java.lang.Object lambda$0(java.lang.String); 6）lambda表达式有个限制，那就是只能引用 final 或 final 局部变量，这就是说不能在lambda内部修改定义在域外的变量。 1234List&lt;Integer&gt; primes &#x3D; Arrays.asList(new Integer[]&#123;2, 3,5,7&#125;);int factor &#x3D; 2;primes.forEach(element -&gt; &#123; factor++; &#125;);Compile time error : &quot;local variables referenced from a lambda expression must be final or effectively final&quot; 另外，只是访问它而不作修改是可以的，如下所示： 123List&lt;Integer&gt; primes &#x3D; Arrays.asList(new Integer[]&#123;2, 3,5,7&#125;);int factor &#x3D; 2;primes.forEach(element -&gt; &#123; System.out.println(factor*element); &#125;); 输出： 1234461014 因此，它看起来更像不可变闭包，类似于Python。 以上就是Java 8的lambda表达式的全部10个例子。此次修改将成为Java史上最大的一次，将深远影响未来Java开发者使用集合框架的方式。我想规模最相似的一次修改就是Java 5的发布了，它带来了很多优点，提升了代码质量，例如：泛型、枚举、自动装箱（Autoboxing）、静态导入、并发API和变量参数。上述特性使得Java代码更加清晰，我想lambda表达式也将进一步改进它。我在期待着开发并行第三方库，这可以使高性能应用变得更容易写。 更多阅读：http://javarevisited.blogspot.com/2014/02/10-example-of-lambda-expressions-in-java8.html#ixzz3gCMp6Vhc 原文链接： javarevisited 翻译： ImportNew.com - lemeilleur译文链接： http://www.importnew.com/16436.html[ 转载请保留原文出处、译者和译文链接。]","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"Lambda","slug":"Lambda","permalink":"http://www.octber.xyz/tags/Lambda/"}]},{"title":"synchronized/volatile浅谈","slug":"synchronized-volatile浅谈","date":"2019-08-22T07:31:57.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/22/synchronized-volatile浅谈/","link":"","permalink":"http://www.octber.xyz/2019/08/22/synchronized-volatile%E6%B5%85%E8%B0%88/","excerpt":"前言 学习这位大神: HollisChuang","text":"前言 学习这位大神: HollisChuang 知识点 Java语言为了解决并发编程中存在的原子性、可见性和有序性问题，提供了一系列和并发处理相关的关键字，比如synchronized、volatile、final、concurren包等。(再有人问你Java内存模型是什么，就把这篇文章发给他) synchronized通过加锁的方式，使得其在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案，看起来是“万能”的。的确，大部分并发控制操作都能使用synchronized来完成。再有人问你synchronized是什么，就把这篇文章发给他。 volatile通过在volatile变量的操作前后插入内存屏障的方式，保证了变量在并发场景下的可见性和有序性。再有人问你volatile是什么，把这篇文章也发给他 volatile关键字是无法保证原子性的，而synchronized通过monitorenter和monitorexit两个指令，可以保证被synchronized修饰的代码在同一时间只能被一个线程访问，即可保证不会出现CPU时间片在多个线程间切换，即可保证原子性。Java的并发编程中的多线程问题到底是怎么回事儿？ synchronized的问题我们都知道synchronized其实是一种加锁机制，那么既然是锁，天然就具备以下几个缺点： 1、有性能损耗虽然在JDK 1.6中对synchronized做了很多优化，如如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等（深入理解多线程（五）—— Java虚拟机的锁优化技术），但是他毕竟还是一种锁。 以上这几种优化，都是尽量想办法避免对Monitor（深入理解多线程（四）—— Moniter的实现原理）进行加锁，但是，并不是所有情况都可以优化的，况且就算是经过优化，优化的过程也是有一定的耗时的。 所以，无论是使用同步方法还是同步代码块，在同步操作之前还是要进行加锁，同步操作之后需要进行解锁，这个加锁、解锁的过程是要有性能损耗的。 关于二者的性能对比，由于虚拟机对锁实行的许多消除和优化，使得我们很难量化这两者之间的性能差距，但是我们可以确定的一个基本原则是：volatile变量的读操作的性能小号普通变量几乎无差别，但是写操作由于需要插入内存屏障所以会慢一些，即便如此，volatile在大多数场景下也比锁的开销要低。 2、产生阻塞我们在深入理解多线程（一）——Synchronized的实现原理中介绍过关于synchronize的实现原理，无论是同步方法还是同步代码块，无论是ACC_SYNCHRONIZED还是monitorenter、monitorexit都是基于Monitor实现的。 基于Monitor对象，当多个线程同时访问一段同步代码时，首先会进入Entry Set，当有一个线程获取到对象的锁之后，才能进行The Owner区域，其他线程还会继续在Entry Set等待。并且当某个线程调用了wait方法后，会释放锁并进入Wait Set等待。 所以，synchronize实现的锁本质上是一种阻塞锁，也就是说多个线程要排队访问同一个共享对象。 而volatile是Java虚拟机提供的一种轻量级同步机制，他是基于内存屏障实现的。说到底，他并不是锁，所以他不会有synchronized带来的阻塞和性能损耗的问题。 volatile的附加功能除了前面我们提到的volatile比synchronized性能好以外，volatile其实还有一个很好的附加功能，那就是禁止指令重排。 我们先来举一个例子，看一下如果只使用synchronized而不使用volatile会发生什么问题，就拿我们比较熟悉的单例模式来看。 我们通过双重校验锁的方式实现一个单例，这里不使用volatile关键字： 1234567891011121314public class Singleton &#123; private static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 以上代码，我们通过使用synchronized对Singleton.class进行加锁，可以保证同一时间只有一个线程可以执行到同步代码块中的内容，也就是说singleton = new Singleton()这个操作只会执行一次，这就是实现了一个单例。 但是，当我们在代码中使用上述单例对象的时候有可能发生空指针异常。这是一个比较诡异的情况。 我们假设Thread1 和 Thread2两个线程同时请求Singleton.getSingleton方法的时候： Step1 ,Thread1执行到第8行，开始进行对象的初始化。 Step2 ,Thread2执行到第5行，判断singleton == null。 Step3 ,Thread2经过判断发现singleton ！= null，所以执行第12行，返回singleton。 Step4 ,Thread2拿到singleton对象之后，开始执行后续的操作，比如调用singleton.call()。 以上过程，看上去并没有什么问题，但是，其实，在Step4，Thread2在调用singleton.call()的时候，是有可能抛出空指针异常的。 之所有会有NPE抛出，是因为在Step3，Thread2拿到的singleton对象并不是一个完整的对象。 我们这里来分析一下，singleton = new Singleton();这行代码到底做了什么事情，大致过程如下： 1、虚拟机遇到new指令，到常量池定位到这个类的符号引用。 2、检查符号引用代表的类是否被加载、解析、初始化过。 3、虚拟机为对象分配内存。 4、虚拟机将分配到的内存空间都初始化为零值。 5、虚拟机对对象进行必要的设置。 6、执行方法，成员变量进行初始化。 7、将对象的引用指向这个内存区域。 我们把这个过程简化一下，简化成3个步骤： a、JVM为对象分配一块内存M b、在内存M上为对象进行初始化 c、将内存M的地址复制给singleton变量 因为将内存的地址赋值给singleton变量是最后一步，所以Thread1在这一步骤执行之前，Thread2在对singleton==null进行判断一直都是true的，那么他会一直阻塞，直到Thread1将这一步骤执行完。 但是，以上过程并不是一个原子操作，并且编译器可能会进行重排序，如果以上步骤被重排成： a、JVM为对象分配一块内存M c、将内存的地址复制给singleton变量 b、在内存M上为对象进行初始化 这样的话，Thread1会先执行内存分配，在执行变量赋值，最后执行对象的初始化，那么，也就是说，在Thread1还没有为对象进行初始化的时候，Thread2进来判断singleton==null就可能提前得到一个false，则会返回一个不完整的sigleton对象，因为他还未完成初始化操作。 这种情况一旦发生，我们拿到了一个不完整的singleton对象，当尝试使用这个对象的时候就极有可能发生NPE异常。 那么，怎么解决这个问题呢？因为指令重排导致了这个问题，那就避免指令重排就行了。 所以，volatile就派上用场了，因为volatile可以避免指令重排。只要将代码改成以下代码，就可以解决这个问题： 1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 对singleton使用volatile约束，保证他的初始化过程不会被指令重排。synchronized的有序性保证呢？ 看到这里可能有朋友会问了，说到底上面问题还是个有序性的问题，不是说synchronized是可以保证有序性的么，这里为什么就不行了呢？ 首先，可以明确的一点是：synchronized是无法禁止指令重排和处理器优化的。那么他是如何保证的有序性呢？ 这就要再把有序性的概念扩展一下了。Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有操作都是天然有序的。如果在一个线程中观察另一个线程，所有操作都是无序的。 以上这句话也是《深入理解Java虚拟机》中的原句，但是怎么理解呢？周志明并没有详细的解释。这里我简单扩展一下，这其实和as-if-serial语义有关。 as-if-serial语义的意思指：不管怎么重排序，单线程程序的执行结果都不能被改变。编译器和处理器无论如何优化，都必须遵守as-if-serial语义。 这里不对as-if-serial语义详细展开了，简单说就是，as-if-serial语义保证了单线程中，不管指令怎么重排，最终的执行结果是不能被改变的。 那么，我们回到刚刚那个双重校验锁的例子，站在单线程的角度，也就是只看Thread1的话，因为编译器会遵守as-if-serial语义，所以这种优化不会有任何问题，对于这个线程的执行结果也不会有任何影响。 但是，Thread1内部的指令重排却对Thread2产生了影响。 那么，我们可以说，synchronized保证的有序性是多个线程之间的有序性，即被加锁的内容要按照顺序被多个线程执行。但是其内部的同步代码还是会发生重排序，只不过由于编译器和处理器都遵循as-if-serial语义，所以我们可以认为这些重排序在单线程内部可忽略。 总结本文从两方面论述了volatile的重要性以及不可替代性： 一方面是因为synchronized是一种锁机制，存在阻塞问题和性能问题，而volatile并不是锁，所以不存在阻塞和性能问题。 另外一方面，因为volatile借助了内存屏障来帮助其解决可见性和有序性问题，而内存屏障的使用还为其带来了一个禁止指令重排的附件功能，所以在有些场景中是可以避免发生指令重排的问题的。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java8中ConcurrentHashMap变动","slug":"Java8中ConcurrentHashMap变动","date":"2019-08-22T07:05:39.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/22/Java8中ConcurrentHashMap变动/","link":"","permalink":"http://www.octber.xyz/2019/08/22/Java8%E4%B8%ADConcurrentHashMap%E5%8F%98%E5%8A%A8/","excerpt":"","text":"概述 转载自 🔗链接 我们知道， 在 Java 5 之后，JDK 引入了 java.util.concurrent 并发包 ，其中最常用的就是 ConcurrentHashMap 了， 它的原理是引用了内部的 Segment ( ReentrantLock ) 分段锁，保证在操作不同段 map 的时候， 可以并发执行， 操作同段 map 的时候，进行锁的竞争和等待。从而达到线程安全， 且效率大于 synchronized。 但是在 Java 8 之后， JDK 却弃用了这个策略，重新使用了 synchronized。 弃用原因通过 JDK 的源码和官方文档看来， 他们认为的弃用分段锁的原因由以下几点： 加入多个分段锁浪费内存空间。 生产环境中， map 在放入时竞争同一个锁的概率非常小，分段锁反而会造成更新等操作的长时间等待。 为了提高 GC 的效率 新的同步方案既然弃用了分段锁， 那么一定由新的线程安全方案， 我们来看看源码是怎么解决线程安全的呢？（源码保留了segment 代码， 但并没有使用） put 首先通过 hash 找到对应链表过后， 查看是否是第一个object， 如果是， 直接用cas原则插入，无需加锁。 12345678Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv;if (tab == null || (n = tab.length) == 0) tab = initTable(); // 这里在整个map第一次操作时，初始化hash桶， 也就是一个tableelse if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;//如果是第一个object， 则直接cas放入， 不用锁 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value))) break; &#125; 然后， 如果不是链表第一个object， 则直接用链表第一个object加锁，这里加的锁是synchronized，虽然效率不如ReentrantLock， 但节约了空间，这里会一直用第一个object为锁， 直到重新计算map大小，比如扩容或者操作了第一个object为止。 1234567891011121314151617181920212223242526272829303132333435synchronized (f) &#123;// 这里的f即为第一个链表的object if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // 太长会用红黑树 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; else if (f instanceof ReservationNode) throw new IllegalStateException(&quot;Recursive update&quot;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"集合框架","slug":"集合框架","permalink":"http://www.octber.xyz/tags/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}]},{"title":"2019.8.22日报","slug":"2019-8-22日报","date":"2019-08-22T06:53:46.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/22/2019-8-22日报/","link":"","permalink":"http://www.octber.xyz/2019/08/22/2019-8-22%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.22日报 [TOC]","text":"前言2019.8.22日报 [TOC] 1. 任务与任务进度/工时说明1.1 份额调整及复核 进度: 100% 工时: 4h 1.2 行情转换机&amp;&amp;协助杨鑫等2. 已解决的问题2.1 份额调整及复核2.2 行情转换机&amp;&amp;协助杨鑫等3. 未解决的问题4. 进度延迟原因说明","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.21日报","slug":"2019-8-21日报","date":"2019-08-21T06:58:43.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/21/2019-8-21日报/","link":"","permalink":"http://www.octber.xyz/2019/08/21/2019-8-21%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.19日报 [TOC]","text":"前言2019.8.19日报 [TOC] 1. 任务与任务进度/工时说明1.1 份额调整及复核 进度: 90% 工时: 一天 备注: 剩下分頁這個需要和別人商量一下 1.2 [改Bug]增开基金账户 进度: 100% 工时: 2 1.3 [HUI]发现并解决HUI中table的两个大问题 进度: 100% 工时: 3 2. 已解决的问题2.1 份额调整及复核 页面显示table(前后端) 页面下拉多选查询(前后端) 份额调整弹窗(前端) 2.2 增开基金账户 修改完发现的Bug 2.3 HUI中table的两大问题 table固定栏目多表头样式异常的问题,已解决 √ table的columns隐藏必须设置style全局,影响其他table显示的问题,已解决 √ 3. 未解决的问题3.1 份额调整弹窗后台处理数据 接口写了半了,剩下不多 4. 进度延迟原因说明 HUI的坑有点多 5. [备注]份额调整及复核5.1 表格字段对应 产品编码 fund_code bgb_tfund中的fund_code 根据otc_tunitstock的fund_id查询 产品名称 bgb_tfund中的fund_name 根据otc_tunitstock的fund_id查询 投资组合 basecombi_id(投资组合序号) otc_tunitstock中的basecombi_id 销售渠道 agency_code 交易账户 fund_trade_account(基金交易账号) otc_tunitstock中的fund_trade_account 基金代码(证券代码) report_code 根据otc_tunitstock的inter_code(证券内码)到bgb_tinvestfundinfo(投资基金信息表(投资标的))中拿到report_code 基金名称(证券名称) stock_name 根据otc_tunitstock的inter_code(证券内码)到bgb_tinvestfundinfo(投资基金信息表(投资标的))中拿到stock_name 系统当前持仓 可用: current_amount+unfrozamount(解冻数量)-frozamount(冻结数量) 冻结: frozamount(冻结数量)-unfrozamount(解冻数量) 总份额: current_amount 5.2 下拉多选实现5.3 份额调整弹窗5.4 后台实现","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.20日报","slug":"2019-8-20日报","date":"2019-08-20T09:18:08.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/20/2019-8-20日报/","link":"","permalink":"http://www.octber.xyz/2019/08/20/2019-8-20%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.19日报 [TOC]","text":"前言2019.8.19日报 [TOC] 1. 任务与任务进度/工时说明1.1 持仓信息查询 进度: 90% 工时: 一天 备注: 剩下分頁這個需要和別人商量一下 1.2 字典表更新 进度: 100% 2. 已解决的问题2. 已解决的问题 持仓信息查询 字典表更新 3. 未解决的问题 分页 4. 进度延迟原因说明 没使用封装好的h-query-grid,自己写的表格和查询,会稍慢一点 otc项目运行异常,最后重新拉项目才解决,玄学问题,至今不知道为啥 前端json传递数组时候格式转换异常问题,困扰了好久","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.19日报","slug":"2019-8-19日报","date":"2019-08-19T05:50:33.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/19/2019-8-19日报/","link":"","permalink":"http://www.octber.xyz/2019/08/19/2019-8-19%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.19日报 [TOC]","text":"前言2019.8.19日报 [TOC] 1. 任务与任务进度/工时说明1.1 行情转换机定时任务 进度: 100% 工时: 2.5h 1.2 持仓信息查询 进度: 总体: 50% 前端: 70% 后端: 30% 工时: 下午+晚上 1.3 持仓份额调整及复核 备注: 这是邓斯的任务,一开始看错了,做了前端的页面(不包括前端逻辑功能) 2. 已解决的问题 行情转换机定时任务 持仓信息查询(前端页面+后端部分接口) 持仓份额调整及复核(部分前端) 3. 未解决的问题 持仓信息查询 前端多表头问题需要继续确认 4. 进度延迟原因说明 理解业务逻辑上费时间,需要耐心做笔记思考 前端多表头的问题耗费了时间 5. [备注]持仓信息查询 重点: 页面数据需要控制权限，自有总公司，才能看所有子公司的持仓信息。子公司只能看自己的持仓数据（并且无本页面进入权限）。 备注: 接口传入自带了当前company_id 根据关联子公司表dev_tcompanyright可以对应的子公司,如果没有子公司,自己只能看自己的 5.1 前端对应字段 部门编号 company_id 传入自带 部门名称 company_name bg_tcompany中根据company_id拿到company_name 销售渠道 agency_code otc_tunitstock(投资单元证券表)中的agency_code 交易账户(基金交易账号) fund_trade_account otc_tunitstock中的fund_trade_account 产品编号 fund_code bgb_tfund中的fund_code 根据otc_tunitstock的fund_id查询 产品名称 fund_name bgb_tfund中的fund_name 根据otc_tunitstock的fund_id查询 基金代码(证券代码) report_code 根据otc_tunitstock的inter_code(证券内码)到bgb_tinvestfundinfo(投资基金信息表(投资标的))中拿到report_code 基金名称(证券名称) stock_name 根据otc_tunitstock的inter_code(证券内码)到bgb_tinvestfundinfo(投资基金信息表(投资标的))中拿到stock_name 系统当前持仓 一览的主体数据来源于otc_tagentfundshare表,系统当前持仓的数据来与otc_tunitstock,(系统冻结=frozamount(冻结数量)-unfrozamount(解冻数量)） 可用: current_amount+unfrozamount(解冻数量)-frozamount(冻结数量) 冻结: frozamount(冻结数量)-unfrozamount(解冻数量) 总份额: current_amount 5.2 前端查询5.3 后端逻辑 权限判断 本公司 (是否有)子公司 多表查询 优先使用SQL语句查询? 优先使用业务逻辑Java代码处理(复用其他微服务的接口,以及单表查询继承的接口)? 这两者如何取舍?","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.17日报","slug":"2019-8-17日报","date":"2019-08-17T02:17:49.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/17/2019-8-17日报/","link":"","permalink":"http://www.octber.xyz/2019/08/17/2019-8-17%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.17日报","text":"前言2019.8.17日报 1. 任务与任务进度/工时说明1.1 行情转换机定时任务 进度: 95% 工时: 一天 2. 已解决的问题 行情转换机定时任务字段对应问题 3. 未解决的问题 intercode等插入/更新规则尚未完成 4. 进度延迟原因说明 otc转移到bgb以及otc转移到dev这两个大块太麻烦了，搞不完代码跑不起来没法继续写 上述问题今天已经都解决了 格式校验错误,改了很多大家的代码","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.16日报","slug":"2019-8-16日报","date":"2019-08-16T01:09:16.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/16/2019-8-16日报/","link":"","permalink":"http://www.octber.xyz/2019/08/16/2019-8-16%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.16日报","text":"前言2019.8.16日报 1. 任务与任务进度/工时说明1.1 行情转换机定时任务 进度: 80% 工时: 一天 备注: 对应字段填入,处理好otc-&gt;bgb的转移,就能很快搞完的 2. 已解决的问题行情转换机定时任务 3. 未解决的问题 对应字段填入 4. 进度延迟原因说明 otc转移到bgb问题 格式校验错误,改了很多大家的代码 第一次Debug记录 发现问题: URL 错误 “机构标识” 错误 Header Body Url ProcessCode Exception 第二次Debug记录 问题 “机构标识” 还是错误 Header Url Body Exception 第三次Debug记录 完全使用正确 123456789101112 headers.put(&quot;Content-type&quot;, &quot;application/json&quot;); headers.put(&quot;Version&quot;, &quot;机密&quot;); headers.put(&quot;InstitutionCode&quot;, &quot;机密&quot;); //机构标识暂时先写死为汇林保大 加密串、后续调用接口获取该值 headers.put(&quot;InstitutionMarking&quot;, &quot;机密&quot;); headers.put(&quot;SendTime&quot;, &quot;机密&quot;); headers.put(&quot;ProcessCode&quot;, &quot;机密&quot;); headers.put(&quot;PageIndex&quot;, &quot;机密&quot;); headers.put(&quot;RowSize&quot;, &quot;机密&quot;);headers.put(&quot;机密&quot;); 获得真实数据","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"臭臭做饭日记","slug":"臭臭做饭日记","date":"2019-08-15T11:30:53.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/15/臭臭做饭日记/","link":"","permalink":"http://www.octber.xyz/2019/08/15/%E8%87%AD%E8%87%AD%E5%81%9A%E9%A5%AD%E6%97%A5%E8%AE%B0/","excerpt":"前言臭臭做饭日记","text":"前言臭臭做饭日记 2019-08-02 可乐鸡翅 2019-08-02 咖喱鸡块 2019-08-16 炒花蛤 2019-08-16 青椒炒肉 2019-08-16 煎带鱼 2019-08-24 麻椒肉酱","categories":[{"name":"臭臭专栏","slug":"臭臭专栏","permalink":"http://www.octber.xyz/categories/%E8%87%AD%E8%87%AD%E4%B8%93%E6%A0%8F/"}],"tags":[{"name":"饭饭","slug":"饭饭","permalink":"http://www.octber.xyz/tags/%E9%A5%AD%E9%A5%AD/"}]},{"title":"2019.8.15日报","slug":"2019-8-15日报","date":"2019-08-15T03:46:37.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/15/2019-8-15日报/","link":"","permalink":"http://www.octber.xyz/2019/08/15/2019-8-15%E6%97%A5%E6%8A%A5/","excerpt":"前言 2019.8.15日报 [TOC]","text":"前言 2019.8.15日报 [TOC] 1. 任务与任务进度/工时说明1.1 行情转换机定时任务 进度: 100% 工时: 一天 备注: 接口请求不到,无法测试,如果存在和第三方接口对接的问题目前无法处理,目前只能假装拿到了数据的操作 2. 已解决的问题行情转换机定时任务 3. 未解决的问题无 4. 进度延迟原因说明无 5. [记录]行情转换机定时任务5.1 接口参数 描述 字段 是否必须 备注 接口版本号 Version Y 功能代码 ProcessCode Y 3001 机构标识 InstitutionMarking Y 采用O3lic中的客户名称 日期 Fdate Y TA代码 Tacode N 基金代码 Fundcode N 页码编号 PageIndex N 不填写默认第一页 每页数量 RowSize Y 发送时间 SendTime Y yyyyMMddHHmmssfff 签名 SingText Y 签名文本消息流水号+发送时间，进行签名，接收消息后进行验签，若验签未通过则拒绝。 接口示例 12Request Body部:&#123;&quot;Fdate&quot;:&quot;20180820&quot;&#125; 即接口入参表中除了 Version/SingText/SendTime/InstitutionCode/ProcessCode/PageIndex/RowSize/InstitutionMarking参数之外的参数，通通放置body部json串中。 5.2 接口数据123456789101112131415161718192021222324252627282930313233343536373839[&#123; &quot;Fdate&quot;:&quot;20180820&quot;, &quot;Fundcode&quot;:&quot;000009&quot;, &quot;FundStatus&quot;:&quot;0&quot;, // 基金状态 &quot;NetValueType&quot;:&quot;0&quot;, &quot;ConvertStatus&quot;:&quot;0&quot;, // 基金转换状态 &quot;PeriodicStatus&quot;:&quot;0&quot;, &quot;TransferAgencyStatus&quot;:&quot;0&quot;, &quot;CurrencyType&quot;:&quot;156&quot;, &quot;DefDividendMethod&quot;:&quot;1&quot;, &quot;RegistrarCode&quot;:&quot;01&quot;, &quot;FundIncome&quot;:&quot;00093613&quot;, &quot;FundIncomeFlag&quot;:&quot;0&quot;, &quot;Yield&quot;:&quot;00003132&quot;, &quot;YieldFlag&quot;:&quot;0&quot;, &quot;AllowBreachRedempt&quot;:&quot;0&quot;, &quot;FundType&quot;:&quot;04&quot;, &quot;FundTypeName&quot;:&quot;货币型&quot;, &quot;RegistrarName&quot;:&quot;南方基金管理股份有限公司&quot;, &quot;InstAppSubsAmnt&quot;:&quot;160000000&quot;, &quot;InstAppSubsVol&quot;:&quot;160000000&quot;, &quot;MinAmountByInst&quot;:&quot;160000000&quot;, &quot;MinVolByInst&quot;:&quot;160000000&quot;, &quot;MaxRedemptionVol&quot;:&quot;160000000&quot;, &quot;MinAccountBalance&quot;:&quot;160000000&quot;, &quot;MaxSubsVolByInst&quot;:&quot;160000000&quot;, &quot;MaxSubsAmountByInst&quot;:&quot;160000000&quot;, &quot;UnitSubsVolByInst&quot;:&quot;160000000&quot;, &quot;UnitSubsAmountByInst&quot;:&quot;160000000&quot;, &quot;MinBidsAmountByInst&quot;:&quot;160000000&quot;, &quot;MinAppBidsAmountByInst&quot;:&quot;160000000&quot;, &quot;MinRedemptionVol&quot;:&quot;160000000&quot;, &quot;MinInterconvertVol&quot;:&quot;160000000&quot;, &quot;InstMaxPurchase&quot;:&quot;160000000&quot;, &quot;InstDayMaxSumBuy&quot;:&quot;160000000&quot;, &quot;InstDayMaxSumRedeem&quot;:&quot;160000000&quot;, &quot;InstMaxRedeem&quot;:&quot;160000000&quot;, &quot;HuilinDayMaxSumBuy&quot;:&quot;160000000&quot;&#125;] 需要将这些和bgb_tinvestfundinfo进行对应,(有可能走的是更新处理，业务主键: report_code+销售机构编号+ business_date)。外部接口查询结果与DB字段的映射关系，参考数据库的PDM文件 Fundcode就是ReportCode com.hundsun.am4.bgb.service.business.marketinfo.impl.StockInfoServiceImpl#getInterCode根据String companyId, String reportCode, Integer marketNo拿到InterCode companyId根据CompanyService.listCompany()拿到所有company数据 reportCode就是接口回复中的FundCode marketNo固定是6 最终处理成bgb_tinvestfundinfo的三个主键: 12345678interCode:9006,companyId:1001,agencyCode:12interCode:9006,companyId:1002,agencyCode:12interCode:9006,companyId:9998,agencyCode:12interCode:9006,companyId:9999,agencyCode:12interCode:9006,companyId:1001,agencyCode:150interCode:9006,companyId:1002,agencyCode:150interCode:9006,companyId:9998,agencyCode:150interCode:9006,companyId:9999,agencyCode:150 5.3 数据对应 主键三个都已经搞定 purchase_limit-&gt;外部接口【法人最大申购金额InstMaxPurchase】 fund_fee_type-&gt;外部接口【收费方式ShareClass】 applyredeem_status 申购状态 默认使用逗号进行分割 123451 暂停申购2 暂停转入3 暂停赎回4 暂停转出5 暂停认购 可多选，与外部接口状态对应的关系（需要外部的【基金状态】+【基金转换状态】进行累加勾选） 外部接口字段【基金状态】的【1-发行（认购）】 勾选【1暂停申购】、【2暂停转入】、勾【3暂停赎回】、【4暂停转出】 外部接口字段【基金状态】的【4停止申购赎回】 勾选【1暂停申购】与【3暂停赎回】、勾选【5暂停认购】 外部接口字段【基金状态】的【5-停止申购】 勾选【1暂停申购】、勾选【5暂停认购】 外部接口字段【基金状态】的【6-停止赎回】 勾选【3暂停赎回】、勾选【5暂停认购】 外部接口字段【基金状态】的【8-基金终止】 勾选【1暂停申购】、【2暂停转入】、勾【3暂停赎回】、【4暂停转出】、勾选【5暂停认购】 外部接口字段【基金转换状态】的【1-只可转入】 勾选【4暂停转出】 外部接口字段【基金转换状态】的【2-只可转出】 勾选【2暂停转入】 外部接口字段【基金转换状态】的【3-不可转换】 勾选【2暂停转入】、【4暂停转出】 yesterday_nav-&gt;外部接口【基金单位净值NAV】 ta_code-&gt;外部接口【RegistrarCode】 default_auto_buy-&gt;外部接口【默认分红方式DefDividendMethod】 备注:值域与字典表项不一样 0-红利转投，1-现金分红 字段项40356 1. 现金分红 2. 分红再投资 max redeem-&gt;外部接口【法人最大赎回份额InstMaxRedeem】 day_max_sum_redeem-&gt;外部接口【法人当日累计赎回最大份额InstDayMaxSumRedeem】 day_max_sum_purchase_limit-&gt;外部接口字段【汇林当日累计购买限额2HuilinDayMaxSumBuy】 registrar_name-&gt;外部接口字段【RegistrarName】 5.4 数据新增/更新 通过Mapper存放/更新 5.5 流程总结 通过otc_tagency拿到所有的agency 根据每一个agency的agency_code找到otc_tagencyExternalInterface中对应的数据 根据对应的agencyExternalInterface和dev_httpconfig中的数据,进行接口请求 查到所有的company的company_id,对所有的company获得他们的inter_code 根据company_id+inter_code+agency_code(固定为6)为一组主键,加上其他对应字段数据,插入或更新bgb_tinvestfundinfo表 备注: (举例说明) otc_tagency查到2条数据,对应2条otc_tagencyExternalInterface数据 查到三条company信息,对应3组bgb_tinvestfundinfo主键信息 综上,一共六条数据插入/更新到了bgb_tinvestfundinfo中","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"JUC简析","slug":"JUC简析","date":"2019-08-14T13:14:40.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/14/JUC简析/","link":"","permalink":"http://www.octber.xyz/2019/08/14/JUC%E7%AE%80%E6%9E%90/","excerpt":"前言一直以来对JUC都了解不深入,今天做一个了解和分析","text":"前言一直以来对JUC都了解不深入,今天做一个了解和分析 1. JUC简介 在Java 5.0提供了 java.util.concurrent(简称JUC)包,在此包中增加了在并发编程中很常用的工具类, 用于定义类似于线程的自定义子系统,包括线程池,异步 IO 和轻量级任务框架;还提供了设计用于多线程上下文中 的 Collection 实现等;","categories":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/categories/%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://www.octber.xyz/tags/JUC/"}]},{"title":"2019.8.14日报","slug":"2019-8-14日报","date":"2019-08-14T08:37:34.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/14/2019-8-14日报/","link":"","permalink":"http://www.octber.xyz/2019/08/14/2019-8-14%E6%97%A5%E6%8A%A5/","excerpt":"前言 2019.8.13日报 目录 [TOC]","text":"前言 2019.8.13日报 目录 [TOC] 1. 任务与任务进度/工时说明1.1 资金调整及复核 进度: 100% 工时: 6.5h 1.2 行情转换机定时任务 进度: ? (刚开个头吧,没了解过这块) 工时: 4h 2. 已解决的问题2.1 资金调整及复核3. 未解决的问题3.1行情转换机定时任务4. 进度延迟原因说明对转换机任务以及其流程不了解,金融/银行业务知识太薄弱 5. [记录]行情转换机定时任务5.1 任务简述这是一个纯后端的转换机定时任务,需要通过定时任务,定时从第三方接口获取数据并落库 5.2 数据库相关表 otc_tagentaccountapp(需要更新状态) 已经改名为bgb_tagentaccountapp(场外代销账户类申报表) 问题: 更新什么状态? otc_tjobsetting(废弃，改成dev_httpconfig) otc_tjobsetting-&gt;已经废弃,使用dev_httpconfig 此表用于场外定时任务,业务相关的配置 我使用的任务为400: 场外行情查询任务 dev_httpconfig config_code varchar(32) NOT NULL DEFAULT &#39; &#39; PRIMARY KEY, config_name varchar(128) NOT NULL DEFAULT &#39; &#39;, function_id varchar(32) NOT NULL DEFAULT &#39; &#39;, time_out int(11) DEFAULT 0, retry_times int(11) DEFAULT 0, params varchar(255) DEFAULT &#39; &#39;, onetime_declare_size int(11) DEFAULT 0, query_page_size int(11) DEFAULT 0, thread_num int(11) DEFAULT 0, otc_tjobexecuteinfo 场外定时任务执行信息表 我使用的任务为400: 场外行情查询任务 otc_tagency 销售渠道表 销售机构编码 agency_code varchar(16)代销机构名称 agency_name varchar(128) otc_tagencyexternalinterface 销售渠道外部接口对接信息表 company_id=0 行情及其他查询接口: quotation_other_query_url bgb_tinvestfundinfo 落库表 5.3 外部接口 位置: D:\\Program Files\\HundSun\\AM4文档\\其他\\xx基金代销对接O3接口规范V3.9.1.doc 参考标准版前置机接口文档3.9.1版的[3.1行情信息查询]接口 行情信息查询 功能描述 本基金为单基金行情信息查询，O32调用XXX代销。 接口输入 接口返回 5.4 转换机处理 查询任务ID为【400:场外行情查询任务】 每天单次执行任务(9:00执行)。 @Scheduled(cron = &quot;0 0 9 * * ?&quot;) 转换机的配置信息需要从dev_httpconfig与otc_tagencyexternalinterface(销售渠道外部接口对接信息表)中读取，执行日志记录到otc_tjobexecuteinfo中(采用异步的消息机制处理，统一提交给日志转换机日志服务)。 外部接口返回的数据插入到bgb_tinvestfundinfo表(有可能走的是更新处理，业务主键: report_code+销售机构编号+ business_date)。外部接口查询结果与DB字段的映射关系，参考数据库的PDM文件 5.5 具体流程 首先从otc_tagency(销售渠道表)中拿到所有的信息· company_id 公司编号 agency_code 渠道号 agency_name 渠道名 循环第一步拿到的数据,根据agency_code和company_id去otc_tagencyexternalinterface(销售渠道外部接口对接信息表)中拿到对应的外部接口(quotation_other_query_url)的所有配置 我们的任务为:[400:场外行情查询任务],可以在dev_httpconfig中拿到对应的配置 以上就是转换机的配置信息需要从dev_httpconfig与otc_tagencyexternalinterface中读取的意思","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"Java中的集合和线程安全","slug":"Java中的集合和线程安全","date":"2019-08-13T13:17:03.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/13/Java中的集合和线程安全/","link":"","permalink":"http://www.octber.xyz/2019/08/13/Java%E4%B8%AD%E7%9A%84%E9%9B%86%E5%90%88%E5%92%8C%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","excerpt":"前言Java中的集合和线程安全","text":"前言Java中的集合和线程安全 集合框架Java集合框架 (Java Collections Framework, JCF) 也称容器，这里可以类比 C++ 中的 STL Java集合框架提供了数据持有对象的方式，提供了对数据集合的操作。Java 集合框架位于 java.util 包下，主要有三个大类：Collection(接口)**、Map(接口)、集合工具类**。 Collection ArrayList：线程不同步。默认初始容量为 10，当数组大小不足时容量扩大为 1.5 倍。为追求效率，ArrayList 没有实现同步（synchronized），如果需要多个线程并发访问，用户可以手动同步，也可使用 Vector 替代。 LinkedList：线程不同步。双向链接实现。LinkedList 同时实现了 List 接口和 Deque 接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列（Queue），同时又可以看作一个栈（Stack）。这样看来，LinkedList 简直就是个全能冠军。当你需要使用栈或者队列时，可以考虑使用 LinkedList，一方面是因为 Java 官方已经声明不建议使用 Stack 类，更遗憾的是，Java 里根本没有一个叫做 Queue 的类（它是个接口名字）。关于栈或队列，现在的首选是 ArrayDeque，它有着比 LinkedList（当作栈或队列使用时）有着更好的性能。 Stack and Queue：Java 里有一个叫做 Stack 的类，却没有叫做 Queue 的类（它是个接口名字）。当需要使用栈时，Java 已不推荐使用 Stack，而是推荐使用更高效的 ArrayDeque；既然 Queue 只是一个接口，当需要使用队列时也就首选 ArrayDeque 了（次选是 LinkedList ）。 Vector：线程同步。默认初始容量为 10，当数组大小不足时容量扩大为 2 倍。它的同步是通过 Iterator 方法加 synchronized 实现的。 Stack：线程同步。继承自 Vector，添加了几个方法来完成栈的功能。现在已经不推荐使用 Stack，在栈和队列中有限使用 ArrayDeque，其次是 LinkedList。 TreeSet：线程不同步，内部使用 NavigableMap 操作。默认元素 “自然顺序” 排列，可以通过 Comparator 改变排序。TreeSet 里面有一个 TreeMap（适配器模式） HashSet：线程不同步，内部使用 HashMap 进行数据存储，提供的方法基本都是调用 HashMap 的方法，所以两者本质是一样的。集合元素可以为 NULL。 Set：Set 是一种不包含重复元素的 Collection，Set 最多只有一个 null 元素。Set 集合通常可以通过 Map 集合通过适配器模式得到。 PriorityQueue：Java 中 PriorityQueue 实现了 Queue 接口，不允许放入 null 元素；其通过堆实现，具体说是通过完全二叉树（complete binary tree）实现的小顶堆（任意一个非叶子节点的权值，都不大于其左右子节点的权值），也就意味着可以通过数组来作为 PriorityQueue 的底层实现。 优先队列的作用是能保证每次取出的元素都是队列中权值最小的（Java 的优先队列每次取最小元素，C++ 的优先队列每次取最大元素）。这里牵涉到了大小关系，元素大小的评判可以通过元素本身的自然顺序（natural ordering），也可以通过构造时传入的比较器（Comparator，类似于 C++ 的仿函数）。 NavigableSet：添加了搜索功能，可以对给定元素进行搜索：小于、小于等于、大于、大于等于，放回一个符合条件的最接近给定元素的 key。 EnumSet：线程不同步。内部使用 Enum 数组实现，速度比 HashSet 快。只能存储在构造函数传入的枚举类的枚举值。 Map 关于红黑树可参考: https://www.jianshu.com/p/e136ec79235c TreeMap：线程不同步，基于 红黑树 （Red-Black tree）的 NavigableMap 实现，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的。 TreeMap 底层通过红黑树（Red-Black tree）实现，也就意味着 containsKey(), get(), put(), remove() 都有着 log(n) 的时间复杂度。其具体算法实现参照了《算法导论》。 HashTable：线程安全，HashMap 的迭代器 (Iterator) 是 fail-fast 迭代器。HashTable 不能存储 NULL 的 key 和 value。 HashMap：线程不同步。根据 key 的 hashcode 进行存储，内部使用静态内部类 Node 的数组进行存储，默认初始大小为 16，每次扩大一倍。当发生 Hash 冲突时，采用拉链法（链表）。JDK 1.8中：当单个桶中元素个数大于等于8时，链表实现改为红黑树实现；当元素个数小于6时，变回链表实现。由此来防止hashCode攻击。 Java HashMap 采用的是冲突链表方式。 HashMap 是 Hashtable 的轻量级实现，可以接受为 null 的键值 (key) 和值 (value)，而 Hashtable 不允许。 LinkedHashMap：保存了记录的插入顺序，在用 Iterator 遍历 LinkedHashMap 时，先得到的记录肯定是先插入的。也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比 HashMap 慢，不过有种情况例外，当 HashMap 容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap 慢，因为 LinkedHashMap 的遍历速度只和实际数据有关，和容量无关，而 HashMap 的遍历速度和他的容量有关。 WeakHashMap：从名字可以看出它是某种 Map。它的特殊之处在于 WeakHashMap 里的 entry 可能会被 GC 自动删除，即使程序员没有调用 remove() 或者 clear() 方法。 WeakHashMap 的存储结构类似于HashMap 既然有 WeekHashMap，是否有 WeekHashSet 呢？答案是没有！不过 Java Collections 工具类给出了解决方案，Collections.newSetFromMap(Map&lt;E,Boolean&gt; map) 方法可以将任何 Map包装成一个Set。 工具类 Collections、Arrays：集合类的一个工具类帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 Comparable、Comparator：一般是用于对象的比较来实现排序，两者略有区别。 类设计者没有考虑到比较问题而没有实现 Comparable 接口。这是我们就可以通过使用 Comparator，这种情况下，我们是不需要改变对象的。 一个集合中，我们可能需要有多重的排序标准，这时候如果使用 Comparable 就有些捉襟见肘了，可以自己继承 Comparator 提供多种标准的比较器进行排序。 说明：线程不同步的时候可以通过，Collections.synchronizedList() 方法来包装一个线程同步方法 线程安全 太喜欢这个大哥的文章了: https://www.cnblogs.com/deky97/p/11024527.html 1. 为什么大多数的集合类不是线程安全的？ArrayList, LinkedList, HashMap, HashSet, TreeMap, TreeSet等等都不是线程安全的,事实上,所有的集合类（除了Vector和HashTable以外）在java.util包中都不是线程安全的，只遗留了两个实现类（Vector和HashTable）是线程安全的 线程安全的有: ConcurrentHashMap/Vector/HashTable/Stack 在使用1000万个元素进行测试Vector和ArrayList发现ArrayList的时间是Vector的一般,效率是其的两倍,甚至更多 2. 快速失败迭代器(Fail-Fast Iterators)在使用集合的时候，你也要了解到迭代器的并发策略：Fail-Fast Iterators 看下以后代码片段，遍历一个String类型的集合： 12345678List&lt;String&gt; listNames = Arrays.asList(&quot;Tom&quot;, &quot;Joe&quot;, &quot;Bill&quot;, &quot;Dave&quot;, &quot;John&quot;); Iterator&lt;String&gt; iterator = listNames.iterator(); while (iterator.hasNext()) &#123; String nextName = iterator.next(); System.out.println(nextName);&#125; 这里我们使用了Iterator来遍历list中的元素，试想下listNames被两个线程共享：一个线程执行遍历操作，在还没有遍历完成的时候，第二线程进行修改集合操作（添加或者删除元素），你猜测下这时候会发生什么？ 遍历集合的线程会立刻抛出异常“ConcurrentModificationException”，所以称之为：快速失败迭代器（随便翻的哈，没那么重要，理解就OK） 为什么迭代器会如此迅速的抛出异常？ 因为当一个线程在遍历集合的时候，另一个在修改遍历集合的数据会非常的危险：集合可能在修改后，有更多元素了，或者减少了元素又或者一个元素都没有了。所以在考虑结果的时候，选择抛出异常。而且这应该尽可能早的被发现，这就是原因。（反正这个答案不是我想要的~） 下面这段代码演示了抛出：ConcurrentModificationException 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.util.*; /** * This test program illustrates how a collection&#x27;s iterator fails fast * and throw ConcurrentModificationException * @author www.codejava.net * */public class IteratorFailFastTest &#123; private List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); public IteratorFailFastTest() &#123; for (int i = 0; i &lt; 10_000; i++) &#123; list.add(i); &#125; &#125; public void runUpdateThread() &#123; Thread thread1 = new Thread(new Runnable() &#123; public void run() &#123; for (int i = 10_000; i &lt; 20_000; i++) &#123; list.add(i); &#125; &#125; &#125;); thread1.start(); &#125; public void runIteratorThread() &#123; Thread thread2 = new Thread(new Runnable() &#123; public void run() &#123; ListIterator&lt;Integer&gt; iterator = list.listIterator(); while (iterator.hasNext()) &#123; Integer number = iterator.next(); System.out.println(number); &#125; &#125; &#125;); thread2.start(); &#125; public static void main(String[] args) &#123; IteratorFailFastTest tester = new IteratorFailFastTest(); tester.runIteratorThread(); tester.runUpdateThread(); &#125;&#125; 如你所见，在thread1遍历list的时候，thread2执行了添加元素的操作，这时候异常被抛出。 需要注意的是，使用iterator遍历list，快速失败的行为是为了让我更早的定位问题所在。我们不应该依赖这个来捕获异常，因为快速失败的行为是没有保障的。这意味着如果抛出异常了，程序应该立刻终止行为而不是继续执行。 现在你应该了解到了ConcurrentModificationException是如何工作的，而且最好是避免它。 3. 同步封装器当然我们不能使用线程不安全的集合在多线程环境下，这样做会导致出现我们期望的结果。我们可以手动自己添加synchronized代码块来确保安全，但是使用自动线程安全的线程比我们手动更为明智。 你应该已经知道，Java集合框架提供了工厂方法创建线程安全的集合，这些方法的格式如下： 1Collections.synchronizedXXX(collection) 这个工厂方法封装了指定的集合并返回了一个线程安全的集合。XXX可以是Collection、List、Map、Set、SortedMap和SortedSet的实现类。比如下面这段代码创建了一个线程安全的列表： 1List&lt;String&gt; safeList = Collections.synchronizedList(new ArrayList&lt;&gt;()); 如果我们已经拥有了一个线程不安全的集合，我们可以通过以下方法来封装成线程安全的集合： 12Map&lt;Integer, String&gt; unsafeMap = new HashMap&lt;&gt;();Map&lt;Integer, String&gt; safeMap = Collections.synchronizedMap(unsafeMap); 如你锁看到的，工厂方法封装指定的集合，返回一个线程安全的结合。事实上接口基本都一直，只是实现上添加了synchronized来实现。所以被称之为：同步封装器。后面集合的工作都是由这个封装类来实现。 提示： 在我们使用iterator来遍历线程安全的集合对象的时候，我们还是需要添加synchronized字段来确保线程安全，因为Iterator本身并不是线程安全的，请看代码如下： 12345678910List&lt;String&gt; safeList = Collections.synchronizedList(new ArrayList&lt;&gt;()); // adds some elements to the list Iterator&lt;String&gt; iterator = safeList.iterator(); while (iterator.hasNext()) &#123; String next = iterator.next(); System.out.println(next);&#125; 事实上我们应该这样来操作： 123456synchronized (safeList) &#123; while (iterator.hasNext()) &#123; String next = iterator.next(); System.out.println(next); &#125;&#125; 同时提醒下，Iterators也是支持快速失败的。尽管经过类的封装可保证线程安全，但是他们依然有着自己的缺点，具体见下面部分。 4. 并发集合一个关于同步集合的缺点是，用集合的本身作为锁的对象。这意味着，在你遍历对象的时候，这个对象的其他方法已经被锁住，导致其他的线程必须等待。其他的线程无法操作当前这个被锁的集合，只有当执行的线程释放了锁。这会导致开销和性能较低。 这就是为什么jdk1.5+以后提供了并发集合的原因，因为这样的集合性能更高。并发集合类并放在java.util.concurrent包下，根据三种安全机制被放在三个组中。 第一种为：写时复制集合：这种集合将数据放在一成不变的数组中；任何数据的改变，都会重新创建一个新的数组来记录值。这种集合被设计用在，读的操作远远大于写操作的情景下。有两个如下的实现类：CopyOnWriteArrayList 和 CopyOnWriteArraySet. 需要注意的是，写时复制集合不会抛出ConcurrentModificationException异常。因为这些集合是由不可变数组支持的，Iterator遍历值是从不可变数组中出来的，不用担心被其他线程修改了数据。 第二种为：比对交换集合也称之为CAS（Compare-And-Swap）集合：这组线程安全的集合是通过CAS算法实现的。CAS的算法可以这样理解： 为了执行计算和更新变量，在本地拷贝一份变量，然后不通过获取访问来执行计算。当准备好去更新变量的时候，他会跟他之前的开始的值进行比较，如果一样，则更新值。 如果不一样，则说明应该有其他的线程已经修改了数据。在这种情况下，CAS线程可以重新执行下计算的值，更新或者放弃。使用CAS算法的集合有：ConcurrentLinkedQueue and ConcurrentSkipListMap. 需要注意的是，CAS集合具有不连贯的iterators，这意味着自他们创建之后并不是所有的改变都是从新的数组中来。同时他也不会抛出ConcurrentModificationException异常。 第三种为：这种集合采用了特殊的对象锁（java.util.concurrent.lock.Lock）：这种机制相对于传统的来说更为灵活，可以如下理解： 这种锁和经典锁一样具有基本的功能，但还可以再特殊的情况下获取：如果当前没有被锁、超时、线程没有被打断。 不同于synchronization的代码,当方法在执行，Lock锁一直会被持有，直到调用unlock方法。有些实现通过这种机制把集合分为好几个部分来提供并发性能。比如：LinkedBlockingQueue，在队列的开后和结尾，所以在添加和删除的时候可以同时进行。 其他使用了这种机制的集合有：ConcurrentHashMap 和绝多数实现了BlockingQueue的实现类 同样的这一类的集合也具有不连贯的iterators，也不会抛出ConcurrentModificationException异常。 ConcurrentHashMap: https://www.cnblogs.com/shan1393/p/9020564.html 总结我们来总结下今天我们所学到的几个点： 大部分在java.util包下的实现类都没有保证线程安全为了保证性能的优越，除了Vector和Hashtable以外。 通过Collection可以创建线程安全类，但是他们的性能都比较差。 同步集合既保证线程安全也在给予不同的算法上保证了性能，他们都在java.util.concurrent包中。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"Java集合框架","slug":"Java集合框架","permalink":"http://www.octber.xyz/tags/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}]},{"title":"2019.8.13日报","slug":"2019-8-13日报","date":"2019-08-13T01:49:54.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/13/2019-8-13日报/","link":"","permalink":"http://www.octber.xyz/2019/08/13/2019-8-13%E6%97%A5%E6%8A%A5/","excerpt":"前言 2019.8.13日报 目录 [TOC]","text":"前言 2019.8.13日报 目录 [TOC] 1. 任务与任务进度/工时说明1.1 开户代码测试与调试 进度: 100% 工时: 1.5h 代码不符合validate修改/代码测试与发现问题 1.2 [昨日遗留]资金调整及复合(前端) 进度: 100% 工时: 3.5h 主要是otc需要bgb更新代码,按照代码规范改了一些代码,再install花时间多 1.3 资金调整及符合(后端) 进度: 70% 工时: 4.5h 前端页面显示多表查询/按条件查询/前端数据提交后处理 2. 已解决的问题2.1 资金调整及符合前端(全部完成) 以及操作弹窗: 2.2 资金调整及符合后端(完成部分) 完成前端显示表格数据支持接口 完成部分提交资金调整后接口 3. 未解决的问题后端:资金调整确认提交后处理 4. 进度延迟原因说明 有些坑和bug废了点时间,比如前端中文乱码,前端菜单生成(第二次搞不熟练),otc后台正常运行起来等等不重要却很花费时间的工作 项目重新运行/编译等太费时间了,太慢了 修改自己和别人代码中validate的代码不规范的地方比较忙,代码不规范的地方太多了 业务不熟悉,需要做笔记消化再上手 5. [记录]资金调整及复核(后端)5.1 前端显示表格数据支持 表格对应字段 产品编码 otc_tassetday(资产单元日信息表)的fund_id 产品名称 根据otc_tassetday(资产单元日信息表)的fund_id去bgb_tfund(产品信息表)中拿到fund_name 资产单元 根据otc_tassetday(资产单元日信息表)的asset_id去bgb_tassetunit(资产单元表)中拿到asset_name 期初现金余额 otc_tassetday(资产单元日信息表)的begin_cash 当前现金余额 otc_tassetday(资产单元日信息表)的current_cash 期初可用 期初可用=期初现金余额(begin_cash)－冻结(frozen_balance)＋解冻(unfrozen_balance) 当前可用 当前可用=当前现金余额(current_cash)－冻结(frozen_balance)＋解冻(unfrozen_balance) 5.2 提交修改 按照没有复核时的情况处理 首先插入otc_tcashbusiness(资金业务表),标记已处理状态 更新资产单元日信息表的当前资金余额 插入到证券资金流水表","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"MySQL-InnoDB的结构和特性","slug":"MySQL-InnoDB的结构和特性","date":"2019-08-12T13:41:57.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/12/MySQL-InnoDB的结构和特性/","link":"","permalink":"http://www.octber.xyz/2019/08/12/MySQL-InnoDB%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E7%89%B9%E6%80%A7/","excerpt":"前言数据库中InnoDB引擎的简析以及他和MyISAM的区别 [TOC]","text":"前言数据库中InnoDB引擎的简析以及他和MyISAM的区别 [TOC] InnoDB和MyISAM的区别 特别感谢: https://blog.csdn.net/perfectsorrow/article/details/80150672 显著区别: InnoDB支持了ACID兼容的事务（Transaction）功能事务,而MyISAM不支持,但是MyISAM具有原子性 原子性（Atomicity） 一致性（Consistency） 隔离性（Isolation） 持久性（Durability） 区别一: 事务MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential AccessMethod：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。 区别二: 存储结构 MyISAM 每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。 InnoDB 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。 区别三: 储存空间 MyISAM 可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。 InnoDB 需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。 区别四: 可移植性、备份及恢复 MyISAM 数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。 InnoDB 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。 区别五: AUTO_INCREMENT MyISAM 可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。 InnoDB InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。 区别六: 表锁差异 MyISAM 只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。 InnoDB 支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。 区别七: 全文索引 MyISAM 支持 FULLTEXT类型的全文索引 InnoDB 不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。 区别八: 表主键 MyISAM 允许没有任何索引和主键的表存在，索引都是保存行的地址。 InnoDB 如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。 区别九: 表的具体行数 MyISAM 保存有表的总行数，如果select count() from table;会直接取出出该值。 InnoDB 没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。 区别十: CURD操作 MyISAM 如果执行大量的SELECT，MyISAM是更好的选择。 InnoDB 如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。 区别十一: 外键 MyISAM 不支持 InnoDB 支持 通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.octber.xyz/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.octber.xyz/tags/MySQL/"}]},{"title":"2019.8.12日报-Re","slug":"2019-8-12日报-Re","date":"2019-08-12T11:11:12.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/12/2019-8-12日报-Re/","link":"","permalink":"http://www.octber.xyz/2019/08/12/2019-8-12%E6%97%A5%E6%8A%A5-Re/","excerpt":"前言 目录 [TOC]","text":"前言 目录 [TOC] 1. 任务与任务进度/工时说明1.1 字典表维护 任务描述: 将待申报字典表添加到数据库对应表中 进度说明: 100% 投入工时: 2.5工时 1.2 开户文件上传 进度说明: 100% 投入工时: 6工时 1.3 资金调整及复核(前端) 进度说明: 70% 投入工时: 1工时 2. 已解决的问题2.1 字典表维护 新增882条字典项 自主设计程序运行,之后新增的字典项可以复用此程序 2.2 开户文件上传 前端使用HUI组件上传文件 前端使用BG的upload()接口上传到临时文件夹 提交时对文件进行规范的重命名后转存到客户的FTP服务器 2.3 资金调整及复核(前端) 前端代码已经完成 仅限于显示效果,对应字段的对应关系和具体功能还没有完成 生成菜单栏的JSON完成 后端运行不起来,具体效果需要测试 3. 未解决的问题3.1 资金调整及复核(前端) 菜单栏没添加成功,导致前端页面效果还没能测试 4. 进度延迟原因说明4.1 资金调整及复核(前端) 怀疑是依赖的版本更新后,后端代码没有及时更新,导致后端跑不起来 需要明天问一下涛哥~","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.12日报","slug":"2019-8-12日报","date":"2019-08-12T02:32:11.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/12/2019-8-12日报/","link":"","permalink":"http://www.octber.xyz/2019/08/12/2019-8-12%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.9.12日报 经过四天在芜湖的比赛,今天周一回到杭州,正好避过了台风,开始新的一周的工作","text":"前言2019.9.12日报 经过四天在芜湖的比赛,今天周一回到杭州,正好避过了台风,开始新的一周的工作 今日1. 新增字典项 之前添加的字典项,还有随后新增的字典项,统一更新到数据库中 1.1 格式化字典项数据将所有要添加的字典项Excel表格中的数据,转化为CSV的格式,这种格式通过逗号分隔,利于处理 1.2 编写程序编写读入CSV的程序,并且设计算法将其处理成规范格式的数据 格式参考: 123456789101112131415&#123; &quot;company_id&quot;: 0, &quot;use_flag&quot;: &quot;1&quot;, &quot;dict_key&quot;: &quot;60055&quot;, &quot;dict_value&quot;: &quot;!&quot;, &quot;dict_caption&quot;: &quot;代销账户类别&quot;, &quot;dict_caption_eng&quot;: &quot;&quot;, &quot;hide_flag&quot;: &quot;&quot;, &quot;dict_order&quot;: 0, &quot;dict_version&quot;: &quot;0&quot;, &quot;authorise_code&quot;: &quot;&quot;, &quot;dict_operator_mode_list&quot;: &quot;&quot;, &quot;custom_industry_code&quot;: &quot;&quot;, &quot;custom_id&quot;: &quot;&quot; &#125; 1.3 导出为JSON 使用GSON导出为JSON,写入bg-cloud-manage的BG_TDICTIONARY文件中 删除bg_tsystemversion的内容 运行程序更新到数据库中 1.4 本次更新内容更新了待申报字典表中的所有数据,提供其他人方便使用 2. 提交文件 第一步将上传的文件继续处理,再提交到指定位置 2.1 从上传接口拿到对应文件的信息123456789101112errorCode: &quot;0&quot;errorInfo: nullerrorNo: 0result: &#123;…&#125;classifyNo: nullcompanyId: 1001createUser: &quot;10018888&quot;fileId: 22fileName: &quot;nginxconfig.txt&quot;filePath: &quot;/home/file_tmp/20190812&quot;fileSize: 2122fileStoreName: &quot;903fc4d2a5fb47bb88d4a983899f3fcd&quot; 2.2 前端对一系列文件的fileId进行储存,统一提交2.3 后端根据fileId获得文件列表2.4 后端进行命名规范规则： zip文件命名修改规则: 文件上传，需要自动修改文件名，以支持代销端和开户申请对应； 命名修改建议规则：客户原文件名机构标识 O3基金简称_3位业务代码_8位日期.ZIP （开户报文中有：机构标识、O3基金简称、3位业务代码、8位日期） 四个（或多个）文件格式及命名规则 上传的文件批次编号一个，需加在四个（或多个）文件前缀； 四个（或多个）文件名得改为字母，算上文件编号前缀后，格式为xxxxYYYYMMDDzzz-a，xxxxYYYYMMDDzzz-b，xxxxYYYYMMDDzzz-c/d/e/......; 文件格式： 文件编号规则： 文件编号必须默认传递，即使“四个（或多个）文件”没有上传为空； 文件编号格式：xxxxYYYYMMDDzzz，其中xxxx需要每套“机构通”（或投资者，需考虑多管理人版本）不同，zzz表示当前申请批次号，每笔申请的批次号当前系统当前日期唯一 以上为文档里规定的,通过和龙哥进一步确认命名规范后,确定为 2.4.1 账户电子文件上传 文件类型: 压缩文件 Zip 命名规范: 客户原文件名_机构标识_O3基金简称_3位业务代码_8位日期.ZIP 说明: 机构表示修改为: 公司编号company_id O3基金简称: 来源于OpenAccountFormDTO中的fundName(产品简称) 3位业务代码: Busin_type(业务类型) 8位日期：如20190808 2.4.2 四个文件 投资人营业执照 (盖公章) 投资人法人身份证复印件 (盖公章) 金融许可证复印件 (盖公章) 投资交易平台第三方机构合作协议 (盖公章) 说明: 文件名组成: 文件编号前缀 + “-a”: 投资人营业执照 (盖公章) “-b”: 投资人法人身份证复印件 (盖公章) “-c”: 金融许可证复印件 (盖公章) “-d”: 投资交易平台第三方机构合作协议 (盖公章) 文件编号说明xxxxYYYYMMDDzzz: xxxx: company_id YYYYMMDD: 年月日 zzz: 唯一标识 2.5 后端文件上传到FTP服务器1234567891011#================================================================# File#================================================================#local：本地，sftp：使用sftp方式上传am4.bg.upload.mode=sftpam4.bg.upload.sftp.address=10.20.29.235am4.bg.upload.sftp.port=22am4.bg.upload.sftp.user=rootam4.bg.upload.sftp.password=Yy@zgy2019_cwjytam4.bg.upload.path=/home/trade_account_files/am4.bg.upload.whitelist=txt,doc,docx,xls,jpg,png,zip 将来只需要修改am4.bg.upload.path=/home/trade_account_files/就可以了 流程有问题,改吧!","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"Java线程池","slug":"Java线程池","date":"2019-08-10T13:17:20.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/10/Java线程池/","link":"","permalink":"http://www.octber.xyz/2019/08/10/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"前言线程池的常见问题和创建方式","text":"前言线程池的常见问题和创建方式 什么是线程池？线程池是一种多线程处理形式，处理过程中将任务提交到线程池，任务的执行交由线程池来管理。 如果每个请求都创建一个线程去处理，那么服务器的资源很快就会被耗尽，使用线程池可以减少创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 为什么要使用线程池？创建线程和销毁线程的花销是比较大的，这些时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程，再加上业务工作线程，消耗系统资源的时间，可能导致系统资源不足。（我们可以把创建和销毁的线程的过程去掉） 线程池有什么作用？线程池作用就是限制系统中执行线程的数量。 提高效率 创建好一定数量的线程放在池中，等需要使用的时候就从池中拿一个，这要比需要的时候创建一个线程对象要快的多。 方便管理 可以编写线程池管理代码对池中的线程同一进行管理，比如说启动时有该程序创建100个线程，每当有请求的时候，就分配一个线程去工作，如果刚好并发有101个请求，那多出的这一个请求可以排队等候，避免因无休止的创建线程导致系统崩溃。 说说几种常见的线程池及使用场景1. newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 2. newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 缺点:newFixedThreadPool()在严格上说并不会复用线程，每运行一个Runnable都会通过ThreadFactory创建一个线程 3. newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 缺点：Executors.newCachedThreadPool()缺点：大家一般不用是因为newCachedThreadPool 可以无线的新建线程，容易造成堆外内存溢出，因为它的最大值是在初始化的时候设置为 Integer.MAX_VALUE，一般来说机器都没那么大内存给它不断使用。当然知道可能出问题的点，就可以去重写一个方法限制一下这个最大值 4. newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。 需要注意的是，只有当任务的执行时间到来时，ScheduedExecutor 才会真正启动一个线程，其余时间 ScheduledExecutor 都是在轮询任务的状态。 5. newWorkStealingPool一个拥有多个任务队列的线程池，可以减少连接数，创建当前可用cpu数量的线程来并行执行。 开启线程的三种方式？run()和start()方法区别？Java使用Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。Java可以用三种方式来创建线程1）继承Thread类创建线程2）实现Runnable接口创建线程3）使用Callable和Future创建线程 new Thread的弊端？ 每次new Thread新建对象性能差。 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机。 缺乏更多功能，如定时执行、定期执行、线程中断。 相比new Thread，Java提供的四种线程池的好处在于： 重用存在的线程，减少对象创建、消亡的开销，性能佳。 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。 提供定时执行、定期执行、单线程、并发数控制等功能。 线程池中的几种重要的参数 corePoolSize: 就是线程池中的核心线程数量，这几个核心线程，只是在没有用的时候，也不会被回收 maximumPoolSize: 就是线程池中可以容纳的最大线程的数量 keepAliveTime: 就是线程池中除了核心线程之外的其他的最长可以保留的时间，因为在线程池中，除了核心线程即使在无任务的情况下也不能被清除，其余的都是有存活时间的，意思就是非核心线程可以保留的最长的空闲时间， util: 就是计算这个时间的一个单位。 workQueue: 就是等待队列，任务可以储存在任务队列中等待被执行，执行的是FIFIO原则（先进先出）。 threadFactory: 就是创建线程的线程工厂。 handler: 是一种拒绝策略，我们可以在任务满了之后，拒绝执行某些任务。 说说线程池的拒绝策略​ 当请求任务不断的过来，而系统此时又处理不过来的时候，我们需要采取的策略是拒绝服务。RejectedExecutionHandler接口提供了拒绝任务处理的自定义方法的机会。在ThreadPoolExecutor中已经包含四种处理策略。 AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作。 CallerRunsPolicy策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前的被丢弃的任务。 DiscardOleddestPolicy策略： 该策略将丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。 DiscardPolicy策略：该策略默默的丢弃无法处理的任务，不予任何处理。 ​ 除了JDK默认提供的四种拒绝策略，我们可以根据自己的业务需求去自定义拒绝策略，自定义的方式很简单，直接实现RejectedExecutionHandler接口即可。 execute和submit的区别？​ 在前面的讲解中，我们执行任务是用的execute方法，除了execute方法，还有一个submit方法也可以执行我们提交的任务。 这两个方法有什么区别呢？分别适用于在什么场景下呢？我们来做一个简单的分析。 execute适用于不需要关注返回值的场景，只需要将线程丢到线程池中去执行就可以了。 submit方法适用于需要关注返回值的场景 线程池的关闭关闭线程池可以调用shutdownNow和shutdown两个方法来实现 shutdownNow：对正在执行的任务全部发出interrupt()，停止执行，对还未开始执行的任务全部取消，并且返回还没开始的任务列表。 shutdown：当我们调用shutdown后，线程池将不再接受新的任务，但也不会去强制终止已经提交或者正在执行中的任务。 初始化线程池时线程数的选择 如果任务是IO密集型，一般线程数需要设置2倍CPU数以上，以此来尽量利用CPU资源。 如果任务是CPU密集型，一般线程数量只需要设置CPU数加1即可，更多的线程数也只能增加上下文切换，不能增加CPU利用率。 上述只是一个基本思想，如果真的需要精确的控制，还是需要上线以后观察线程池中线程数量跟队列的情况来定。 线程池都有哪几种工作队列ArrayBlockingQueue是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列 SynchronousQueue一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 PriorityBlockingQueue一个具有优先级的无限阻塞队列。","categories":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/categories/%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"BIO和NIO简述","slug":"BIO和NIOi简述","date":"2019-08-10T11:46:59.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/10/BIO和NIOi简述/","link":"","permalink":"http://www.octber.xyz/2019/08/10/BIO%E5%92%8CNIOi%E7%AE%80%E8%BF%B0/","excerpt":"前言线程中很基础的关于BIO和NIO的概念，需要我们进行一个简单的了解","text":"前言线程中很基础的关于BIO和NIO的概念，需要我们进行一个简单的了解 概念 BIO: Blocking IO 阻塞线程 NIO: Non-Blocking IO 非阻塞线程 所谓的 BIO ， 就是当线程执行了某个耗时操作时，需要等待耗时操作结束，再进行后续操作。 NIO, 就是当线程执行了耗时操作时，该线程不需要等待耗时操作结束，可用来执行其他操作。 Java NIO有三大组成部分：Buffer,Channel,Selector，通过事件驱动模式实现了什么时候有数据可读的问题。 Channel: 相当于IO操作的载体，相当于一个硬件设备，一个文件，一个socket或是区别程序中的不同IO操作，如read，write。channel类似流，但又有些不同：既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。通道可以异步地读写。通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。 Buffer: 用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 Selector: Selector（选择器）是Java NIO中能够检测一到多个NIO通道，通道将关心的事件注册到selector 上，selector能够知晓通道是否为这些事件诸如读写事件做好数据准备。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 Java NIO和IO的主要区别 **IO NIO** 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 线程是较为重量级的资源。bio当并发量大，而后端服务或客户端处理数据慢时就会产生产生大量线程处于等待中，即上述的阻塞，是非常严重的资源浪费。此外，线程的切换也会导致cpu资源的浪费，单机内存限制也无法过多的线程，只能单向以流的形式读取数据。 nio使用单线程或者只使用少量的多线程，多个连接共用一个线程，消耗的线程资源会大幅减小。并且当处于等待（没有事件）的时候线程资源可以释放出来处理别的请求，通过事件驱动模型当有accept/read/write等事件发生后通知（唤醒）主线程分配资源来处理相关事件。以buffer缓冲区的形式处理数据，处理更为方便。 面向流与面向缓冲Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO是将数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查该缓冲区中是否包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 阻塞与非阻塞IOJava IO的各种流是阻塞的。这意味着，当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变得可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 AIO（其实就是NIO.2）: AIO主要有两部分组成，Files用于解决文件的一部处理问题，Sockets用于解决Socket的一部处理问题，在Linux上，主要有两种实现，一种是Posix AIO，即用户态实现，另一种是Kernel Native AIO内核态实现，性能比较高，nginx、mysql等的新版本都支持kernel Natice AIO。","categories":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/categories/%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"【崩坏3】官方壁纸01","slug":"【崩坏3】官方壁纸01","date":"2019-08-10T09:33:23.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/10/【崩坏3】官方壁纸01/","link":"","permalink":"http://www.octber.xyz/2019/08/10/%E3%80%90%E5%B4%A9%E5%9D%8F3%E3%80%91%E5%AE%98%E6%96%B9%E5%A3%81%E7%BA%B801/","excerpt":"前言官方壁纸,多图警告","text":"前言官方壁纸,多图警告","categories":[{"name":"游戏专栏","slug":"游戏专栏","permalink":"http://www.octber.xyz/categories/%E6%B8%B8%E6%88%8F%E4%B8%93%E6%A0%8F/"}],"tags":[{"name":"崩坏3","slug":"崩坏3","permalink":"http://www.octber.xyz/tags/%E5%B4%A9%E5%9D%8F3/"}]},{"title":"【崩坏3】手机壁纸01","slug":"【崩坏3】手机壁纸01","date":"2019-08-10T09:32:41.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/10/【崩坏3】手机壁纸01/","link":"","permalink":"http://www.octber.xyz/2019/08/10/%E3%80%90%E5%B4%A9%E5%9D%8F3%E3%80%91%E6%89%8B%E6%9C%BA%E5%A3%81%E7%BA%B801/","excerpt":"前言多图警告","text":"前言多图警告","categories":[{"name":"游戏专栏","slug":"游戏专栏","permalink":"http://www.octber.xyz/categories/%E6%B8%B8%E6%88%8F%E4%B8%93%E6%A0%8F/"}],"tags":[{"name":"崩坏3","slug":"崩坏3","permalink":"http://www.octber.xyz/tags/%E5%B4%A9%E5%9D%8F3/"}]},{"title":"2019.8.7日报","slug":"2019-8-7日报","date":"2019-08-09T07:30:52.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/09/2019-8-7日报/","link":"","permalink":"http://www.octber.xyz/2019/08/09/2019-8-7%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.7日报","text":"前言2019.8.7日报 今日 由于个人电脑问题(最终推断是因为电源问题,导致CPU速度太低),太卡了,重装了系统,浪费了很多时间,虽然通过加班完成了部分作棒给的任务,上班期间不能好好打码还是需要反思 另外: 明后天需要请假,努力挤出时间在外边再打打码,把剩余的问题解决 控制人信息和纳税人信息录入 难点 主信息对应多个控制人和纳税人信息 控制人对应多个纳税人信息 解决方案 表单的DTO中有控制人的List,控制人的List中又有纳税人的List 表单的DTO中有纳税人的DTO 开户信息查询略 开户信息修改略","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"MySQL底层原理简析","slug":"MySQL底层原理简析","date":"2019-08-06T12:09:06.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/06/MySQL底层原理简析/","link":"","permalink":"http://www.octber.xyz/2019/08/06/MySQL%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%E7%AE%80%E6%9E%90/","excerpt":"前言简单分析了解MySQL底层原理","text":"前言简单分析了解MySQL底层原理 感谢码到城攻文章对我的指导 感谢秋风醉了文章对我的指导 1.MySQL逻辑架构 MySQL的逻辑结构分为三层，分别为：客户端层、核心服务层、存储引擎层： 1.1 客户层连接处理、授权认证、安全等功能均在这一层处理； 1.2 核心服务层包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现，如：存储过程、触发器、视图等； 1.3 存储引擎层其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异； 2.MySQL逻辑流程 一条SQL语句的执行流程是什么样的呢? 2.1 客户端和服务端的通信协议​ mysql客户端和服务器的通信协议是半双工的，这意味着在任何时刻，要么由服务器向客户端发送数据，要么由客户端向服务器发送数据，这两个动作不能同时发生。所以我们无法也无须将一个消息切成小块独立来发送。 ​ 这种协议让mysql通信简单快速，但也从很多地方限制了mysql。一个明显的限制是没法进行流量控制。一旦一端开始发送消息，另一端要接收完整个消息才能响应它。 ​ 客户端用一个单独的数据包将查询传给服务器。一旦客户端发送了请求，他能做的事情就只是等待结果了。 ​ 相反的，一般服务器响应给用户的数据通常很多，由多个数据包组成。当服务器开始响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，或者接收完几条结果后就粗暴地断开连接。这也是在必要的时候一定要在查询中加上limit限制的原因。 ​ 多数连接mysql 的库函数都可以获得全部结果集并缓存到内存中，还可以逐行获取需要的数据，默认一般是获取全部结果集并缓存到内存中。mysql通常要等待所有的数据都已经发送给客户端才能释放这条查询所占用的资源，所以接收全部结果并缓存通常可以减少服务器的压力，让查询能够早点结束，早点释放相应的资源。 ​ 当使用多数连接mysql的库函数从mysql获取数据时，其结果看起来都像是从mysql服务器获取数据，而实际上都是从这个库函数的缓存获取数据。多数情况下这没什么问题，但是如果需要返回一个很大的结果集的时候，这样做并不好，因为库函数会花很多时间和内存来存储所有的结果集。如果能够尽早开始处理这些结果集，就能大大减少内存的消耗，这种情况下可以不使用缓存来记录结果而是直接处理。这样做的缺点是，对于服务器来说，需要查询完成后才能释放资源，所以在和客户端交互的整个过程中，服务器的资源都是被这个查询所占用的。 2.2 查询缓存2.2.1 什么情况会使用缓存​ 在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。 2.2.2 缓存原理MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。 2.2.3 什么情况下进行缓存如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。 2.2.4 缓存失效既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外。 2.2.5 缓存的优缺点 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗 所以，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化。 例如： 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存 最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。 2.3 语法解析和预处理 语法解析 MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。 预处理 预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等。 2.4 查询优化经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。 MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。 2.5 查询执行引擎在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handler API。查询过程中的每一张表由一个handler实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。 2.6结果数据返回查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如该查询影响到的行数以及执行时间等。 如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。 结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。 2.7 一个查询过程的总结 客户端向MySQL服务器发送一条查询请求 服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段 服务器进行SQL解析、预处理、再由优化器生成对应的执行计划 MySQL根据执行计划，调用存储引擎的API来执行查询 将结果返回给客户端，同时缓存查询结果 2.8 事务支持InnoDB的本地事务由资源管理器进行管理: 事务的 ACID 是通过 InnoDB 日志和锁来保证； 事务的隔离性是通过数据库锁的机制实现的； 持久性通过 Redo Log（重做日志）来实现； 原子性和一致性通过Undo Log 来实现； 123456789101112事务管理（ACID）谈到事务一般都是以下四点1. 原子性（Atomicity）原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。2. 一致性（Consistency）事务前后数据的完整性必须保持一致。3. 隔离性（Isolation）事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。4. 持久性（Durability）持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响&#x2F;&#x2F; 优秀博文: https:&#x2F;&#x2F;blog.csdn.net&#x2F;dengjili&#x2F;article&#x2F;details&#x2F;82468576 2.8.1 Undo LogUndo Log 的原理是，为了满足事务的原子性，在操作数据之前，首先将这个数据备份到一个地方（这个存储数据备份的地方称为 Undo Log）。然后进行数据的修改。 如果事务范围内出现了错误或者用户执行了 Rollback 语句，系统就会利用Undo Log中的备份，将数据恢复到事务开始之前的状态。 2.8.2 Redo Log和 Undo Log 相反，Redo Log 记录的是新数据的备份。在事务提交前，只要将Redo Log 持久化即可，不需要将数据持久化。 当系统崩溃时，虽然数据没有持久化，但是 Redo Log已经持久化。系统会根据 Redo Log 的内容，将所有数据恢复到最新的状态。 3. 性能优化3.1 Scheme设计与数据类型优化选择数据类型只要遵循小而简单的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用DATETIME来存储时间，而不是使用字符串。 通常来说把可为NULL的列改为NOT NULL不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为NOT NULL。 整数类型指定宽度，比如INT(11)，没有任何卵用。INT使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的。 UNSIGNED表示不允许负值，大致可以使正数的上限提高一倍。比如TINYINT存储范围是-128 ~ 127，而UNSIGNED TINYINT存储的范围却是0 - 255。 通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用BIGINT存储。这样可以避免浮点数计算不准确和DECIMAL精确计算代价高的问题。 TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。 大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用ALTER TABLE（如果只只是在列表末尾追加元素，不需要重建表）。 schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。 大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇技淫巧可以解决这个问题，有兴趣可自行查阅。 3.2 创建高性能索引索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。 通常我们所说的索引是指B-Tree索引，它是目前关系型数据库中查找数据最为常用和有效的索引，大多数存储引擎都支持这种索引。使用B-Tree这个术语，是因为MySQL在CREATE TABLE或其它语句中使用了这个关键字，但实际上不同的存储引擎可能使用不同的数据结构，比如InnoDB就是使用的B+Tree。 关于BTree和B+Tree可以通过这篇博文了解: https://www.cnblogs.com/vianzhang/p/7922426.html B+Tree中的B是指balance，意为平衡。需要注意的是，B+树索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。 3.3 优化的建议 通常来说把可为NULL的列改为NOT NULL不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为NOT NULL 对整数类型指定宽度，比如INT(11)，没有任何卵用 INT使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的 没有太大的必要使用DECIMAL数据类型 即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用BIGINT存储。这样可以避免浮点数计算不准确和DECIMAL精确计算代价高的问题 DATETIME优于TIMESTAMP TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同 大多数情况下没有使用枚举类型的必要 其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用ALTER TABLE（如果只只是在列表末尾追加元素，不需要重建表） schema的列不要太多 原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高 对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引 应尽量避免在 where 子句中的索引字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描 1select id from t where num is null 最好不要给数据库索引字段留NULL，尽可能的使用 NOT NULL填充数据库. 备注、描述、评论之类的可以设置为 NULL，其他的，最好不要使用NULL。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。 应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描 应尽量避免在 where 子句中使用 or 来连接条件 如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描。 1select id from t where num&#x3D;10 or Name &#x3D; &#39;admin&#39;; 可改为： 123select id from t where num &#x3D; 10union allselect id from t where Name &#x3D; &#39;admin&#39;; in 和 not in 也要慎用，否则会导致全表扫描 1select id from t where num in(1,2,3); 对于连续值，可改为： 1select id from t where num between 1 and 3 很多时候用 exists 代替 in 123select num from a where num in(select num from b);#使用exists替换select num from a where exists(select 1 from b where num&#x3D;a.num); 模糊查询like将导致全表扫描 123select id from t where name like ‘%abc%’;#改为，或是用搜索引擎select id from t where name like ‘abc%’; 不要在where子句中使用参数 1select id from t where num &#x3D; @num 上面语句将导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。 可以使用强制索引来解困 1select id from t with(index(索引名)) where num &#x3D; @num; 避免在where子句中对字段进行表函数、算术运算或其他表达式运算 12select id from t where num&#x2F;2 &#x3D; 100;select id from t where substring(name,1,3) &#x3D; ’abc’; 这将导致引擎放弃使用索引而进行全表扫描。 应改为： 12select id from t where num &#x3D; 100*2;select id from t where name like &#39;abc%&#39;; 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致 尽量使用表变量来代替临时表 如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 尽量避免大事务操作，提高系统并发能力 尽量避免向客户端返回大数据量 若数据量过大，应该考虑相应需求是否合理，或者分页查询。 一、基础规范 （1）必须使用InnoDB存储引擎 解读：支持事务、行级锁、并发性能更好、CPU及内存缓存页优化使得资源利用率更高 （2）必须使用UTF8字符集 解读：万国码，无需转码，无乱码风险，节省空间 （3）数据表、数据字段必须加入中文注释 解读：N年后谁tm知道这个r1,r2,r3字段是干嘛的 （4）禁止使用存储过程、视图、触发器、Event 解读：高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能”。数据库擅长存储与索引，CPU计算还是上移吧 （5）禁止存储大文件或者大照片 解读：为何要让数据库做它不擅长的事情？大文件和照片存储在文件系统，数据库里存URI多好 二、命名规范 （6）只允许使用内网域名，而不是ip连接数据库 （7）线上环境、开发环境、测试环境数据库内网域名遵循命名规范 业务名称：xxx 线上环境：dj.xxx.db 开发环境：dj.xxx.rdb 测试环境：dj.xxx.tdb 从库在名称后加-s标识，备库在名称后加-ss标识 线上从库：dj.xxx-s.db 线上备库：dj.xxx-sss.db （8）库名、表名、字段名：小写，下划线风格，不超过32个字符，必须见名知意，禁止拼音英文混用 （9）表名t_xxx，非唯一索引名idx_xxx，唯一索引名uniq_xxx 三、表设计规范 （10）单实例表数目必须小于500 （11）单表列数目必须小于30 （12）表必须有主键，例如自增主键 解读： a）主键递增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和内存的使用 b）主键要选择较短的数据类型， Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率 c） 无主键的表删除，在row模式的主从架构，会导致备库夯住 （13）禁止使用外键，如果有外键完整性约束，需要应用程序控制 解读：外键会导致表与表之间耦合，update与delete操作都会涉及相关联的表，十分影响sql 的性能，甚至会造成死锁。高并发情况下容易造成数据库性能，大数据高并发业务场景数据库使用以性能优先 四、字段设计规范 （14）必须把字段定义为NOT NULL并且提供默认值 解读： a）null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化 b）null 这种类型MySQL内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多 c）null值需要更多的存储空，无论是表还是索引中每行中的null的列都需要额外的空间来标识 d）对null 的处理时候，只能采用is null或is not null，而不能采用=、in、&lt;、&lt;&gt;、!=、not in这些操作符号。如：where name!=’shenjian’，如果存在name为null值的记录，查询结果就不会包含name为null值的记录 （15）禁止使用TEXT、BLOB类型 解读：会浪费更多的磁盘和内存空间，非必要的大量的大字段查询会淘汰掉热数据，导致内存命中率急剧降低，影响数据库性能 （16）禁止使用小数存储货币 解读：使用整数吧，小数容易导致钱对不上 （17）必须使用varchar(20)存储手机号 解读： a）涉及到区号或者国家代号，可能出现+-() b）手机号会去做数学运算么？ c）varchar可以支持模糊查询，例如：like“138%” （18）禁止使用ENUM，可使用TINYINT代替 解读： a）增加新的ENUM值要做DDL操作 b）ENUM的内部实际存储就是整数，你以为自己定义的是字符串？ 五、索引设计规范 （19）单表索引建议控制在5个以内 （20）单索引字段数不允许超过5个 解读：字段超过5个时，实际已经起不到有效过滤数据的作用了 （21）禁止在更新十分频繁、区分度不高的属性上建立索引 解读： a）更新会变更B+树，更新频繁的字段建立索引会大大降低数据库性能 b）“性别”这种区分度不大的属性，建立索引是没有什么意义的，不能有效过滤数据，性能与全表扫描类似 （22）建立组合索引，必须把区分度高的字段放在前面 解读：能够更加有效的过滤数据 六、SQL使用规范 （23）禁止使用SELECT *，只获取必要的字段，需要显示说明列属性 解读： a）读取不需要的列会增加CPU、IO、NET消耗 b）不能有效的利用覆盖索引 c）使用SELECT *容易在增加或者删除字段后出现程序BUG （24）禁止使用INSERT INTO t_xxx VALUES(xxx)，必须显示指定插入的列属性 解读：容易在增加或者删除字段后出现程序BUG （25）禁止使用属性隐式转换 解读：SELECT uid FROM t_user WHERE phone=13812345678 会导致全表扫描，而不能命中phone索引，猜猜为什么？（这个线上问题不止出现过一次） （26）禁止在WHERE条件的属性上使用函数或者表达式 解读：SELECT uid FROM t_user WHERE from_unixtime(day)&gt;=’2017-02-15’ 会导致全表扫描 正确的写法是：SELECT uid FROM t_user WHERE day&gt;= unix_timestamp(‘2017-02-15 00:00:00’) （27）禁止负向查询，以及%开头的模糊查询 解读： a）负向查询条件：NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT IN、NOT LIKE等，会导致全表扫描 b）%开头的模糊查询，会导致全表扫描 （28）禁止大表使用JOIN查询，禁止大表使用子查询 解读：会产生临时表，消耗较多内存与CPU，极大影响数据库性能 （29）禁止使用OR条件，必须改为IN查询 解读：旧版本Mysql的OR查询是不能命中索引的，即使能命中索引，为何要让数据库耗费更多的CPU帮助实施查询优化呢？ （30）应用程序必须捕获SQL异常，并有相应处理","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.octber.xyz/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.octber.xyz/tags/MySQL/"}]},{"title":"2019.8.6日报","slug":"2019-8-6日报","date":"2019-08-06T03:28:06.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/06/2019-8-6日报/","link":"","permalink":"http://www.octber.xyz/2019/08/06/2019-8-6%E6%97%A5%E6%8A%A5/","excerpt":"前言2019.8.6日报","text":"前言2019.8.6日报 1.反洗钱基本信息录入1.1 前端 前端字段较多,需要仔细核对,截图展示一部分 1.1.1 前端页面 1.1.2 页面说明1.1.2.1【开户-确认】按钮说明页面必须输入项目检查成功后，把数据分别存入: 场外代销账户类申报表otc_tagentaccountapp(会有字段冗余，页面上有项目保存到对应字段即可) otc_tamlsuitableapp otc_tamlbeneficiaryapp otc_tamlshareholderapp otc_tcrsmaininfoapp otc_tcrscontrollerapp otc_tcrstaxpayerapp otc_tcrsmaiTotaxpayerapp otc_tcrscontrollerTotaxpayerapp 页面上的文件先通过bg的文件上传接口临时保存到ftp上以当前日期命名的文件夹里，点【开户-确认】时正式上传到销售机构的ftp上（文件名需要按照文件规则重名称，注意有2个ftp，一个是机构通临时存放文件的ftp）。 1.2 后端1.2.1 数据库 所有数据针对申报表 数据库表: 反洗钱与适当性信息明细申报表 表名: otc_tamlsuitableapp 表备注: 反洗钱与适当性信息明细申报表，存放反洗钱基本信息和适当性的内容。 1.2.2 DTO/DO/Convertor… 使用生成工具mybatis-generator 123&lt;table tableName=&quot;otc_tamlsuitableapp&quot; domainObjectName=&quot;AmlSuitablAapp&quot;&gt; &lt;property name=&quot;subPackage&quot; value=&quot;business.basis&quot;/&gt;&lt;/table&gt; 1.2.3 业务逻辑实现 注意添加事务处理,具体过程略,实现🆗 2.(反洗钱)受益人信息2.1 前端 前端页面如下 2.2 后端2.2.1 数据库 数据库表: 反洗钱受益人申报明细表 表名: otc_tamlbeneficiaryapp 表注释: 反洗钱受益人申报明细表 2.2.2 DTO/DO/Convertor… 使用生成工具mybatis-generator 12345&lt;table tableName=&quot;otc_tamlbeneficiaryapp&quot; domainObjectName=&quot;AmlBeneficiaryApp&quot;&gt; &lt;property name=&quot;subPackage&quot; value=&quot;business.basis&quot;/&gt;&lt;/table&gt; 2.2.3 业务逻辑实现 注意添加事务处理,具体过程略,实现🆗 3.(反洗钱)股东信息3.1 前端 前端页面如下 3.2 后端3.2.1 数据库 数据库表: 反洗钱股东信息申报明细表 表名: otc_tamlshareholderapp 表注释: (反洗钱)股东信息 3.2.2 DTO/DO/Convertor… 使用生成工具mybatis-generator 12345&lt;table tableName=&quot;otc_tamlshareholderapp&quot; domainObjectName=&quot;amlShareHolderApp&quot;&gt; &lt;property name=&quot;subPackage&quot; value=&quot;business.basis&quot;/&gt;&lt;/table&gt; 3.2.3 业务逻辑实现 注意添加事务处理,具体过程略,实现🆗 4.CRS信息主信息明细申报表3.1 前端 前端页面如下，本页面还没完全做完，使用原型 3.2 后端3.2.1 数据库 数据库表: 反洗钱股东信息申报明细表 表名: otc_tcrsmaininfoapp 表注释: (反洗钱)股东信息 3.2.2 DTO/DO/Convertor… 使用生成工具mybatis-generator 12345&lt;table tableName=&quot;otc_tcrsmaininfoapp&quot; domainObjectName=&quot;CrsMainInfoApp&quot;&gt; &lt;property name=&quot;subPackage&quot; value=&quot;business.basis&quot;/&gt;&lt;/table&gt; 3.2.3 业务逻辑实现 注意添加事务处理,具体过程略,实现🆗 CRS纳税人信息明细申报表,[无居民国家/地区纳税人识别号的原因类型] 字段 或【纳税人识别号】2者，2选1必须输入。 CRS控制人信息明细申报表，【姓名】必须输入。是指其他数据有输入时，【姓名】必须输入。 其他任务略","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"【动漫杂图】第0期","slug":"【动漫杂图】第0期","date":"2019-08-06T02:09:25.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/06/【动漫杂图】第0期/","link":"","permalink":"http://www.octber.xyz/2019/08/06/%E3%80%90%E5%8A%A8%E6%BC%AB%E6%9D%82%E5%9B%BE%E3%80%91%E7%AC%AC0%E6%9C%9F/","excerpt":"前言动漫杂图,第0期, 多图警告!⚠","text":"前言动漫杂图,第0期, 多图警告!⚠","categories":[{"name":"动漫专栏","slug":"动漫专栏","permalink":"http://www.octber.xyz/categories/%E5%8A%A8%E6%BC%AB%E4%B8%93%E6%A0%8F/"}],"tags":[{"name":"动漫杂图","slug":"动漫杂图","permalink":"http://www.octber.xyz/tags/%E5%8A%A8%E6%BC%AB%E6%9D%82%E5%9B%BE/"}]},{"title":"将博客搬至CSDN","slug":"将博客搬至CSDN","date":"2019-08-05T12:50:18.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/05/将博客搬至CSDN/","link":"","permalink":"http://www.octber.xyz/2019/08/05/%E5%B0%86%E5%8D%9A%E5%AE%A2%E6%90%AC%E8%87%B3CSDN/","excerpt":"前言","text":"前言","categories":[],"tags":[]},{"title":"2019.8.5日报","slug":"2019-8-5日报","date":"2019-08-05T01:06:52.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/05/2019-8-5日报/","link":"","permalink":"http://www.octber.xyz/2019/08/05/2019-8-5%E6%97%A5%E6%8A%A5/","excerpt":"2019.8.5日报","text":"2019.8.5日报 今日内容1.待定内容 由于本周四到周日需要去芜湖参加2019年全国计算机设计大赛的答辩,所以安排在周四周五的任务,需要提前了解完成 任务内容: 3.27资金交收复核 3.27 资金交收复核 李浩田 8月7日 8月9日 但是由于目前还没有确定,所以现在做不了咯 2.文件上传任务 帮助作棒学长完成页面的一部分较为独立的内容:文件上传的功能 2.1 需求分析 前端使用HUI组件上传 后端首先接收文件并存放到一个临时文件夹内(可配置) 再点击提交后将文件夹内的内容统一存放到指定的服务器上 **注意: **文件命名有相应的规范 注意: 同一个文件上传框,可能上传多次,只保留最后一次上传的最新版本 2.2 前端实现 HUI有相关示例代码,根据HUI中的Demo,我们可以快速构建用于我们需求的组件 12345678910111213&lt;template&gt; &lt;div&gt; &lt;h-upload multiple type=&quot;drag&quot; action=&quot;//jsonplaceholder.typicode.com/posts/&quot;&gt; &lt;div style=&quot;padding: 20px 0&quot;&gt; &lt;h-icon type=&quot;ios-cloud-upload&quot; size=&quot;52&quot; style=&quot;color: #3399ff&quot;&gt;&lt;/h-icon&gt; &lt;p&gt;点击或将文件拖拽到这里上传&lt;/p&gt; &lt;/div&gt; &lt;/h-upload&gt; &lt;/div&gt;&lt;/template&gt; 前端实现效果: 2.3 后端遇到了一些问题，主要是逻辑和源代码的理解，遇到一些bg和bgb之间Api调用的问题 在config/index.js中,由于js是脚本语言,所以根据执行顺序,下面顺序不能有错,否则会出现上传接口不能使用的问题: 123456789101112131415&#x27;/bgb/file&#x27;: &#123; target: &#x27;http://10.20.29.235:8088&#x27;, changeOrigin: true, onProxyReq(proxyReq, req) &#123; proxyReq.setHeader(&#x27;Content-Type&#x27;, req.headers[&#x27;content-type&#x27;]); &#125;, pathRewrite: &#123; &#x27;^/bgb&#x27;: &#x27;&#x27; &#125;,&#125;,&#x27;/bg&#x27;: &#123; // target: &#x27;http://10.20.39.153:10086&#x27;, target: &#x27;http://10.20.29.235:8088&#x27;, // target: &#x27;http://10.20.30.5:10086&#x27;, changeOrigin: true, autoRewrite: true,&#125;, 其他作棒学长继续布置的其他任务 明日继续协助作棒学长把他那一块比较复杂的内容搞完，我负责Api的支持，前端复杂的对应关系，有学长完成。","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.3日报","slug":"2019-8-3日报","date":"2019-08-03T01:57:01.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/03/2019-8-3日报/","link":"","permalink":"http://www.octber.xyz/2019/08/03/2019-8-3%E6%97%A5%E6%8A%A5/","excerpt":"2019.8.3日报","text":"2019.8.3日报 今日任务1.将字典转化为JSON 概述: 本来是可以用工具导入的，但是我是用不了office,安装不了,所以只能自己写程序导入 1.1.1 数据处理将excel处理成逗号分隔的csv文件 1.1.2 数据读入使用fastCSV的maven中包工具导入 123456&lt;!-- fastcsv --&gt;&lt;dependency&gt; &lt;groupId&gt;de.siegmar&lt;/groupId&gt; &lt;artifactId&gt;fastcsv&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt;&lt;/dependency&gt; 1.1.3 数据封装1.1.4 数据处理1.1.5 JSON输出","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.2日报","slug":"2019-8-2日报","date":"2019-08-02T03:06:59.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/02/2019-8-2日报/","link":"","permalink":"http://www.octber.xyz/2019/08/02/2019-8-2%E6%97%A5%E6%8A%A5/","excerpt":"2019.8.2日报","text":"2019.8.2日报 今日总结1.账户类业务申报记录前后端全部实现 只是搜索和数据展示 1.1遗留问题解决1.1.1 菜单问题 最好的办法是使用Excel修改，但是目前条件不允许，可以使用以下方法，但是要在使用后找其他人更新Excel 修改application.properties中的配置 1system.table.change.mode=upgrade 修改数据库bgb_tsystemversion： 删除其中的记录，重新运行程序，就会做一次menu的更新 直接修改bg_tmenu,复制其他的数据自己修改 后续操作: 在基础组中的菜单模板管理中拖拽相应的菜单到指定区域 在人员信息中分配指定权限即可 1.1.2 原型确认早晨找海龙确认前端原型,以祥哥昨天指定的字段为准 1.2 前端 前端页面在昨天完成一大半,确认UI后做了一定的修改,加上了对应的接口 实现页面方法 1.3 后端1.3.1 完成搜索功能1234567/** * 查询对应查询条件的所有场外代销账户 * @param agentAccountAppDTO 场外代销账户类申报表 * @return 所有满足条件的场外代销账户类 */ @CloudFunction(functionId = Functions.QUERY_AGENT_ACCOUNT, desc = &quot;查询对应查询条件的所有场外代销账户&quot;) ApiResult&lt;Page&lt;AgentAccountAppDTO&gt;&gt; queryAgentAccountApp(@NotNull AgentAccountAppDTO agentAccountAppDTO); 1.3.2 BaseCommonQueryMapper的后端使用学习 Mapper通过extends BaseCommonQueryMapper&lt;Type, Type&gt;可以获得很多非常方便的封装好的函数 2.遗留问题 关于h-query-grid使用效果的问题,建议之后自己写代码完成,不依赖封装过度的组件 关于搜索选项的问题和原型,海龙还要更新新的UI,到时候做细微调整,本页面基本完成 3.字典维护 任务: 把excel中的字典转化为指定数据类型的json 工具 自己写代码读取","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.8.1日报","slug":"2019-8-1日报","date":"2019-08-01T02:51:38.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/08/01/2019-8-1日报/","link":"","permalink":"http://www.octber.xyz/2019/08/01/2019-8-1%E6%97%A5%E6%8A%A5/","excerpt":"2019.8.1日报","text":"2019.8.1日报 今日总结 概述: 积累了专业名词 基本完成了账户类业务申报记录前端页面(表格字段需要再确认) 进步: 不确定的东西要尽早确认 win10更新禁止掉,省的浪费时间 原型和UI和字段要仔细确认好 1.任务概述 3.1.2 账户类业务申报记录: 查询账户申报订单 概述:完成前端页面和部分后端开发,定时任务交给作棒完成 前端开发 菜单=&gt;杨鑫帮忙开设菜单 原型确定=&gt;海龙帮忙确认 基础页面开发 后端开发 未定 任务描述: 1.1 原型问题 原型存在冲突,需要确定 1.1.1 文档中原型 1.1.2 蓝湖UI原型(确定为以此为准) 1.2 主要流程 查询确认数据，维度：申报日期，确认日期，销售渠道，产品名称，产品代码，状态（注：可多选），TA代码等； 状态更新： 查询账户确认数据； 按销售机构返回的数据匹配申报记录，以“申请日期+订单编号”； 开户订单归档条件： T+1开户成功或失败归档； T+5强制归档； 页面列表中“…”不展示，详情双击查看； 2.数据表设计2.1 涉及到的数据表 otc_tagentaccountapp name: 场外代销账户类申报表 desc: 字段命名大部需要与外部接口规定字段名统一 otc_topenaccountfilesapp name: 场外开户文件资料明细申报表 otc_tamlsuitableapp name: 反洗钱与适当性信息明细申报表 desc: 反洗钱与适当性信息明细申报表，存放反洗钱基本信息和适当性的内容 otc_tamlbeneficiaryapp name: 反洗钱受益人申报明细表 otc_tamlshareholderapp name: 反洗钱股东信息申报明细表 otc_tcrsmaininfoapp name: CRS信息主信息明细申报表 otc_tcrscontrollerapp name: CRS控制人信息明细申报表 otc_tcrstaxpayerapp name: CRS纳税人信息明细申报表 otc_tcrsmaiTotaxpayerapp name: CRS信息主信息与纳税人明细申报的关系 otc_tcrscontrollerTotaxpayerapp name: CRS控制人信息与纳税人明细申报的关系 等 2.1.1 分析记录 otc_tcrsmaiTotaxpayerapp和otc_tcrscontrollerTotaxpayerapp是对应关系表 otc_tcrsmaiTotaxpayerapp结构: 12345678create table otc_tcrsmaiTotaxpayerapp( company_id int(11) not null, crsmaininfoapp_id int(11) not null, crstaxpayerapp_id int(11) not null, date numeric(8) not null, primary key (company_id, crsmaininfoapp_id, crstaxpayerapp_id, date)); otc_tcrscontrollerTotaxpayerapp结构 12345678create table otc_tcrscontrollerTotaxpayerapp( company_id int(11) not null, crscontrollerapp_id int(11) not null, crstaxpayerapp_id int(11) not null, date numeric(8) not null, primary key (company_id, crscontrollerapp_id, crstaxpayerapp_id, date)); 3.专业名词积累3.1 什么是场内？什么是场外？ “场”，是证券交易场所的意思 我们内地有两个证券交易场所，分别是上海证券交易场所和深圳证券交易场所 场内购买，就是需要在券商那里开户 券商有中信证券，海通证券，广发证券，华泰证券，华泰证券等等 一个人可以开三个证券账户 场外是第三方APP，一些代销平台，比如支付宝，理财通，蛋卷基金，且慢，天天基金等 如何选择? 如果是短期投资，走场内，费率低。如果是长期投资，场内场外都差不多。场外收取的是申购赎回费，虽然申购费一般比场内的费用贵，但是赎回费的话，一般持有2年之后就不用收取了。而且场内的买卖佣金费，无论持有多久都是要收取的。 如果场内的交易额不大，建议场外申赎。因为场内交易额不大的话，可能买不了或者卖不出去。场外是跟基金公司直接交易的，不会出现这个问题。 3.2 反洗钱3.2.1 什么是洗钱 巴塞尔银行: 犯罪分子及其同伙利用金融系统将资金从一个帐户转向另一个账户，以掩盖款项的真实来裸和受益所有权关系;或者利用金融系统提供的资金保管服务存放款项，就是常说的“洗钱” 央行对洗钱的解释是: 洗钱是指毒品犯罪、黑社会性质的组织犯罪、恐怖活动犯罪、走私犯罪或者其他犯罪的违法所得及其产生的收益，通过各种手段掩饰、隐瞒其来源和性质，使其在形式上合法化，这样的行为就是洗钱。也就是说把来路不正“不干净“的非法收人变成“千净”的钱，就叫做“洗钱“，又称.洗黑钱”。 3.2.2 如何通过基金洗钱? 来源博客小曹反洗钱的博客 ​ 境外资金通过银行直接购买A股基金，不仅违背了境外个人投资国内A股基金应通过合格境外机构投资者办理的相关规定，甚至可能成为海外资金洗钱的一个通道. ​ 据上海一家基金公司监察稽核部人士表示，目前监管层要求基金公司和所有代销机构签署反洗钱补充协议，但因为一些大型代销渠道过于强势且不愿意签署反洗钱补充协议，因此该公司签署反洗钱条款情况不太理想。据他透露，这一情况在小基金公司内比较普遍。 ​ 他介绍，反洗钱补充条款主要是针对客户身分识别、可疑交易报告、交易记录等多方面内容，其中最重要的是对反洗钱责任划分的条款。“如果不签署反洗钱补充条款，一旦出现问题，基金公司要负主要责任。不过，即使签署了这类条款，大银行在某些条款上也非常苛刻，尽量将责任推给基金公司。”因此他认为，这是银行对境外资金买A股基金开绿灯的一个重要原因。 ​ 据证券时报记者了解，目前多数基金公司已签署了反洗钱补充条例，这类协议条款基本符合监管层的要求，但在某些具体环节上划分得不够仔细。深圳一家基金公司人士分析，境外资金直接购买A股基金，其中核心是对客户资料的核实。“这主要是银行所进行的工作，目前绝大部分银行不将客户资料提供给基金公司，基金公司想查很难。” 3.2.3 如何防止洗钱 中华人民共和国反洗钱法 制定完整的反洗钱内部控制制度； 建立健全客户身份识别(know your client)体系； 制定客户身份资料和交易记录保存制度； 进行大额交易和可以交易报告。 3.2 CRS(共同申报准则)CRS起源和目的 CRS的提出者是经济合作与发展组织，也就是OECD（经合组织）。而概念是来自美国的美国海外账户税收遵从法（FATCA）。 CRS旨在推动国与国之间税务信息自动交换 CRS在中国:中国2015年已经加入了CRS，到去年9月份第一次跟别的国家交换信息，所以这事儿最近几个月才火起来。 历史了解：略 4.页面处理 页面初始化：数据来源otc_tagentaccountapp。查询条件为申请日。排序申请日、申报编号降序 查询：查询 导出：按照查询条件导出excel，字段同一览表 5.任务流程5.1 添加菜单1234567891011121314151617181920&#123; &quot;company_id&quot;: 0, &quot;menu_code&quot;:&quot;050415&quot;, &quot;menu_name&quot;:&quot;账号类业务申报记录&quot;, &quot;menu_parent_code&quot;:&quot;0504&quot;, &quot;subsys_no&quot;:3340, &quot;menu_name_eng&quot;:&quot;AccountRecord&quot;, &quot;url&quot;:&quot;/account/accountRecord/index&quot;, &quot;window_show&quot;:&quot;&quot;, &quot;create_type&quot;:&quot;&quot;, &quot;sort_no&quot;:15, &quot;field_status&quot;:&quot;1&quot;, &quot;icon&quot;:&quot;&quot;, &quot;operator_mode&quot;:0, &quot;group_code&quot;:&quot;&quot;, &quot;custom_industry_code&quot;:&quot;&quot;, &quot;authorize_code&quot;:&quot;&quot;, &quot;custom_id&quot;:&quot;&quot;, &quot;bizframeurl&quot;:&quot;/bgb/#/account/accountRecord/indexM050415&quot;&#125; 执行clean然后install,添加菜单,然后添加权限: 然而今天杨鑫没搞成功，一直没添加上，先写出来，之后拷贝进来吧 5.2 页面表格字段(需再确认) 数据来源otc_tagentaccountapp 申请编号 otc_report_seq 日期 create_user 销售机构编号 agency_code 业务类型 busin_type 申报状态 status 产品ID fund_id 产品代码 fund_code 产品简称 fund_name 投资人交易账号 fund_trade_account 基金账号 fund_account 开户TA代码 ta_code 申报状态的错误信息 erro_info 5.3 账号申报类转机机定时任务说明未进行到这一步 5.4 账号类回填转机机定时任务说明未进行到这一步","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.7.31日报","slug":"2019-7-31日报","date":"2019-07-31T02:15:48.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/31/2019-7-31日报/","link":"","permalink":"http://www.octber.xyz/2019/07/31/2019-7-31%E6%97%A5%E6%8A%A5/","excerpt":"2019.7.31日报","text":"2019.7.31日报 日报1.增开基金账户显示taCodes1.1 数据库表bgb_ttradeaccount、otc_ttradeaccount_ex、bgb_tfund、bgb_tinvestfundinfo（TA下拉数据） 1.2 页面处理说明 页面初始化：交易账号来源于bgb_ttradeaccount、产品数据来源bgb_tfund、TA数据来源于bgb_tinvestfundinfo表（需要去重）。 【确认】按钮：页面数据保存与otc_tagentaccountapp表，只保存交易账号字段、渠道、TA代码、业务类型（009:增开基金账户）。 1.3 后端业务逻辑1.3.1 DTO/DO/Query修改对bgb_tinvestfundinfo表新增了agency_code字段 在DTO/DO/Query中添加agency_code 12345/** * 销售渠道代码 */@Column(name = &quot;agency_code&quot;, length = 16, nullable = false)private String agencyCode; 1.3.2 具体实现 在Service-Api中和Impl中实现其对应方法 管理平台上线Api 前端调用,获取数据,显示所有taCode 2.保存增开账户信息2.1 数据库要求页面数据保存与otc_tagentaccountapp场外代销账户类申报表，只保存交易账号字段、渠道、TA代码、业务类型（009:增开基金账户）。 表:otc_tagentaccountapp 保存字段: 交易账号fundTradeAccount 销售渠道agencyCode TA代码taCode 业务类型(009)businType 2.2 后台接口实现2.2.1 代码生成器 配置数据源 配置数据表 123&lt;table tableName=&quot;otc_tagentaccountapp&quot; domainObjectName=&quot;AgentAccountApp&quot;&gt; &lt;property name=&quot;subPackage&quot; value=&quot;agentaccountapp&quot;/&gt;&lt;/table&gt; 配置生成的文件位置 先都搞到/src/generated,然后按需导入项目,随后删掉无用文件 第一次失败原因:没有写对数据源地址 第二次失败原因:Integer和BigDecimal生成有错误,需要手动改正 特别感谢:邓斯学长 2.2.2 书写业务逻辑 按照上述数据库要求,匹配字段 使用默认生成的insert方法即可快速插入 2.2.3 逻辑漏洞2.2.3.1 有问题的逻辑: 作为一个插入操作,如果不存在应当插入 如果已经存在 (做Update操作) 不同: 更新 相同: 不更新 2.2.3.2 正确的逻辑 在用户选择的时候就用该剔除已经用过的TA段 用户选择好的一定是不存在的 2.2.4 共同维护自增序列问题:otc_tagentaccountapp.agentaccountapp_id和otc_ttradeorder.tradeorder_id共同维护自增序列 创建OperatorNoSequence类,定义其中的表明和自增字段名 使用他的nextValue()函数获得下一个值 明日计划 做新任务 多学学业务,看看专业名词","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"深入理解JVM","slug":"深入理解JVM","date":"2019-07-30T08:36:42.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/30/深入理解JVM/","link":"","permalink":"http://www.octber.xyz/2019/07/30/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/","excerpt":"前言","text":"前言 JDK组成 最下面的Java HotSpot VM就是Java虚拟机,JDK比JRE多的其实就是一些工具类,而JRE包含了Java虚拟机和一些核心类库,Java虚拟机有很多种实现方式,IBM,Google等大公司都有其实现,现在主要以Oracle的为主 Java文件的运行 一个Java代码,首先通过Javac编译生成字节码文件(.class),随后交予JVM进行执行,生成对应平台的二进制机器码,所以JDK有很多版本,对windows的版本,对Linux的版本等等,最终生成的机器码是不一样的,正因为一份字节码文件可以通过JVM适配不同的平台,所以Java能够实现”一次编写,到处运行”的功能 JVM组成 JVM包括三部分: 类安装子系统 执行引擎 运行时数据区(内存模型) 栈(线程)在main的主线程中,每个函数的局部范围都会开辟一块栈帧内存区,并保证先进后出,最上面的往往是优先级最高,作用范围最小的,里面可能有局部变量表等","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"}]},{"title":"深入解析Java反射","slug":"深入解析Java反射","date":"2019-07-30T08:35:24.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/30/深入解析Java反射/","link":"","permalink":"http://www.octber.xyz/2019/07/30/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Java%E5%8F%8D%E5%B0%84/","excerpt":"前言Java中的反射时刻在用，如果对这哥了解不能深入，谈何了解Java？","text":"前言Java中的反射时刻在用，如果对这哥了解不能深入，谈何了解Java？ 经过个人的学习和优秀博文的整理，得到以下内容，侵删。 特别鸣谢：sczyh30 1.什么是反射 Oracle官方的解释： Reflection enables Java code to discover information about the fields, methods and constructors of loaded classes, and to use reflected fields, methods, and constructors to operate on their underlying counterparts, within security restrictions.The API accommodates applications that need access to either the public members of a target object (based on its runtime class) or the members declared by a given class. It also allows programs to suppress default reflective access control. 1.1 定义反射 (Reflection) 是 Java 的特征之一，它允许运行中的 Java 程序获取自身的信息，并且可以操作类或对象的内部属性。 1.2 功能我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 简而言之：我们一般通过类寻找对象，现在我们可以通过对象寻找类，这就是反射的“反” 核心：反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 2.反射的主要用途 有一个例子很多大神在讲的时候都会说到： 当我们在使用 IDE(如 Eclipse，IDEA)时，当我们输入一个对象或类并想调用它的属性或方法时，一按点号，编译器就会自动列出它的属性或方法，这里就会用到反射。 那么我举一个实战中的常见的例子： 在JavaEE最基础的Servlet技术中我们配置Web.xml，在xml中： 12345678&lt;servlet&gt; &lt;servlet-name&gt;ChangeFactory&lt;/servlet-name&gt; &lt;servlet-class&gt;com.drugs.Servlet.ChangeFactoryServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;ChangeFactory&lt;/servlet-name&gt; &lt;url-pattern&gt;/ChangeFactory&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 我们通过配置url为/ChangeFactory，映射到com.drugs.Servlet.ChangeFactoryServlet去自动化创建类的对象并调用他的函数，执行对应的操作，这就是JVM在运行中进行的反射操作，他可以构造任意一个类的对象并且调用其中的方法。可以说反射是各种容器实现的核心。当我们深入源代码去理解的时候，就会发现反射虽小，虽基础，但是起到了非常大的作用。 3.反射的基本应用 反射相关的类一般都在java.lang.relfect包里 3.1 获得Class对象方法有三种： (1) 使用 Class 类的 forName 静态方法:比如在 JDBC 开发中常用此方法加载数据库驱动: 12public static Class&lt;?&gt; forName(String className)java Class.forName(driver); (2)直接获取某一个对象的 class，比如:1Class&lt;?&gt; klass = int.class;Class&lt;?&gt; classInt = Integer.TYPE; (3)调用某个对象的 getClass() 方法，比如:1StringBuilder str = new StringBuilder(&quot;123&quot;);Class&lt;?&gt; klass = str.getClass(); 3.2 判断是否为某个类的实例一般地，我们用 instanceof 关键字来判断是否为某个类的实例。同时我们也可以借助反射中 Class 对象的 isInstance() 方法来判断是否为某个类的实例，它是一个 native 方法： 1public native boolean isInstance(Object obj); 3.3 创建实例通过反射来生成对象主要有两种方式。 使用Class对象的newInstance()方法来创建Class对象对应类的实例。 1Class&lt;?&gt; c = String.class;Object str = c.newInstance(); 先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例。这种方法可以用指定的构造器构造类的实例。 1//获取String所对应的Class对象Class&lt;?&gt; c = String.class;//获取String类带一个String参数的构造器Constructor constructor = c.getConstructor(String.class);//根据构造器创建实例Object obj = constructor.newInstance(&quot;23333&quot;);System.out.println(obj); 3.4 获取方法获取某个Class对象的方法集合，主要有以下几个方法： getDeclaredMethods 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 1public Method[] getDeclaredMethods() throws SecurityException getMethods 方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。 1public Method[] getMethods() throws SecurityException getMethod 方法返回一个特定的方法，其中第一个参数为方法名称，后面的参数为方法的参数对应Class的对象。 1public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 只是这样描述的话可能难以理解，我们用例子来理解这三个方法： 123456789101112131415161718192021222324252627282930package org.ScZyhSoft.common;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;public class test1 &#123; public static void test() throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;?&gt; c = methodClass.class; Object object = c.newInstance(); Method[] methods = c.getMethods(); Method[] declaredMethods = c.getDeclaredMethods(); //获取methodClass类的add方法 Method method = c.getMethod(&quot;add&quot;, int.class, int.class); //getMethods()方法获取的所有方法 System.out.println(&quot;getMethods获取的方法：&quot;); for(Method m:methods) System.out.println(m); //getDeclaredMethods()方法获取的所有方法 System.out.println(&quot;getDeclaredMethods获取的方法：&quot;); for(Method m:declaredMethods) System.out.println(m); &#125; &#125;class methodClass &#123; public final int fuck = 3; public int add(int a,int b) &#123; return a+b; &#125; public int sub(int a,int b) &#123; return a+b; &#125;&#125; 程序运行的结果如下: 123456789101112131415getMethods获取的方法：public int org.ScZyhSoft.common.methodClass.add(int,int)public int org.ScZyhSoft.common.methodClass.sub(int,int)public final void java.lang.Object.wait() throws java.lang.InterruptedExceptionpublic final void java.lang.Object.wait(long,int) throws java.lang.InterruptedExceptionpublic final native void java.lang.Object.wait(long) throws java.lang.InterruptedExceptionpublic boolean java.lang.Object.equals(java.lang.Object)public java.lang.String java.lang.Object.toString()public native int java.lang.Object.hashCode()public final native java.lang.Class java.lang.Object.getClass()public final native void java.lang.Object.notify()public final native void java.lang.Object.notifyAll()getDeclaredMethods获取的方法：public int org.ScZyhSoft.common.methodClass.add(int,int)public int org.ScZyhSoft.common.methodClass.sub(int,int) 3.5 获取构造器信息获取类构造器的用法与上述获取方法的用法类似。主要是通过Class类的getConstructor方法得到Constructor类的一个实例，而Constructor类有一个newInstance方法可以创建一个对象实例: 1public T newInstance(Object ... initargs) 此方法可以根据传入的参数来调用对应的Constructor创建对象实例。 3.6 获取类的成员变量（字段）信息主要是这几个方法，在此不再赘述： getFiled：访问公有的成员变量 getDeclaredField：所有已声明的成员变量，但不能得到其父类的成员变量 getFileds 和 getDeclaredFields 方法用法同上（参照 Method）。 3.7 调用方法 关于invoke()的详情，请查看: https://www.sczyh30.com/posts/Java/java-reflection-1/ 当我们从类中获取了一个方法后，我们就可以用 invoke() 方法来调用这个方法。invoke 方法的原型为: 123public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException 例子: 123456789101112131415161718192021public class test1 &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;?&gt; klass = methodClass.class; //创建methodClass的实例 Object obj = klass.newInstance(); //获取methodClass类的add方法 Method method = klass.getMethod(&quot;add&quot;,int.class,int.class); //调用method对应的方法 =&gt; add(1,4) Object result = method.invoke(obj,1,4); System.out.println(result); &#125;&#125;class methodClass &#123; public final int fuck = 3; public int add(int a,int b) &#123; return a+b; &#125; public int sub(int a,int b) &#123; return a+b; &#125;&#125; 3.8 利用反射创建数组数组在Java里是比较特殊的一种类型，它可以赋值给一个Object Reference。下面我们看一看利用反射创建数组的例子： 123456789101112public static void testArray() throws ClassNotFoundException &#123; Class&lt;?&gt; cls = Class.forName(&quot;java.lang.String&quot;); Object array = Array.newInstance(cls,25); //往数组里添加内容 Array.set(array,0,&quot;hello&quot;); Array.set(array,1,&quot;Java&quot;); Array.set(array,2,&quot;fuck&quot;); Array.set(array,3,&quot;Scala&quot;); Array.set(array,4,&quot;Clojure&quot;); //获取某一项的内容 System.out.println(Array.get(array,3)); &#125; 其中的Array类为java.lang.reflect.Array类。我们通过Array.newInstance()创建数组对象，它的原型是: 1234public static Object newInstance(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException &#123; return newArray(componentType, length); &#125; 而 newArray 方法是一个 native 方法，它在 HotSpot JVM 里的具体实现我们后边再研究，这里先把源码贴出来： 12private static native Object newArray(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException; 源码目录：openjdk\\hotspot\\src\\share\\vm\\runtime\\reflection.cpp 123456789101112131415161718arrayOop Reflection::reflect_new_array(oop element_mirror, jint length, TRAPS) &#123; if (element_mirror == NULL) &#123; THROW_0(vmSymbols::java_lang_NullPointerException()); &#125; if (length &lt; 0) &#123; THROW_0(vmSymbols::java_lang_NegativeArraySizeException()); &#125; if (java_lang_Class::is_primitive(element_mirror)) &#123; Klass* tak = basic_type_mirror_to_arrayklass(element_mirror, CHECK_NULL); return TypeArrayKlass::cast(tak)-&gt;allocate(length, THREAD); &#125; else &#123; Klass* k = java_lang_Class::as_Klass(element_mirror); if (k-&gt;oop_is_array() &amp;&amp; ArrayKlass::cast(k)-&gt;dimension() &gt;= MAX_DIM) &#123; THROW_0(vmSymbols::java_lang_IllegalArgumentException()); &#125; return oopFactory::new_objArray(k, length, THREAD); &#125;&#125; 另外，Array 类的 set 和 get 方法都为 native 方法，在 HotSpot JVM 里分别对应 Reflection::array_set 和 Reflection::array_get 方法，这里就不详细解析了。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/tags/Java/"}]},{"title":"VO/DTO/DO/PO的区别","slug":"VO-DTO-DO-PO的区别","date":"2019-07-30T03:52:11.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/30/VO-DTO-DO-PO的区别/","link":"","permalink":"http://www.octber.xyz/2019/07/30/VO-DTO-DO-PO%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"前言浅析VO、DTO、DO、PO的概念、区别和用处","text":"前言浅析VO、DTO、DO、PO的概念、区别和用处 浅析VO、DTO、DO、PO的概念、区别和用处转载：http://www.cnblogs.com/qixuejia/p/4390086.html 本篇文章主要讨论一下我们经常会用到的一些对象：VO、DTO、DO和PO。 由于不同的项目和开发人员有不同的命名习惯，这里我首先对上述的概念进行一个简单描述，名字只是个标识，我们重点关注其概念： 概念： VO**（View Object**）：视图对象，用于展示层，它的作用是把某个指定页面（或组件）的所有数据封装起来。 DTO**（Data Transfer Object**）：数据传输对象，这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载，但在这里，我泛指用于展示层与服务层之间的数据传输对象。 DO**（Domain Object**）：领域对象，就是从现实世界中抽象出来的有形或无形的业务实体。 PO**（Persistent Object**）：持久化对象，它跟持久层（通常是关系型数据库）的数据结构形成一一对应的映射关系，如果持久层是关系型数据库，那么，数据表中的每个字段（或若干个）就对应PO的一个（或若干个）属性。 模型： ​ 下面以一个时序图建立简单模型来描述上述对象在三层架构应用中的位置 l 用户发出请求（可能是填写表单），表单的数据在展示层被匹配为VO。 l 展示层把VO转换为服务层对应方法所要求的DTO，传送给服务层。 l 服务层首先根据DTO的数据构造（或重建）一个DO，调用DO的业务方法完成具体业务。 l 服务层把DO转换为持久层对应的PO（可以使用ORM工具，也可以不用），调用持久层的持久化方法，把PO传递给它，完成持久化操作。 l 对于一个逆向操作，如读取数据，也是用类似的方式转换和传递，略。 VO**与DTO**的区别 ​ 大家可能会有个疑问（在笔者参与的项目中，很多程序员也有相同的疑惑）：既然DTO是展示层与服务层之间传递数据的对象，为什么还需要一个VO呢？对！对于绝大部分的应用场景来说，DTO和VO的属性值基本是一致的，而且他们通常都是POJO，因此没必要多此一举，但不要忘记这是实现层面的思维，对于设计层面来说，概念上还是应该存在VO和DTO，因为两者有着本质的区别，DTO代表服务层需要接收的数据和返回的数据，而VO代表展示层需要显示的数据。 ​ 用一个例子来说明可能会比较容易理解：例如服务层有一个getUser的方法返回一个系统用户，其中有一个属性是gender(性别)，对于服务层来说，它只从语义上定义：1-男性，2-女性，0-未指定，而对于展示层来说，它可能需要用“帅哥”代表男性，用“美女”代表女性，用“秘密”代表未指定。说到这里，可能你还会反驳，在服务层直接就返回“帅哥美女”不就行了吗？对于大部分应用来说，这不是问题，但设想一下，如果需求允许客户可以定制风格，而不同风格对于“性别”的表现方式不一样，又或者这个服务同时供多个客户端使用（不同门户），而不同的客户端对于表现层的要求有所不同，那么，问题就来了。再者，回到设计层面上分析，从职责单一原则来看，服务层只负责业务，与具体的表现形式无关，因此，它返回的DTO，不应该出现与表现形式的耦合。 ​ 理论归理论，这到底还是分析设计层面的思维，是否在实现层面必须这样做呢？一刀切的做法往往会得不偿失，下面我马上会分析应用中如何做出正确的选择。 VO**与DTO**的应用 ​ 上面只是用了一个简单的例子来说明VO与DTO在概念上的区别，本节将会告诉你如何在应用中做出正确的选择。 ​ 在以下才场景中，我们可以考虑把VO与DTO二合为一（注意：是实现层面）： l 当需求非常清晰稳定，而且客户端很明确只有一个的时候，没有必要把VO和DTO区分开来，这时候VO可以退隐，用一个DTO即可，为什么是VO退隐而不是DTO？回到设计层面，服务层的职责依然不应该与展示层耦合，所以，对于前面的例子，你很容易理解，DTO对于“性别”来说，依然不能用“帅哥美女”，这个转换应该依赖于页面的脚本（如JavaScript）或其他机制（JSTL、EL、CSS） l 即使客户端可以进行定制，或者存在多个不同的客户端，如果客户端能够用某种技术（脚本或其他机制）实现转换，同样可以让VO退隐 以下场景需要优先考虑VO、DTO并存： l 上述场景的反面场景 l 因为某种技术原因，比如某个框架（如Flex）提供自动把POJO转换为UI中某些Field时，可以考虑在实现层面定义出VO，这个权衡完全取决于使用框架的自动转换能力带来的开发和维护效率提升与设计多一个VO所多做的事情带来的开发和维护效率的下降之间的比对。 l 如果页面出现一个“大视图”，而组成这个大视图的所有数据需要调用多个服务，返回多个DTO来组装（当然，这同样可以通过服务层提供一次性返回一个大视图的DTO来取代，但在服务层提供一个这样的方法是否合适，需要在设计层面进行权衡）。 DTO**与DO**的区别 ​ 首先是概念上的区别，DTO是展示层和服务层之间的数据传输对象（可以认为是两者之间的协议），而DO是对现实世界各种业务角色的抽象，这就引出了两者在数据上的区别，例如UserInfo和User（对于DTO和DO的命名规则，请参见笔者前面的一篇博文），对于一个getUser方法来说，本质上它永远不应该返回用户的密码，因此UserInfo至少比User少一个password的数据。而在领域驱动设计中，正如第一篇系列文章所说，DO不是简单的POJO，它具有领域业务逻辑。 DTO**与DO**的应用 ​ 从上一节的例子中，细心的读者可能会发现问题：既然getUser方法返回的UserInfo不应该包含password，那么就不应该存在password这个属性定义，但如果同时有一个createUser的方法，传入的UserInfo需要包含用户的password，怎么办？在设计层面，展示层向服务层传递的DTO与服务层返回给展示层的DTO在概念上是不同的，但在实现层面，我们通常很少会这样做（定义两个UserInfo，甚至更多），因为这样做并不见得很明智，我们完全可以设计一个完全兼容的DTO，在服务层接收数据的时候，不该由展示层设置的属性（如订单的总价应该由其单价、数量、折扣等决定），无论展示层是否设置，服务层都一概忽略，而在服务层返回数据时，不该返回的数据（如用户密码），就不设置对应的属性。 ​ 对于DO来说，还有一点需要说明：为什么不在服务层中直接返回DO呢？这样可以省去DTO的编码和转换工作，原因如下： l 两者在本质上的区别可能导致彼此并不一一对应，一个DTO可能对应多个DO，反之亦然，甚至两者存在多对多的关系。 l DO具有一些不应该让展示层知道的数据 l DO具有业务方法，如果直接把DO传递给展示层，展示层的代码就可以绕过服务层直接调用它不应该访问的操作，对于基于AOP拦截服务层来进行访问控制的机制来说，这问题尤为突出，而在展示层调用DO的业务方法也会因为事务的问题，让事务难以控制。 l 对于某些ORM框架（如Hibernate）来说，通常会使用“延迟加载”技术，如果直接把DO暴露给展示层，对于大部分情况，展示层不在事务范围之内（Open session in view在大部分情况下不是一种值得推崇的设计），如果其尝试在Session关闭的情况下获取一个未加载的关联对象，会出现运行时异常（对于Hibernate来说，就是LazyInitiliaztionException）。 l 从设计层面来说，展示层依赖于服务层，服务层依赖于领域层，如果把DO暴露出去，就会导致展示层直接依赖于领域层，这虽然依然是单向依赖，但这种跨层依赖会导致不必要的耦合。 对于DTO来说，也有一点必须进行说明，就是DTO应该是一个“扁平的二维对象”，举个例子来说明：如果User会关联若干个其他实体（例如Address、Account、Region等），那么getUser()返回的UserInfo，是否就需要把其关联的对象的DTO都一并返回呢？如果这样的话，必然导致数据传输量的大增，对于分布式应用来说，由于涉及数据在网络上的传输、序列化和反序列化，这种设计更不可接受。如果getUser除了要返回User的基本信息外，还需要返回一个AccountId、AccountName、RegionId、RegionName，那么，请把这些属性定义到UserInfo中，把一个“立体”的对象树“压扁”成一个“扁平的二维对象”，笔者目前参与的项目是一个分布式系统，该系统不管三七二十一，把一个对象的所有关联对象都转换为相同结构的DTO对象树并返回，导致性能非常的慢。 DO**与PO**的区别 ​ DO和PO在绝大部分情况下是一一对应的，PO是只含有get/set方法的POJO，但某些场景还是能反映出两者在概念上存在本质的区别： l DO在某些场景下不需要进行显式的持久化，例如利用策略模式设计的商品折扣策略，会衍生出折扣策略的接口和不同折扣策略实现类，这些折扣策略实现类可以算是DO，但它们只驻留在静态内存，不需要持久化到持久层，因此，这类DO是不存在对应的PO的。 l 同样的道理，某些场景下，PO也没有对应的DO，例如老师Teacher和学生Student存在多对多的关系，在关系数据库中，这种关系需要表现为一个中间表，也就对应有一个TeacherAndStudentPO的PO，但这个PO在业务领域没有任何现实的意义，它完全不能与任何DO对应上。这里要特别声明，并不是所有多对多关系都没有业务含义，这跟具体业务场景有关，例如：两个PO之间的关系会影响具体业务，并且这种关系存在多种类型，那么这种多对多关系也应该表现为一个DO，又如：“角色”与“资源”之间存在多对多关系，而这种关系很明显会表现为一个DO——“权限”。 l 某些情况下，为了某种持久化策略或者性能的考虑，一个PO可能对应多个DO，反之亦然。例如客户Customer有其联系信息Contacts，这里是两个一对一关系的DO，但可能出于性能的考虑（极端情况，权作举例），为了减少数据库的连接查询操作，把Customer和Contacts两个DO数据合并到一张数据表中。反过来，如果一本图书Book，有一个属性是封面cover，但该属性是一副图片的二进制数据，而某些查询操作不希望把cover一并加载，从而减轻磁盘IO开销，同时假设ORM框架不支持属性级别的延迟加载，那么就需要考虑把cover独立到一张数据表中去，这样就形成一个DO对应对个PO的情况。 l PO的某些属性值对于DO没有任何意义，这些属性值可能是为了解决某些持久化策略而存在的数据，例如为了实现“乐观锁”，PO存在一个version的属性，这个version对于DO来说是没有任何业务意义的，它不应该在DO中存在。同理，DO中也可能存在不需要持久化的属性。 DO**与PO**的应用 ​ 由于ORM框架的功能非常强大而大行其道，而且JavaEE也推出了JPA规范，现在的业务应用开发，基本上不需要区分DO与PO，PO完全可以通过JPA，Hibernate Annotations/hbm隐藏在DO之中。虽然如此，但有些问题我们还必须注意： l 对于DO中不需要持久化的属性，需要通过ORM显式的声明，如：在JPA中，可以利用@Transient声明。 l 对于PO中为了某种持久化策略而存在的属性，例如version，由于DO、PO合并了，必须在DO中声明，但由于这个属性对DO是没有任何业务意义的，需要让该属性对外隐藏起来，最常见的做法是把该属性的get/set方法私有化，甚至不提供get/set方法，但对于Hibernate来说，这需要特别注意，由于Hibernate从数据库读取数据转换为DO时，是利用反射机制先调用DO的空参数构造函数构造DO实例，然后再利用JavaBean的规范反射出set方法来为每个属性设值，如果不显式声明set方法，或把set方法设置为private，都会导致Hibernate无法初始化DO，从而出现运行时异常，可行的做法是把属性的set方法设置为protected。 l 对于一个DO对应多个PO，或者一个PO对应多个DO的场景，以及属性级别的延迟加载，Hibernate都提供了很好的支持，请参考Hibnate的相关资料。 ​ 到目前为止，相信大家都已经比较清晰的了解VO、DTO、DO、PO的概念、区别和实际应用了。通过上面的详细分析，我们还可以总结出一个原则：分析设计层面和实现层面完全是两个独立的层面，即使实现层面通过某种技术手段可以把两个完全独立的概念合二为一，在分析设计层面，我们仍然（至少在头脑中）需要把概念上独立的东西清晰的区分开来，这个原则对于做好分析设计非常重要（工具越先进，往往会让我们越麻木）。第一篇系列博文抛砖引玉，大唱领域驱动设计的优势，但其实领域驱动设计在现实环境中还是有种种的限制，需要选择性的使用，正如我在《田七的智慧》博文中提到，我们不能永远的理想化的去选择所谓“最好的设计”，在必要的情况下，我们还是要敢于放弃，因为最合适的设计才是最好的设计。本来，系列中的第二篇博文应该是讨论领取驱动设计的限制和如何选择性的使用，但请原谅我的疏忽，下一篇系列博文会把这个主题补上，敬请关注。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/tags/Java/"}]},{"title":"2019.7.30日报","slug":"2019-7-30日报","date":"2019-07-30T01:26:08.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/30/2019-7-30日报/","link":"","permalink":"http://www.octber.xyz/2019/07/30/2019-7-30%E6%97%A5%E6%8A%A5/","excerpt":"2019.7.30日报","text":"2019.7.30日报 一日概述 主要内容记录在【问题记录】中 1.上午上午主要进行学习： svn 前后台对接流程 管理控制台工作原理 前端模板 其他 2.下午 业务逻辑探究 后端接口书写 其他 问题记录 【发现问题】：学习过程中发现的新问题 【计划任务】：前一天计划要完成的任务 【学习记录】：记录备忘 1.【发现问题】没有使用svn检出项目，导致无法更新和上传代码。 产生原因： 刚来的时候没有域账号，大家复制代码给我，没有直接从svn检出代码 技术问题： 之前使用Git，没有使用过SVN 解决方案： 学习svn的具体使用方法——使用TortoiseSVN 正确检出所有源代码文件，就可以看到当前代码的状态，有svn的图标标注 svn源代码地址：https://192.168.57.155/HZYY/FIS1.0/trunk/Sources/0_FIS/ 2.【计划任务】前后端对接问题+管理控制台协同工作原理问题驱动学习 2.1左边栏菜单如何生成2.1.1后台定义业务基础（BGB）中菜单首先在/initData/BGB_TMENU.json中定义，数据格式为： 1234567891011121314151617181920&#123; &quot;company_id&quot;: 0, &quot;menu_code&quot;:&quot;050409&quot;, &quot;menu_name&quot;:&quot;产品单元组合&quot;, &quot;menu_parent_code&quot;:&quot;0504&quot;, &quot;subsys_no&quot;:3340, &quot;menu_name_eng&quot;:&quot;FundunitCombineView&quot;, &quot;url&quot;:&quot;/baseinfo/general/unitgrid/index&quot;, &quot;window_show&quot;:&quot;fundunitCombineView&quot;, &quot;create_type&quot;:&quot;&quot;, &quot;sort_no&quot;:9, &quot;field_status&quot;:&quot;1&quot;, &quot;icon&quot;:&quot;&quot;, &quot;operator_mode&quot;:0, &quot;group_code&quot;:&quot;&quot;, &quot;custom_industry_code&quot;:&quot;&quot;, &quot;authorize_code&quot;:&quot;&quot;, &quot;custom_id&quot;:&quot;&quot;, &quot;bizframeurl&quot;:&quot;/bgb/#/baseinfo/general/unitgrid/indexM050409&quot;&#125; 里面定义了一些关键信息，如名称menu_name，前端文件路由url，等。 后端会在运行时，根据这些信息，进行初始化菜单操作。 2.1.2前端动态路由表 src\\store\\modules\\permission.js下的permission.js文件用于动态生成路由表,根据后台传回的可用menus或者业务标识,递归过滤异步路由表，返回符合用户角色权限的路由表 根据输出,可以看到动态生成的路由的一部分: 详细内容 获取url的api为: 1import &#123; filedir &#125; from &#x27;@/api/url&#x27;; 而filedir的内容主要就是一个对应关系 123456789101112131415export const filedir = &#123; 3339: &#x27;/bg/&#x27;, 3349: &#x27;/bm/&#x27;, 3344: &#x27;/liq/&#x27;, 3348: &#x27;/zx/&#x27;, 3343: &#x27;/jys/&#x27;, 3346: &#x27;/yhj/&#x27;, 3345: &#x27;/otc/&#x27;, 3342: &#x27;/intb/&#x27;, 3347: &#x27;/der/&#x27;, 3341: &#x27;/ins/&#x27;, 3340: &#x27;/bgb/&#x27;, 3354: &#x27;/bgs/&#x27;, 3355: &#x27;/bgb/&#x27;,&#125;; 针对的是两个路由表: 12let asyncRouterMap = new Map();const asyncMenuPathMap = new Map(); 这两个Map用于储存对应的Router和Menu,具体的方法为: 123456789/** * 根据后台传回的可用menus或者业务标识,递归过滤异步路由表，返回符合用户角色权限的路由表 * @param router * @param menus * @param type 过滤类型 1菜单过滤，2业务标识过滤 */function filterRouterByArr(router, menus) &#123; ...&#125; 这个方法是通过一个递归,对Menus中的所有Menus中的所有children进行遍历,对每一个menu中的item的属性进行处理和存放:(部分代码) 12345let tempComName = `M$&#123;menu.menuCode&#125;`;let tempUrl = menu.url;let tempName = menu.menuName;let tempId = menu.menuCode;let tempHidden = menu.url.trim() === &#x27;&#x27;; 处理好后封装到一个route里面 123456789101112131415161718const route = &#123; path: tempUrl + tempComName, name: tempName, hidden: tempHidden, meta: &#123; icon: menu.icon, isKeepAlive: true, // 或者直接置为true comName: tempComName, rootId: menu.subsysNo, id: tempId, // 用于tabs切换时可以定位到菜单栏 windowShow: menu.windowShow, createType: menu.createType, sysPre: `$&#123;filedir[menu.subsysNo]&#125;#`, // subsysNo: menu.subsysNo, &#125;, redirect: menu.redirect, component: tempComp, // resolve =&gt; require([`@/views$&#123;tempUrl&#125;.vue`], resolve), &#125;; 这就一个动态route了,我们只需要把这个route放到router和两个Map中即可 123router.push(route);asyncRouterMap.set(tempId, route);asyncMenuPathMap.set(route.path, tempId); 可以看到,最后得到的一个完整的是route: 这个函数的功能就是返回一个return router; persimmon.js的功能不仅仅是做这样一个router,这只是一个工具,,我们真正需要返回的是一个permission的对象,他应该拥有哪些属性了? 1234567891011121314151617const permission = &#123; state: &#123; // routers: constantRouterMap, addRouters: [], searchRoute: [], // general: &#123;&#125;, routerMap: [], gridflash: &#123;&#125;, menuPathMap: [], &#125;, mutations: &#123; ... &#125;, action: &#123; ... &#125;&#125; 在action中就做了一些和刚才函数有关的操作: 12345678910111213// 根据服务端菜单生成路由GenerateRoutesByMenus(&#123; commit &#125;, data) &#123; return new Promise((resolve) =&gt; &#123; asyncRouterMap = new Map(); const accessedRouters = filterRouterByArr([], data); commit(&#x27;ADD_GRIDFLASH&#x27;, accessedRouters); commit(&#x27;SET_ROUTERS&#x27;, accessedRouters); commit(&#x27;SEARCH_ROUTE&#x27;, accessedRouters); commit(&#x27;SET_ROUTERMAP&#x27;, asyncRouterMap); commit(&#x27;SET_MENUPATH&#x27;, asyncMenuPathMap); resolve(); &#125;);&#125; 如何理解这里使用Promise的方法,首先通过廖雪峰大神对Promise的理解入手:https://www.liaoxuefeng.com/wiki/1022910821149312/1023024413276544 ,这种“承诺将来会执行”的对象在JavaScript中称为Promise对象,可见Promise最大的好处是在异步执行的流程中，把执行代码和处理结果的代码清晰地分离了,在做多个任务的时候,尤为有用，job1.then(job2).then(job3).catch(handleError); 在这里我们给的第一个参数router是[],第二个参数menu就是data 返回这个Promise 2.2后台Api+管理控制台2.2.1POM定义的SpringClod模块1234&lt;modules&gt; &lt;module&gt;am4-bgb-service-manage&lt;/module&gt; &lt;module&gt;am4-bgb-service-manage-api&lt;/module&gt;&lt;/modules&gt; 2.2.2后台为什么没有Controller？ am4-bgb-service-manage-api中定义了Api的定义，主要以接口interface为主 am4-bgb-service-manage主要为实现类，实现了具体的业务逻辑 关键在于am4-bgb-service-manage-api中Service使用的自定义注解： @CloudFunction(functionId= Functions.INSERT_FUNDACCOUNT, desc = &quot;新增基金账户&quot;) 和@CloudService，他们都来自com.hundsun.jrescloud.rpc.annotation这个包下，他们的作用是协同管理控制台，注册Service，从而省去了Controller模块，由管理控制台统一管理Api 通过可视化的上下线和流控，能够更好地进行Api的管理，同时当Api较多时也方便查找和控制。 而前端则通过Api的名字进行调用： 123async insertFundAccountInfo(FundAccount) &#123; return this.post(&#x27;insertFundAccount&#x27;, FundAccount);&#125; 3.【学习记录】国际化3.1国际化配置 src\\assets\\locale\\default\\zh-CN.js src\\assets\\locale\\default\\en-US.js 入口文件配置中文： 123import VueI18n from &#x27;vue-i18n&#x27;;import zhHuiLocale from &#x27;h_ui/dist/locale/zh-CN&#x27;;import zhLocale from &#x27;@/assets/locale/default/zh-CN&#x27;; 3.2国际化使用 具体使用： 1234&lt;h-button type=&quot;ghost&quot; size=&quot;small&quot; @click=&quot;addFispBankCode&quot; &gt;&#123;&#123;$t(&#x27;fans.common.add&#x27;)&#125;&#125;&lt;/h-button&gt; 使用$t(&#39;fans.common.add&#39;)来显示添加文字，如果配置为英文则显示add 如何切换语言？ this.$i18n.locale=zh-CN或this.$i18n.locale=en-US进行切换 vue-i18n 数据渲染的模板语法 $t(&#39;fans.common.add&#39;) 4.【学习记录】后台接口规范与逻辑4.1接口规范4.1.1@Valid 验证规范用于验证注解是否符合要求，直接加在变量之前，在变量中添加验证信息的要求，当不符合要求时就会在方法中返回message 的错误提示信息。 4.1.2@NotNull/@NotBlank/@NotEmpty的区别和约束 @NotNull CharSequence, Collection, Map 和 Array 对象不能是 null, 但可以是空集（size = 0）。 @NotEmpty CharSequence, Collection, Map 和 Array 对象不能是 null 并且相关对象的 size 大于 0。 @NotBlank String 不是 null 且去除两端空白字符后的长度（trimmed length）大于 0。 所以说对于一般的DTO而言，我们可以使用@NotNull，如果是String，我们可以使用@NotBlank。 4.1.3注释规范 函数功能注释 函数参数注释 函数返回值注释 5.【计划任务】新增基金账号业务逻辑5.1接口数据 销售机构 资管产品 交易账户 TA 5.2相关数据表 otc_tagentaccountApp（第三方代销账号申报表） 此表位于BG数据库 表备注 字段命名大部需要与外部接口规定字段名统一 unique约束字段 Name Type NULL Default Extras Comment company_id int(11) No agentaccountapp_id int(11) No 需要和otc_ttradeorder表，共用自增序列。 申请编号，至少保证当天内不能重复。 date numeric(8,0) No 问题：找不到otc_ttradeorder表？？ otc_TAGENTINVESTFUNDINFO（代销基金表—获取TA代码） 问题：找不到这张表？？ hisotc_tagentaccountApp（归档表） 问题：找不到这张表？？ bgb_ttradeaccount（交易账号表） 此表在BGB和BG中都有 问题：为什么BGB数据库表的编码集是GBK而不是UTF-8? 5.3业务逻辑 首先通过代销基金表—获取TA代码，拿到TA代码和其他的接口数据，填写到otc_tagentaccountApp(三方代销账号申报表)中 申报成功后，基金账号回填到bgb_tfundaccount 明日计划 继续研究业务逻辑 看懂后台封装的持久层代码逻辑 前端有页面就继续做 等待新任务布置","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"2019.7.29日报","slug":"2019-7-29日报","date":"2019-07-29T10:07:56.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/29/2019-7-29日报/","link":"","permalink":"http://www.octber.xyz/2019/07/29/2019-7-29%E6%97%A5%E6%8A%A5/","excerpt":"2019.7.29日报","text":"2019.7.29日报 上午 会议 任务分配 kpi详情 学习HUI相关组件 下午 完成增开基金账户页面 原型： 效果： 遗留问题： 本页面为父页面弹窗页，需要杨鑫做完调用 本页面提交的后台接口还没有做完 解决方案： 1. 等待杨鑫调用接口，提供实际数据 2. 继续学习后台业务逻辑 3. 继续学习后端框架技术流程 了解了前端代码组成 学习了数据库相关表内容，了解业务逻辑 明日计划 完成今日遗留问题 对接接口，完成后端开发和前端页面对接 了解前后端完整流程 等待作棒布置新任务","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"}]},{"title":"基于地点LBS的O2O现场问答移动应用","slug":"基于地点LBS的O2O现场问答移动应用","date":"2019-07-29T01:06:30.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/29/基于地点LBS的O2O现场问答移动应用/","link":"","permalink":"http://www.octber.xyz/2019/07/29/%E5%9F%BA%E4%BA%8E%E5%9C%B0%E7%82%B9LBS%E7%9A%84O2O%E7%8E%B0%E5%9C%BA%E9%97%AE%E7%AD%94%E7%A7%BB%E5%8A%A8%E5%BA%94%E7%94%A8/","excerpt":"前言全国计算机设计大赛-国家赛-芜湖-2019年8月8日","text":"前言全国计算机设计大赛-国家赛-芜湖-2019年8月8日 1.作品核心1.1关注秒级需求1.1.1用户定位 定位哪些用户？（作品价值？） 生活节奏快，对自己生活计划精准的工作人员——他们关注自己接下来行程的细节变化 不愿花费不必要时间和精力在未知的时间上的普通居民——他们关注自己的生活品质 大城市中生活节奏较快的人员 高级白领：生活计划井井有条、上下班节奏较快 快递行业：关注时时的路况、目标地点的 一般小区住户 一般女性：联络当下时某地点的其他人，顺路帮忙（购物等） 一般男性：关注某些娱乐场所当下状况（网吧、健身馆） 家长：对于孩子必经的一些关键路段或学校的信息能迅速获得一手信息 1.1.2用户需求 用户需求是什么？ 他们不希望通过非常官方的渠道获取信息，他们更希望获得“接地气”的回复 他们希望自己的需求能够立刻被满足，因为他们的需求往往不是很难 他们希望自己自己能时刻把握关键地点的具体信息，类似于一种“关注、监控” 用户需要一种小型的非官方为主的实时信息渠道。 备注：我们可以看到抖音上很多信息，都是非官方的，普通人贡献的，但是大家更愿意相信这种渠道的信息，因为这种信息往往没有利益引导趋向，往往最真实最贴切。 备注：应用领域非常广泛，但最经典的还是针对关键地点，密集人群，信息爆炸的场所。 1.2如何定义我们的“新型”O2O模式 什么是传统O2O模式？ 什么是我们的“新型O2O”模式？ 传统的O2O模式对于市场来说，最重要的并不是线上交流和交易，而是将客人引流到实体店，加以利用。 而我们对O2O进行创新发展，我们在注重线上基于地点实时信息共享的同时，将客户有引导性（遵循市场原则）地引流到合适的实体地点，从而实现用户的引流和前期定位，线下地点往往接受太多无用客户，这些客户不能带来有用的价值却占用了他们本身的时间和线下场所的资源，这对于用户和线下都是不希望看到的。而我们进行的“新型O2O”模式，为解决这一难题做出了调整。 如果用户使用本款APP，他可能不会前往他不值得去的地点，不会因此浪费时间，浪费公众资源 如果用户使用本款APP，他可能会获得基于地点的一手信息，有利于个人计划安排，更有利于社会资源合理利用 1.3如何定义我们的“新型”LBS服务 什么是传统LBS服务？ 什么是我们的“新型LBS”模式？ 传统的LBS服务往往基于地标、商家、机构点进行服务，他们提供更为官方的服务，如通过定位用户（GPS或移动运营商提供地点）当下地点，为他提供方圆1公里的咖啡馆、影院、图书馆等 而我们对LBS服务进行创新发展，我们认为应当发生一个转化，那就是让用户成为LBS规则的需求者，同时也让用户成为LBS规则的服务者。如果说传统LBS是“基于地点的公众号服务”，我们新型的LBS则是“基于地点的人群服务”，简单来说，只要你指定地点附近有“人”即可进行服务，我们无需关心这些“人”是否具备服务的能力，因为这些人作为指定地点下此时此刻存在的个体，他们提供服务并无成本。 这样，我们就可以实现LBS的定点服务，而不是区域服务。 ##2.PPT内容及演讲者备注 2.1 作品简介 这个经典场景我觉得不管怎么想,都看起来有种无用的感觉,因为我们关注点的问题,为了升华价值,进行深入剖析 演讲者备注:作品愿景： 服务变简单？免去复杂的“自由人-公众号-机器人”或者“自由人-公众号-专业的服务人员”的流程，简单到“自由人-自由人”的服务 5G形式最核心的就是信息变得更为丰富，很多信息转瞬即逝，信息如何保值？掌握第一手信息的往往并不是官方，而是“现场的人”，他们掌握信息，他们分享无成本。 经典应用场景： 看似简单的场景，蕴含着商业引导和个人取舍的关键问题： 移动营业厅是核心需求，只有营业厅人少用户才有去的动力，但是其他因素也是市场中存在的非常重要的因素，那就是附加服务，移动营业厅附近可能有用户“可能”需要去的超市，这就为超市和用户带来双向的服务与消费的关系 “推荐”的核心是“大数据”，而在5G下，每一秒的信息都是“大数据”。而这一秒的数据可能再下一秒就失去价值。这就是我们所关注的核心。 2.2 作品内容 删除了无用的PPT,精简语言 本页面主要说一些基本的作品流程,让评委有一个直观的感受 演讲者备注:在线问 强调非学术性和日常性，这是作品定位的核心。投放机制 推荐机制，算法处理，标签，分类，检索等 在线帮： 强调使用文字+图片/短视频的方式，这是4G/5G时代下信息趋向多维度丰富性的特点 现场帮 成为提问者的第三只眼，让问题解决成为“同步”到现场的的“现场快照” 专注效率 2.3 作品核心 参考1.作品核心内容,完成本节的PPT内容 2.3.1 关注秒级需求 演讲者备注:1.用户定位 大城市中生活节奏较快的人员 高级白领：生活计划井井有条、上下班节奏较快 快递行业：关注时时的路况、目标地点的 一般小区住户 一般女性：联络当下时某地点的其他人，顺路帮忙（购物等） 一般男性：关注某些娱乐场所当下状况（网吧、健身馆） 家长：对于孩子必经的一些关键路段或学校的信息能迅速获得一手信息 用户需求用户需要一种小型的非官方为主的实时信息渠道。 备注：我们可以看到抖音上很多信息，都是非官方的，普通人贡献的，但是大家更愿意相信这种渠道的信息，因为这种信息往往没有利益引导趋向，往往最真实最贴切。 备注：应用领域非常广泛，但最经典的还是针对关键地点，密集人群，信息爆炸的场所。 2.3.2 如何定义我们的”新型O2O”模式 演讲者备注:而我们对O2O进行创新发展，我们在注重线上基于地点实时信息共享的同时，将客户有引导性（遵循市场原则）地引流到合适的实体地点，从而实现用户的引流和前期定位，线下地点往往接受太多无用客户，这些客户不能带来有用的价值却占用了他们本身的时间和线下场所的资源，这对于用户和线下都是不希望看到的。而我们进行的“新型O2O”模式，为解决这一难题做出了调整。 2.3.3 如何定义我们的“新型”LBS服务 演讲者备注:传统的LBS服务往往基于地标、商家、机构点进行服务，他们提供更为官方的服务，如通过定位用户（GPS或移动运营商提供地点）当下地点，为他提供方圆1公里的咖啡馆、影院、图书馆等 而我们对LBS服务进行创新发展，我们认为应当发生一个转化，那就是让用户成为LBS规则的需求者，同时也让用户成为LBS规则的服务者。如果说传统LBS是“基于地点的公众号服务”，我们新型的LBS则是“基于地点的人群服务”，简单来说，只要你指定地点附近有“人”即可进行服务，我们无需关心这些“人”是否具备服务的能力，因为这些人作为指定地点下此时此刻存在的个体，他们提供服务并无成本。 这样，我们就可以实现LBS的定点服务，而不是区域服务。 2.4 作品优势2.4.1 用户分析 演讲者备注无 2.4.2 竞品分析 演讲者备注无 2.5 作品技术直接查看PPT 2.6 作品展示直接查看PPT","categories":[{"name":"Android","slug":"Android","permalink":"http://www.octber.xyz/categories/Android/"}],"tags":[{"name":"比赛","slug":"比赛","permalink":"http://www.octber.xyz/tags/%E6%AF%94%E8%B5%9B/"}]},{"title":"集合框架查漏补缺","slug":"集合框架查漏补缺","date":"2019-07-22T02:00:32.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/22/集合框架查漏补缺/","link":"","permalink":"http://www.octber.xyz/2019/07/22/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/","excerpt":"前言","text":"前言","categories":[],"tags":[]},{"title":"优秀博客和网站收录","slug":"优秀博客和网站收录","date":"2019-07-17T05:16:13.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/17/优秀博客和网站收录/","link":"","permalink":"http://www.octber.xyz/2019/07/17/%E4%BC%98%E7%A7%80%E5%8D%9A%E5%AE%A2%E5%92%8C%E7%BD%91%E7%AB%99%E6%94%B6%E5%BD%95/","excerpt":"前言平时浏览器收藏总会丢失，索性在这里收录我觉得优秀的博文和网站。","text":"前言平时浏览器收藏总会丢失，索性在这里收录我觉得优秀的博文和网站。 编程相关 Qt学习之路:https://www.devbean.net/category/qt-study-road-2/ 数据库相关 关系型数据库是如何工作的:https://www.devbean.net/category/数据库/ 手册相关 唯品会Java开发手册:https://vipshop.github.io/vjtools/#/standard/ 阿里巴巴Java开发手册:https://github.com/alibaba/p3c","categories":[{"name":"小工具","slug":"小工具","permalink":"http://www.octber.xyz/categories/%E5%B0%8F%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"收藏","slug":"收藏","permalink":"http://www.octber.xyz/tags/%E6%94%B6%E8%97%8F/"}]},{"title":"Go数据底层的存储","slug":"Go数据底层的存储","date":"2019-07-03T11:40:45.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/03/Go数据底层的存储/","link":"","permalink":"http://www.octber.xyz/2019/07/03/Go%E6%95%B0%E6%8D%AE%E5%BA%95%E5%B1%82%E7%9A%84%E5%AD%98%E5%82%A8/","excerpt":"前言填坑参考 https://research.swtch.com/godata","text":"前言填坑参考 https://research.swtch.com/godata","categories":[{"name":"Go","slug":"Go","permalink":"http://www.octber.xyz/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://www.octber.xyz/tags/Go/"}]},{"title":"Go学习资料","slug":"Go学习资料","date":"2019-07-03T01:59:41.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/07/03/Go学习资料/","link":"","permalink":"http://www.octber.xyz/2019/07/03/Go%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/","excerpt":"前言Go学习资料","text":"前言Go学习资料 A Tour of Go:点击访问 好处: 在线打代码,在线运行,教程简单易懂 **缺点:**可能需要翻墙,教程太基础,有一定编程基础的人,不太建议 golang-book:点击访问 **好处:**大佬写的,专业全面 **缺点:**全英文 雨痕的《go语言学习笔记》:点击访问 **好处:**GitHub大牛文档,专业全面 **缺点:**貌似很久没有更新了 Go轻松学:点击访问Go示例学: 点击访问Go Web 编程: 点击访问 golang书籍学习大全: 点击访问 这个里面有很多其他的教程,很全,可见Github真的是有很多好东西,天啦噜! 《Go编程基础》 Unknwon/go-fundamental-programming · GitHub 《Go Web基础》 Unknwon/go-web-foundation · GitHub 《Go名库讲解》 Unknwon/go-rock-libraries-showcases · GitHub","categories":[{"name":"Go","slug":"Go","permalink":"http://www.octber.xyz/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://www.octber.xyz/tags/Go/"}]},{"title":"Vue-基础篇","slug":"Vue-基础篇","date":"2019-06-21T01:04:34.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/21/Vue-基础篇/","link":"","permalink":"http://www.octber.xyz/2019/06/21/Vue-%E5%9F%BA%E7%A1%80%E7%AF%87/","excerpt":"前言本系列学习，基于下面这位掘金作者，讲的很详细，而且免费看，对于vue学习者非常有好处。 作者：花裤衩 链接：https://juejin.im/post/59097cd7a22b9d0065fb61d2","text":"前言本系列学习，基于下面这位掘金作者，讲的很详细，而且免费看，对于vue学习者非常有好处。 作者：花裤衩 链接：https://juejin.im/post/59097cd7a22b9d0065fb61d2 components这里往往放一些全局经常会用到的组件，比如左边栏，有些组件用于规范化页面风格，比如每个页面的主体内容头部应该怎样规范等。而页面是不写在这个地方的，写在views里面。 storeVuex 是一个专为 Vue.js 应用程序开发的状态管理模式。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。Vuex 也集成到 Vue 的官方调试工具 devtools extension，提供了诸如零配置的 time-travel 调试、状态快照导入导出等高级调试功能。 但是由于Vuex的数据，在页面刷新的时候就会没有，而且本质上很多数据没必要储存在Vuex中，所以Vuex并不是必备的，甚至我们可以考虑使用Session Stroge来储存用户信息，解决用户刷信页面就需要重新登录的问题，将权限控制更多的交给后端来做，如果要用Vuex，那也要在每次刷新的时候让Vuex获取Session Stroge的信息进行重新储存。 如果是Android开发，使用Vuex就十分有用了，因为用户不可能在手机端刷新页面。 alias当项目逐渐变大之后，文件与文件直接的引用关系会很复杂，这时候就需要使用alias 了。 有的人喜欢alias 指向src目录下，再使用相对路径找文件 12345678alias: &#123; &#x27;src&#x27;: path.resolve(__dirname, &#x27;../src&#x27;), &#x27;components&#x27;: path.resolve(__dirname, &#x27;../src/components&#x27;), &#x27;api&#x27;: path.resolve(__dirname, &#x27;../src/api&#x27;), &#x27;utils&#x27;: path.resolve(__dirname, &#x27;../src/utils&#x27;), &#x27;store&#x27;: path.resolve(__dirname, &#x27;../src/store&#x27;), &#x27;router&#x27;: path.resolve(__dirname, &#x27;../src/router&#x27;)&#125; axiosAxios 是一个基于 promise 的 HTTP 库，可以用在浏览器和 node.js 中。 特性 从浏览器中创建 XMLHttpRequests 从 node.js 创建 http 请求 支持 Promise API 拦截请求和响应 转换请求数据和响应数据 取消请求 自动转换 JSON 数据 客户端支持防御 XSRF 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import axios from &#x27;axios&#x27;import &#123; Message &#125; from &#x27;element-ui&#x27;import store from &#x27;@/store&#x27;import &#123; getToken &#125; from &#x27;@/utils/auth&#x27;// 创建axios实例const service = axios.create(&#123; baseURL: process.env.BASE_API, // api的base_url timeout: 5000 // 请求超时时间&#125;)// request拦截器service.interceptors.request.use(config =&gt; &#123; // Do something before request is sent if (store.getters.token) &#123; config.headers[&#x27;X-Token&#x27;] = getToken() // 让每个请求携带token--[&#x27;X-Token&#x27;]为自定义key 请根据实际情况自行修改 &#125; return config&#125;, error =&gt; &#123; // Do something with request error console.log(error) // for debug Promise.reject(error)&#125;)// respone拦截器service.interceptors.response.use( response =&gt; response, /** * 下面的注释为通过response自定义code来标示请求状态，当code返回如下情况为权限有问题，登出并返回到登录页 * 如通过xmlhttprequest 状态码标识 逻辑可写在下面error中 */ // const res = response.data; // if (res.code !== 20000) &#123; // Message(&#123; // message: res.message, // type: &#x27;error&#x27;, // duration: 5 * 1000 // &#125;); // // 50008:非法的token; 50012:其他客户端登录了; 50014:Token 过期了; // if (res.code === 50008 || res.code === 50012 || res.code === 50014) &#123; // MessageBox.confirm(&#x27;你已被登出，可以取消继续留在该页面，或者重新登录&#x27;, &#x27;确定登出&#x27;, &#123; // confirmButtonText: &#x27;重新登录&#x27;, // cancelButtonText: &#x27;取消&#x27;, // type: &#x27;warning&#x27; // &#125;).then(() =&gt; &#123; // store.dispatch(&#x27;FedLogOut&#x27;).then(() =&gt; &#123; // location.reload();// 为了重新实例化vue-router对象 避免bug // &#125;); // &#125;) // &#125; // return Promise.reject(&#x27;error&#x27;); // &#125; else &#123; // return response.data; // &#125; error =&gt; &#123; console.log(&#x27;err&#x27; + error)// for debug Message(&#123; message: error.message, type: &#x27;error&#x27;, duration: 5 * 1000 &#125;) return Promise.reject(error) &#125;)export default service 12345678910import request from &#x27;@/utils/request&#x27;//使用export function getInfo(params) &#123; return request(&#123; url: &#x27;/user/info&#x27;, method: &#x27;get&#x27;, params &#125;);&#125; 比如后台项目，每一个请求都是要带 token 来验证权限的，这样封装以下的话我们就不用每个请求都手动来塞 token，或者来做一些统一的异常处理，一劳永逸。 而且因为我们的 api 是根据 env 环境变量动态切换的，如果以后线上出现了bug，我们只需配置一下 @/config/dev.env.js 再重启一下服务，就能在本地模拟线上的环境了。 12345module.exports = &#123; NODE_ENV: &#x27;&quot;development&quot;&#x27;, BASE_API: &#x27;&quot;https://api-dev&quot;&#x27;, //修改为&#x27;&quot;https://api-prod&quot;&#x27;就行了 APP_ORIGIN: &#x27;&quot;https://wallstreetcn.com&quot;&#x27; //为公司打个广告 pc站为vue+ssr&#125; 多环境vue-cli 默认只提供了dev和prod两种环境。但其实正真的开发流程可能还会多一个sit或者stage环境，就是所谓的测试环境和预发布环境。所以我们就要简单的修改一下代码。其实很简单就是设置不同的环境变量 123&quot;build:prod&quot;: &quot;NODE_ENV=production node build/build.js&quot;,&quot;build:sit&quot;: &quot;NODE_ENV=sit node build/build.js&quot;,复制代码 之后在代码里自行判断，想干就干啥 12var env = process.env.NODE_ENV === &#x27;production&#x27; ? config.build.prodEnv : config.build.sitEnv复制代码 新版的 vue-cli 也内置了 webpack-bundle-analyzer 一个模块分析的东西，相当的好用。使用方法也很简单，和之前一样封装一个 npm script 就可以。 1234567//package.json &quot;build:sit-preview&quot;: &quot;cross-env NODE_ENV=production env_config=sit npm_config_preview=true npm_config_report=true node build/build.js&quot;//之后通过process.env.npm_config_report来判断是否来启用webpack-bundle-analyzervar BundleAnalyzerPlugin = require(&#x27;webpack-bundle-analyzer&#x27;).BundleAnalyzerPluginwebpackConfig.plugins.push(new BundleAnalyzerPlugin()) router-viewdifferent router the same component vue。真实的业务场景中，这种情况很多。比如 我创建和编辑的页面使用的是同一个component,默认情况下当这两个页面切换时并不会触发vue的created或者mounted钩子，官方说你可以通过watch $route的变化来做处理，但其实说真的还是蛮麻烦的。后来发现其实可以简单的在 router-view上加上一个唯一的key，来保证路由切换时都会重新渲染触发钩子了。这样简单的多了。 1234567&lt;router-view :key=&quot;key&quot;&gt;&lt;/router-view&gt;computed: &#123; key() &#123; return this.$route.name !== undefined? this.$route.name + +new Date(): this.$route + +new Date() &#125; &#125; 总结要考虑的问题是很多，需要我们持续的学习。","categories":[{"name":"Vue专题","slug":"Vue专题","permalink":"http://www.octber.xyz/categories/Vue%E4%B8%93%E9%A2%98/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://www.octber.xyz/tags/Vue/"}]},{"title":"Springboot-@Validated和@Valid的分析","slug":"Springboot-Validated和-Valid的分析","date":"2019-06-20T11:44:38.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/20/Springboot-Validated和-Valid的分析/","link":"","permalink":"http://www.octber.xyz/2019/06/20/Springboot-Validated%E5%92%8C-Valid%E7%9A%84%E5%88%86%E6%9E%90/","excerpt":"前言","text":"前言","categories":[],"tags":[]},{"title":"Java基础-互斥同步","slug":"Java的锁机制","date":"2019-06-20T07:07:27.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/20/Java的锁机制/","link":"","permalink":"http://www.octber.xyz/2019/06/20/Java%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6/","excerpt":"前言Java中遇到的基本的线程问题,还有并发问题 以下内容来自大神frank的博文","text":"前言Java中遇到的基本的线程问题,还有并发问题 以下内容来自大神frank的博文 互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronized1. 同步一个代码块 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 12345678910111213141516public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 12345678public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125;0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 2. 同步一个方法 123public synchronized void func () &#123; // ...&#125; 它和同步代码块一样，作用于同一个对象。 3. 同步一个类 12345public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 1234567891011121314151617public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 4. 同步一个静态方法 非静态同步函数的锁是：this 静态的同步函数的锁是：字节码对象 123public synchronized static void fun() &#123; // ...&#125; 作用于整个类。 ReentrantLock重入锁（ReentrantLock）是一种递归无阻塞的同步机制。 123456789101112131415161718192021public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125;public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125;0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁，相比于 synchronized，它多了以下高级功能： 1. 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 2. 可实现公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。 3. 锁绑定多个条件 一个 ReentrantLock 对象可以同时绑定多个 Condition 对象。 synchronized 和 ReentrantLock 比较1. 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等。目前来看它和 ReentrantLock 的性能基本持平了，因此性能因素不再是选择 ReentrantLock 的理由。synchronized 有更大的性能优化空间，应该优先考虑 synchronized。 3. 功能 ReentrantLock 多了一些高级功能。 4. 使用选择 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 synchronized与lock的区别，使用场景。看过synchronized的源码没? （用法）synchronized（隐式锁）：在需要同步的对象中加入此控制，synchronized 可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。 （用法）lock（显示锁）：需要显示指定起始位置和终止位置。一般使用 ReentrantLock 类做为锁，多个线程中必须要使用一个 ReentrantLock 类做为对象才能保证锁的生效。且在加锁和解锁处需要通过 lock() 和 unlock() 显示指出。所以一般会在 finally 块中写 unlock() 以防死锁。 （性能）synchronized 是托管给 JVM 执行的，而 lock 是 Java 写的控制锁的代码。在 Java1.5 中，synchronize 是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用 Java 提供的 Lock 对象，性能更高一些。但是到了 Java1.6 ，发生了变化。synchronize 在语义上很清晰，可以进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致 在 Java1.6 上 synchronize 的性能并不比 Lock 差。 （机制）synchronized 原始采用的是 CPU 悲观锁机制，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。Lock 用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是 CAS 操作（Compare and Swap）。 什么是CAS 蘑菇街面试，这里简单论述一下 入门例子在 Java 并发包中有这样一个包，java.util.concurrent.atomic，该包是对 Java 部分数据类型的原子封装，在原有数据类型的基础上，提供了原子性的操作方法，保证了线程安全。下面以 AtomicInteger 为例，来看一下是如何实现的。 1234567891011121314151617public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125;&#125;public final int decrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current - 1; if (compareAndSet(current, next)) return next; &#125;&#125; 以这两个方法为例，incrementAndGet 方法相当于原子性的 ++i，decrementAndGet 方法相当于原子性的 –i，这两个方法中都没有使用阻塞式的方式来保证原子性（如 Synchronized ），那它们是如何保证原子性的呢，下面引出 CAS。 Compare And SwapCAS 指的是现代 CPU 广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。这个指令会对内存中的共享数据做原子的读写操作。 简单介绍一下这个指令的操作过程： 首先，CPU 会将内存中将要被更改的数据与期望的值做比较。 然后，当这两个值相等时，CPU 才会将内存中的数值替换为新的值。否则便不做操作。 最后，CPU 会将旧的数值返回。 这一系列的操作是原子的。它们虽然看似复杂，但却是 Java 5 并发机制优于原有锁机制的根本。简单来说，CAS 的含义是：我认为原有的值应该是什么，如果是，则将原有的值更新为新值，否则不做修改，并告诉我原来的值是多少。 简单的来说，CAS 有 3 个操作数，内存值 V，旧的预期值 A，要修改的新值 B。当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B，否则返回 V。这是一种乐观锁的思路，它相信在它修改之前，没有其它线程去修改它；而 Synchronized 是一种悲观锁，它认为在它修改之前，一定会有其它线程去修改它，悲观锁效率很低。 什么是乐观锁和悲观锁 为什么需要锁（并发控制） 并发控制机制 参考资料： 乐观锁与悲观锁——解决并发问题 - WhyWin - 博客园 Synchronized（对象锁）和Static Synchronized（类锁）区别 一个是实例锁（锁在某一个实例对象上，如果该类是单例，那么该锁也具有全局锁的概念），一个是全局锁（该锁针对的是类，无论实例多少个对象，那么线程都共享该锁）。 实例锁对应的就是 synchronized关 键字，而类锁（全局锁）对应的就是 static synchronized（或者是锁在该类的 class 或者 classloader 对象上）。 1234567891011121314151617181920212223242526272829303132333435363738/** * static synchronized 和synchronized的区别！ * 关键是区别第四种情况！ */public class StaticSynchronized &#123; /** * synchronized方法 */ public synchronized void isSynA()&#123; System.out.println(&quot;isSynA&quot;); &#125; public synchronized void isSynB()&#123; System.out.println(&quot;isSynB&quot;); &#125; /** * static synchronized方法 */ public static synchronized void cSynA()&#123; System.out.println(&quot;cSynA&quot;); &#125; public static synchronized void cSynB()&#123; System.out.println(&quot;cSynB&quot;); &#125; public static void main(String[] args) &#123; StaticSynchronized x = new StaticSynchronized(); StaticSynchronized y = new StaticSynchronized(); /** * x.isSynA()与x.isSynB(); 不能同时访问(同一个对象访问synchronized方法) * x.isSynA()与y.isSynB(); 能同时访问(不同对象访问synchronized方法) * x.cSynA()与y.cSynB(); 不能同时访问(不同对象也不能访问static synchronized方法) * x.isSynA()与y.cSynA(); 能同时访问(static synchronized方法占用的是类锁， * 而访问synchronized方法占用的是对象锁，不存在互斥现象) */ &#125;&#125;","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.octber.xyz/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"互斥同步","slug":"互斥同步","permalink":"http://www.octber.xyz/tags/%E4%BA%92%E6%96%A5%E5%90%8C%E6%AD%A5/"}]},{"title":"ServletContext引起的思考","slug":"ServletContext引起的思考","date":"2019-06-20T07:05:11.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/20/ServletContext引起的思考/","link":"","permalink":"http://www.octber.xyz/2019/06/20/ServletContext%E5%BC%95%E8%B5%B7%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"前言Servlet三大域对象的应用 request、session、application（ServletContext） ServletContext是一个全局的储存信息的空间，服务器开始就存在，服务器关闭才释放。 request，一个用户可有多个；session，一个用户一个；而servletContext，所有用户共用一个。所以，为了节省空间，提高效率，ServletContext中，要放必须的、重要的、所有用户需要共享的线程又是安全的一些信息。","text":"前言Servlet三大域对象的应用 request、session、application（ServletContext） ServletContext是一个全局的储存信息的空间，服务器开始就存在，服务器关闭才释放。 request，一个用户可有多个；session，一个用户一个；而servletContext，所有用户共用一个。所以，为了节省空间，提高效率，ServletContext中，要放必须的、重要的、所有用户需要共享的线程又是安全的一些信息。 获取servletcontext对象：12345ServletContext sc = null; sc = request.getSession().getServletContext();//或者使用//ServletContext sc = this.getServletContext(); System.out.println(&quot;sc=&quot; + sc); 还有一种方法，通过ServletContextListener获得： 1234567891011121314public class MySCListener1 implements ServletContextListener &#123; public MySCListener1() &#123; // TODO Auto-generated constructor stub &#125; @Override public void contextDestroyed(ServletContextEvent sce) &#123; // TODO Auto-generated method stub &#125; @Override public void contextInitialized(ServletContextEvent sce) &#123; // 通过事件对象获取事件源(ServletContext) ServletContext sc=sce.getServletContext(); &#125;&#125; 拓展：JavaEE中常见的监听器和事件Servlet和JSP提供Listener接口8个，Event类6个 Listener**接口** Event**类** ServletContextListener ServletContextEvent（上下文事件） ServletContextAtrributeListener ServletContextAttributeEvent（上下文属性事件） HttpSessionListener HttpSessionEvent HttpSessionActivationListener HttpSessionAttributeListener HttpSessionBindingEvent（会话绑定事件） HttpSessionBindingListener ServletRequestListener ServletRequestEvent ServletRequestAttributeListener ServletRequestAttributeEvent 一般来说也就是围绕着之前说的三大域对象：Request、Session、ServlerContext来进行的 源码级别了解ServletContextListener 类头注释123456789/** * Implementations of this interface receive notifications about changes to the * servlet context of the web application they are part of. To receive * notification events, the implementation class must be configured in the * deployment descriptor for the web application. * * @see ServletContextEvent * @since v 2.3 */ 意思很简单，就是说实现这个接口的类将会接收到servlet context的一些changes，也就是改变，为了能够接收到这些改变，必须实现这些对应的方法（废话）。 类中函数123456789101112131415/** ** Notification that the web application initialization process is starting. * All ServletContextListeners are notified of context initialization before * any filter or servlet in the web application is initialized. * @param sce Information about the ServletContext that was initialized */public void contextInitialized(ServletContextEvent sce);/** ** Notification that the servlet context is about to be shut down. All * servlets and filters have been destroy()ed before any * ServletContextListeners are notified of context destruction. * @param sce Information about the ServletContext that was destroyed */public void contextDestroyed(ServletContextEvent sce); contextInitialized:在web引用初始化的时候就启动了servlet context,也就是在servlet context初始化的时候调用了这个函数,我们可以在这里做一些项目初始化的操作,当然需要注意这些操作会占用长期的系统资源,谨慎使用 contextDestoryed:在servlet context在将要关闭的时候,会执行这个方法,可以做一些资源的释放,达到安全的关闭应用,或者记录一些关键数据,或者备份 类中参数ServletContextEvent:这个类作为上述函数的参数,继承自extends java.util.EventObject,显而易见,他是一个事件对象,类头的注释也很容易理解 12This is the event class for notifications about changes to the servletcontext of a web application. 他有着两个函数: 123456789101112131415161718/** * Construct a ServletContextEvent from the given context. * * @param source * - the ServletContext that is sending the event. */public ServletContextEvent(ServletContext source) &#123; super(source);&#125;/** * Return the ServletContext that changed. * * @return the ServletContext that sent the event. */public ServletContext getServletContext() &#123; return (ServletContext) super.getSource();&#125; 而我们之前获取servlet context也正是调用了getServletContext()这个函数,这个函数会返回ServletContext,如何返回?他通过调用他的父类方法(super)的getSource(),那么他的父类是EventObject,这是一个可以序列化的类(因为它实现了:implements java.io.Serializable),它里面定义了一个不可序列化的保护对象:protected transient Object source;并且通过getSource()返回了这个source,也就”源”对象 ServletContext的特性 获取全局对象中的储存数据 所有用户贡献一个 优秀博文推荐(Api向)这里有他很多用法,用的时候可以注意看一下 ServletContext对象核心方法 建议直接查看ServletContext源码","categories":[{"name":"Springboot","slug":"Springboot","permalink":"http://www.octber.xyz/categories/Springboot/"}],"tags":[{"name":"Servlet","slug":"Servlet","permalink":"http://www.octber.xyz/tags/Servlet/"}]},{"title":"Springboot-Shiro-编码/加密","slug":"Springboot-Shiro-编码-加密","date":"2019-06-19T01:30:54.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/19/Springboot-Shiro-编码-加密/","link":"","permalink":"http://www.octber.xyz/2019/06/19/Springboot-Shiro-%E7%BC%96%E7%A0%81-%E5%8A%A0%E5%AF%86/","excerpt":"前言此文章为填坑FamilyManage中关于加密次数的问题，拓展为对编码/加密模块的学习和思考。","text":"前言此文章为填坑FamilyManage中关于加密次数的问题，拓展为对编码/加密模块的学习和思考。 编码/解码Shiro 提供了 base64 和 16 进制字符串编码 / 解码的 API 支持，方便一些编码解码操作。Shiro 内部的一些数据的存储 / 表示都使用了 base64 和 16 进制字符串。 12String str = &quot;hello&quot;; String base64Encoded = Base64.encodeToString(str.getBytes()); String str2 = Base64.decodeToString(base64Encoded); Assert.assertEquals(str, str2); 通过debug,我们逐步查看:hello字符串首先被转换成byte类型,传入函数: 加密过后会生成:(这个过程可以参看下面Base64编码的讲解,博客中间的很清楚) 编码过后变为 5 × 8 ÷ 6 = 7,但为什么会有8个呢,就是因为出现了位数不足的问题: 所以最后出现的结果为hello=&gt; 有一个等于号,一共是八位,这个过程就看完了 Base64编码目前Base64已经成为网络上常见的传输8Bit字节代码的编码方式之一。在做支付系统时，系统之间的报文交互都需要使用Base64对明文进行转码，然后再进行签名或加密，之后再进行（或再次Base64）传输。 在参数传输的过程中经常遇到的一种情况：使用全英文的没问题，但一旦涉及到中文就会出现乱码情况。与此类似，网络上传输的字符并不全是可打印的字符，比如二进制文件、图片等。Base64的出现就是为了解决此问题，它是基于64个可打印的字符来表示二进制的数据的一种方法。 Base64的编码原理Base64的原理比较简单，每当我们使用Base64时都会先定义一个类似这样的数组：[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, ... &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, ... &#39;0&#39;, &#39;1&#39;, ... &#39;+&#39;, &#39;/&#39;]上面就是Base64的索引表，字符选用了”A-Z、a-z、0-9、+、/“ 64个可打印字符，这是标准的Base64协议规定。在日常使用中我们还会看到“=”或“==”号出现在Base64的编码结果中，“=”在此是作为填充字符出现 具体转换过程第一步，将待转换的字符串每三个字节分为一组，每个字节占8bit，那么共有24个二进制位。第二步，将上面的24个二进制位每6个一组，共分为4组。第三步，在每组前面添加两个0，每组由6个变为8个二进制位，总共32个二进制位，即四个字节。第四步，根据Base64编码对照表（见下图）获得对应的值。0 A 17 R 34 i 51 z 1 B 18 S 35 j 52 0 2 C 19 T 36 k 53 1 3 D 20 U 37 l 54 2 4 E 21 V 38 m 55 3 5 F 22 W 39 n 56 4 6 G 23 X 40 o 57 5 7 H 24 Y 41 p 58 6 8 I 25 Z 42 q 59 7 9 J 26 a 43 r 60 8 10 K 27 b 44 s 61 9 11 L 28 c 45 t 62 + 12 M 29 d 46 u 63 / 13 N 30 e 47 v 14 O 31 f 48 w 15 P 32 g 49 x 16 Q 33 h 50 y从上面的步骤我们发现： Base64字符表中的字符原本用6个bit就可以表示，现在前面添加2个0，变为8个bit，会造成一定的浪费。因此，Base64编码之后的文本，要比原文大约三分之一。 为什么使用3个字节一组呢？因为6和8的最小公倍数为24，三个字节正好24个二进制位，每6个bit位一组，恰好能够分为4组。 详细内容还请参看下面的博文 特别鸣谢作者：二师兄-公众号-程序新视界来源：CSDN原文：https://blog.csdn.net/wo541075754/article/details/81734770版权声明：本文为博主原创文章，转载请附上博文链接！ 散列算法Base64是一种编码方式,它并不能进行加密,因为他的过程是可逆的,我告诉你我的密码的base64,你可以哪去转换为明文,所以并不能使用base64进行加密 散列算法一般用于生成数据的摘要信息，是一种不可逆的算法，一般适合存储密码之类的数据，常见的散列算法如 MD5、SHA 等。一般进行散列时最好提供一个 salt（盐），比如加密密码 “admin”，产生的散列值是 “21232f297a57a5a743894a0e4a801fc3”，可以到一些 md5 解密网站很容易的通过散列值得到密码 “admin”，即如果直接对密码进行散列相对来说破解更容易，此时我们可以加一些只有系统知道的干扰数据，如用户名和 ID（即盐）；这样散列的对象是 “密码 + 用户名 +ID”，这样生成的散列值相对来说更难破解。 而我们往往要通过Base64的方式,我们可以看到Md5Hash的静态方法 我们可以通过这个方法进行加密 123456@Testpublic void Md5Code() &#123; String str = &quot;hello&quot;; String salt = &quot;123&quot;; String md5 = new Md5Hash(str, salt).toString();//还可以转换为 toBase64()/toHex()&#125; 如上代码通过盐 “123”MD5 散列 “hello”。另外散列时还可以指定散列次数，如 2 次表示：md5(md5(str))：“new Md5Hash(str, salt, 2).toString()”。 我之前遇到的坑,这个散列次数,我是用1024,出现了错误,后来改成2就对了 Springboot Shiro12345678910@Bean(&quot;hashedCredentialsMatcher&quot;)public HashedCredentialsMatcher shiroHashedCredentialsMatcher() &#123; HashedCredentialsMatcher credentialsMatcher = new HashedCredentialsMatcher(); //指定加密方式为MD5 credentialsMatcher.setHashAlgorithmName(&quot;MD5&quot;); //加密次数 credentialsMatcher.setHashIterations(2); credentialsMatcher.setStoredCredentialsHexEncoded(true); return credentialsMatcher;&#125; 我们首先制定了@Bean(“hashedCredentialsMatcher”),就可以为我们的密码认证进行加密,我们设置了加密的方法为MD5,加密次数为2,那么setHashIterations()的方法具体的意思是什么? 12345678910/ * **设置提交的&#123;@code AuthenticationToken&#125;的凭据在进行比较之前被散列的次数,指向存储在*系统中的凭据。除非被覆盖，否则默认值为&#123;@code 1&#125;，这意味着将执行正常的单个散列。如果*该参数小于1(即0或负数)，则应用默认值1。一定要有至少进行一次哈希迭代(否则将没有哈希)。*/public void setHashIterations(int hashIterations) &#123; if (hashIterations &lt; 1) &#123; this.hashIterations = 1; &#125; else &#123; this.hashIterations = hashIterations; &#125; &#125;","categories":[{"name":"Springbooot","slug":"Springbooot","permalink":"http://www.octber.xyz/categories/Springbooot/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"http://www.octber.xyz/tags/Shiro/"}]},{"title":"英语六级-作文集","slug":"英语六级-作文集","date":"2019-06-15T03:50:07.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/15/英语六级-作文集/","link":"","permalink":"http://www.octber.xyz/2019/06/15/%E8%8B%B1%E8%AF%AD%E5%85%AD%E7%BA%A7-%E4%BD%9C%E6%96%87%E9%9B%86/","excerpt":"前言六级考试范例作文","text":"前言六级考试范例作文 第一组(两篇)题目1: 2016真题题目2: 志愿者 Directions：For this part，you are allowed 30 minutes to write a short essay on innovation/ creation/ invention. Your essay should include the importance of innovation and measures to be taken to encourage innovation/creation/invention. You are required to write at least 150 words but no more than 200 words.参考范文： In the era that is full of competition and challenges, the issue of how to be innovative has been brought into focus. “Genius is one percent inspiration and ninety-nine percent perspiration.” Thomas Edison, a famous inventor, once put it that way. And I totally agree with him. According to Edison, one can only achieve a hundred percent success by both hard work and the creation elicited by the inspiration. In other words, being creative or innovative is an essential quality for people to succeed. Besides, it is the unceasingly up-coming innovations that have actually promote the progress of human beings.There are several ways to be innovative. To start with, one should learn to break the rule. The rule is used to regulate people’s behavior and to make everything in order. Nevertheless, new things do not always follow the old routines for their unique qualities. Thus, to create something new, you have to be brave enough to ignore what is old. Furthermore, it is vital that a creative person should adopt a sharp sense in the new trend in this fast-changing society. Living only with familiar things can trap oneself in the comfort zone which may gradually result in a dull and lazy mind. In that case, nothing new will ever come up to shine up his or her boring days. Only by being exposed to trendy and fashionable things as well as ideas can one really be on the right track of being innovative. 题目2: 志愿者 题目要求： 1.现在越来越多的人加人志愿者的队伍 2.志愿者的意义 3.我的看法 参考范文： In recent years, the volunteering spirit hasspread widely among the public, especially among youngsters. FromOlympic Games to urban communities, many people are seen to offerfree help. Volunteering is of tremendous benefit to thosein need. For example, hundreds of thousands of volunteers played anactive role in the quake-hit Yushu area: they offered medical andpsychological aid tothe victims in the relief work. On the otherhand, volunteering is beneficial to the volunteers themselves too.Involved in volunteering activities, people are exposed to newcircumstances and they can learn how to work well in a team and howto improve their interpersonal skills, all of which are criticalfor their career development. In my view, we should all join in volunteeringwork as long as we have spare time. That doesn’tnecessarily mean that we all volunteer in regions struck by naturaldisasters. There are many people who need our help, i.e. the old orthe sick in the near nursing home.Little by little, we are sure tohelp make the world better. 第二组(两篇)题目1：海外留学题目2：炫富 议论文是一种常见的文体，近年来，六级考试尤其注重议论文的写作能力，因为许多事情都有两面性，许多作文题目的做法是提出一种社会现象，要求作者在作文中分析利弊，下面是为你准备的两篇作文题目及对应的范文。 题目1：海外留学题目要求：1）海外留学的好处2）海外留学也存在一些问题3）我的观点 参考范文 题目1：海外留学 The discussion about overseas study has never stopped in the pastfew years. Let‘s have a look at its advantagesand disadvantages before drawing the final conclusion. The biggest advantage ofstudying overseas is the higher academic level and advancedresearch facilities. What’s more, byunderstanding a new culture and meeting different people, studentscan develop a more reasonable and balanced view towards the world.Last but not least, the experience will be invaluable to characterbuilding, which makes most students more independent, diligent andenterprising. However, the negative effects are also obvious.To begin with, if a person does not make full preparations beforegoing abroad, he will have great difficulty adapting to the newenvironment. In the second place,the cultural differences willhinder the regular life in many ways.Finally, money is always a bigproblem. Many students have to find part-time jobs to earn money topay tuition and fees. In conclusion, the advantages of overseas studyoutweigh disadvantages. Once they return home, the overseasstudents will make great contributions toour motherland. 题目2：炫富 题目要求： 1）由于经济的发展，有一些人喜欢炫富 2）人们对这一现象的看法不一 3）我的看法 题目：炫富 Nowadays, it is not rare to seepeople displaying their wealth on the Internet. Some postpicturesof luxury goods, such as brand clothes and bags, luxuriousautomobiles or jewelries. Some write about their experiences inwhich a lot of money is spent. People have differentresponses to this phenomenon. Some say that it ispeople’s right to share their possessions orexperiences with others on the Internet, as long as the things arelegal and the experiences are real. However, some criticize thatthe rich people are too arrogant. What’s worse,there are also a few who are not actually rich but put fake photosonlyto satisfy their vanity. In my opinion, sharing isagood thing, and it is exactly the spirit of the Internet.Butpeople should make careful choice on what they are sharing.After all,showing off is not very nice, not to mention faking. 第三篇(两篇)题目1:中国的污染题目2:环境与经济 环境污染已经成为了很多人都关心的一个问题，近年来，六级考试也开始偏向于提出与环境污染相关的作文题目，这也是属于议论文的一种，需要描写现状和发表自己的看法。下面是为你准备的两篇有关环境污染话题的作文题目及对应的范文。 题目要求1： 世界上污染最严重的二十个城市当中，有十个来自中国，可以看出中国目前的环境污染已经比较严重了，你觉得这是哪些原因造成的呢？应该如何解决？ 题目1：中国的污染 It isreported that ten big cities in China are being ranked among thetop twenty cities with the highest pollution index in the world.This means it is high time we did something to bring the situationunder control. Many factors are contributing to thedeteriorating situation: industrial wastes pumped into the air, thelakes and rivers; a increasing number of automobiles crowding intothe streets; the widespread use of plastic bags etc. To my view, stiffer lawsand regulations must be implemented to check pollution. Industriesthat release wastes without permission should be heavily fined.Carsshould be equipped to minimize the exhaust they release into theair. And the use of plastic bags and disposable meal boxes shouldbe banned. What’s more, the media should play an important role inimplanting a sense of environmental consciousness into people’smind. If everybody works toward a common goal ofmaking the environment better, we can create a cleaner and lovelierworld for us and for the coming generation. 题目要求2： 1)随着经济的高速发展，环境污染已经成为不可忽视的一个问题。 2)如何做到环境与经济平衡发展？ 参考范文 题目2：环境与经济 Nowadays wehave enjoyed an increasingly prosperous life in the wake ofenormous social and economic development. But at the same time, weforget that the consequence brought about by rapid economicdevelopment. For instance,greenhouse effect,duststorm,haze. As societydevelops,people are attaching much importance to deal with therelationship between economic development andenvironmental. Economic development isseemingly more important,the country develops much faster aner that it creates enormous job opportunities, improves livingconditions and increases government revenues. However, theenvironment is becoming worse and worse.In order to protect theenvironment which we depends on, something must be done. First and the foremost,we are expected touse public transportations instead of private cars that emit alarge amount of exhaust gas.what’s more, we canplant more trees to absorb carbon dioxide and build anenvironment-friendly society. Last butnot least, it is surelynecessary to complete relevant laws and regulations. We should rememberthatour future depends upon what we do right now. 第四组(两篇)题目1：自行车出行题目2：微笑 记叙文是一种常见的文体，近年来，六级考试尤其注重记叙文的写作能力，题目一般提出一种常见的事物，要求描写其特点并表达自己的看法，写这种的文章时需要明确题目要求，叙述准确到位，下面是为你准备的两篇记叙文作文题目及范文。 题目要求1： 出游的方式有很多种，有的人为了节省时间乘坐飞机，有的人选择较为舒适的火车，还有的人情愿乘坐拥挤的巴士。但你们有没有想过自行车旅行也是一种不错的方式呢! 范文： 题目1：自行车出行 There are many waysoftraveling. People may travel by plane if they want to travelfarand reach their destination in a shorter time. It is themostcomfortable but expensive way. Most people travel by trainbecauseit is a less expensive way but the compartments are crampedandstuffy. Bus journey is a cheaper way but it is spent onnarrow,bumpy roads which are crowded with traffic. Trips by shipmay bethe cheapest and most comfortable way but it takes toomuchtime. I like traveling by bike.Ican set out when I like and stop when I like. I can go whereverIlike so that I can enjoy delightful spots rarely visited byothertravelers. When I feel tired, I sit down by the bike and haveagood rest. Besides, I can save much money for tickets and muchtimein waiting for the train or bus. I can cover more places byridinga bike than going on foot. Traveling by bike is goodtohealth. It is really a sort of good exercise to strengthenone’smuscles and to test one’s will. Moreover, it brings nopollution tothe air. So it helps to clean the atmosphere. 题目要求2： 1)有些人不喜欢微笑，或者轻视微笑的作用; 2)其实微笑是最好的语言。 题目2：微笑 It has long been acceptedthat a smile is the best language. The truth of a smile is thatitis like a seed that can grow into a towering tree and at longlast it has deep and profound effect onpeople’slives. At the moment we getintrouble,get misunderstood or give thanks,a smile is more helpful than any other ex-pression. Many daily incidents can probe thestrength/power of smile.To begin with,we should always smile toourselves,so as to keep optimistic when in difficulty.At the sametime,smiling to others is necessary, too. Sometimes, we may facemisunderstandings that are hard to explain clearly simplybuwords.Then, a smile can show them the genuine sincerity to wintheir trust. Besides, smile is a worldwide language to say“thanks” and can bring pleasantfeelings to others. In a word,perhaps the bestexample of universally understood body language is smile. As theold saying goes, smile to others,and sooner or later they willsmile back to you. 第五组(两篇)题目1.公务员热潮题目2.低头族 议论文是一种常见的文体，近年来，六级考试尤其注重议论文的写作能力，题目一般是针对某种社会现象发表自己的看法，写这种的文章时需要清晰的逻辑和干练的表达，下面为你准备两篇有关社会现象的热点作文题目及参考范文。 题目要求1： 1)近几年兴起了一股报考国家公务员的热潮 2)分析产生这一现象的原因3)你对此的看法是…… 题目1.公务员热潮 In recent years, there aremore and more people who have participated in the test for nationalcivil servants. Millions of students choose civil servant as theirmost ideal occupation after graduation. And among them, thehigh-educated, like masters and doctors, take quite a largepercentage. The craze in civil servant test has attractedwidespread attention. The following reasons canaccount for this kind of craze. Above all, nowadays collegestudents face great employment pressure. Civil servant, as one ofthe most stable professions in today’s China,becomes their preferable choice. Moreover, in recent years, thewelfare and salary of civil servants have been improved greatly,which undoubtedly attracts many people. Besides, the high socialposition of civil servants is an important factor drawing manypeople to take part in the civil servant test. In my opinion, this craze in civil servant testwill continue in the following years. However, from the long run,it doesn’t do good to the development of thenation. If most high quality talents gather in the governmentdepartments, it might lead to a waste of resources. Therefore, boththe individuals and the government should have a more objectiverecognition of the civil servant test craze. 题目2.低头族 题目要求2： 1）现在，各个场所“低头族”现象比较普遍 2）出现这一现象的原因 3）我对这一现象的看法和建议 The picturedepicts a couple dating in the park. While the man just focuses onhis cellphones, and doesn’t pay any attention tohis partner or the nature beauty in the park. This picture reflectsa common phenomenon in today’s society: peoplespend too much time with their cellphones and communicate less andless with the people around them. Nowadays, thesmart-cellphones become more and more important in our daily life.They have made our life more convenient. We are timely aware of themost latest news around or faraway from us. However, everything has twosides. Except for all the advantages, the smart-cellphones alsohave brought some problems. First, when you’refocus on the cellphone, you may ignore the beautiful scene aroundyou. What’s worse, you are just absorbed in yourown small world, rather than share your happiness and sorrows withthe family. You hardly talk with your family and the ones aroundyou. You become indifferent to them. All in all,let’s put down the cellphones and spend more timecommunicating with our family and friends face to facedirectly.","categories":[{"name":"English","slug":"English","permalink":"http://www.octber.xyz/categories/English/"}],"tags":[{"name":"六级考试","slug":"六级考试","permalink":"http://www.octber.xyz/tags/%E5%85%AD%E7%BA%A7%E8%80%83%E8%AF%95/"}]},{"title":"FamilyManage-SpringbootShiro中遇到的问题与思考","slug":"FamilyManage-SpringbootShiro中遇到的问题与思考","date":"2019-06-14T17:44:48.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/15/FamilyManage-SpringbootShiro中遇到的问题与思考/","link":"","permalink":"http://www.octber.xyz/2019/06/15/FamilyManage-SpringbootShiro%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E6%80%9D%E8%80%83/","excerpt":"前言本次研究Springboot Shiro还是遇到了很多问题，记录如下： 加密次数问题：credentialsMatcher.setHashIterations(2); 首次登录不跳转Controller问题 登录验证流程 异常类自定义和捕获 工具类研究","text":"前言本次研究Springboot Shiro还是遇到了很多问题，记录如下： 加密次数问题：credentialsMatcher.setHashIterations(2); 首次登录不跳转Controller问题 登录验证流程 异常类自定义和捕获 工具类研究 关于加密次数出现这个问题的位置：ShiroConfigcredentialsMatcher.setHashIterations(2); 1234567891011121314151617/** * 密码校验规则HashedCredentialsMatcher * 这个类是为了对密码进行编码的 * 防止密码在数据库里明码保存 ,当然在登陆认证的时候 * 这个类也负责对form里输入的密码进行编码 * 处理认证匹配处理器：如果自定义需要实现继承HashedCredentialsMatcher */ @Bean(&quot;hashedCredentialsMatcher&quot;) public HashedCredentialsMatcher shiroHashedCredentialsMatcher() &#123; HashedCredentialsMatcher credentialsMatcher = new HashedCredentialsMatcher(); //指定加密方式为MD5 credentialsMatcher.setHashAlgorithmName(&quot;MD5&quot;); //加密次数 credentialsMatcher.setHashIterations(2); credentialsMatcher.setStoredCredentialsHexEncoded(true); return credentialsMatcher; &#125; 这就涉及到了Shiro中的编码加密的内容，请参看《Springboot-Shiro-编码/加密》 首次登录不跳转Controller这是Shiro的一个大的坑,因为理论上我们应当在login的Controller中使用 1234UsernamePasswordToken token = new UsernamePasswordToken(username, password, role);Subject currentUser = SecurityUtil.currentSubject();currentUser.login(token); 进行登录,之后我们会详细研究login的过程,之后会跳转到下面的代码中,进行用户指定方式的验证 12@Overrideprotected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; 但是首次登录并没有按照这个流程,而是直接跳到了上述代码,没有走Controller,也就是没有放入一个UsernamePasswordToken,那么肯定无法验证,这就需要我们进行一下配置: 12345@Beanpublic ShiroFilterFactoryBean shiroFilterFactoryBean(DefaultWebSecurityManager securityManager) &#123; // 开放登录接口，否则在第一次登录的时候就会绕过controller，执行doGetAuthenticationInfo map.put(&quot;/*/login&quot;, &quot;anon&quot;);&#125; 如果没有配置开放登录的接口,就会被过滤器filter拦截,拦截过后就无法进入 登录验证流程现在我们来看一下详细的登录验证流程:在Controller的login中打断点,逐步debug进行研究 使用postman进行Post请求的发送: shiroConfig的过滤器中设置登录接口的位置: 12//登录shiroFilterFactoryBean.setLoginUrl(&quot;/*/login&quot;); 而login的controller代码如下: 通过path拿到用户的角色,后面的LoginInfoRequestBean是为了获取用户的用户名密码,并验证他们的基本数据(长度够不够,能否为空等) Debug-Controller进入Controller,拿到请求的数据: UsernamePasswordTokenUsernamePassword类是我们之前说过的Shiro用于验证用户登录的基本类 设置了用户的基本数据,用户名,密码,是否记住我,还有host(角色),而password被转换成了char的数组,为了之后方便进行处理,char是基本数据类型,而String不是,这有很大的区别 SubjectSubject是用户/客户端对象,我们通过构建一个Subject来记录 拿到了当前的Subject: 可以进行登录操作:currentUser.login(token); login的源码中,使用securityManager的login功能,我们在shiroConfig中自定义注入了一个manager,就会使用我们自己的规则 此处掠过几步,我通过对login的继续深入,发现进入了: 而这个正式我们在ShiroRealm中定义的doAuthenticate()的方法 成功从大量的源代码跳入了我们自己写的代码中: 我们在Controller中定义的UsernamePassword就进入了这里,我们储存了用户登录的凭证,一路随着源码往回走,返回可用的用户info info是不为空的,也就是验证成功了 shiro就会告诉我们notifySuccess(token, info); 创建一个Subject的loggedIn并且成功onSuccessfulLogin,这样就跳回了最初的: 直到最后,Controller执行到了最后一行: 就返回成功success();登录完成 我们可以继续debug看到,其实Springboot最核心的也是Servlet的机制 最终PostMan收到了:","categories":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"}],"tags":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"}]},{"title":"软件项目管理-敏捷先锋朱少民","slug":"软件项目管理-敏捷先锋朱少民","date":"2019-06-13T10:00:16.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/13/软件项目管理-敏捷先锋朱少民/","link":"","permalink":"http://www.octber.xyz/2019/06/13/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-%E6%95%8F%E6%8D%B7%E5%85%88%E9%94%8B%E6%9C%B1%E5%B0%91%E6%B0%91/","excerpt":"前言软件项目管理相关内容","text":"前言软件项目管理相关内容 第一章：概述项目管理的生命周期项目管理的生命周期——“启动、计划、执行、控制、结束”演进顺序 项目的概念项目是为完成某个独特的产品或服务所做的一次性任务： 目标性，其结果只可能是一种期望的产品或服务。 独特性，每一个项目都是唯一的。 一次性，有确定的起点和终点。 约束性，每一个项目的资源、成本和时间都是有限的。 关联性，所开展的活动是密切相互关联的。 多方面性，一个项目涉及多个相关利益者 不可逆转性。不论结果如何，项目结束了，结果也就确定了。 项目-项目集-项目组合三者关系 简单来说就是：多个项目构成项目集，项目集进行组合构成项目组合 项目管理的定义项目管理，简单地说就是对项目进行的管理，即有计划地有序的有控制的做事。 项目管理就是以项目为对象的系统管理方法，通过一个特定的柔性组织，对项目进行高效率的计划、组织、指导和控制，不断进行资源的配置和优化，不断与项目各方沟通和协调，努力使项目执行的全过程处于最佳状态，获得最好的结果。项目管理是全过程的管理，是动态的管理，是在多个目标之间不断地进行平衡、协调与优化的体现。 参考： 项目管理的构成和约束因素 项目管理本质 项目管理的对象-3P People 人员必须被组织成有效率的团队，他们的潜力需要被激发出来，我们要为项目团队及其成员建立有效的沟通途径和方法，以实现人员之间，团队之间，管理者和被管理者之间的有效沟通，有效的团队应建立合适的组织结构和工作文化，并通过一系列活动，提高团队的凝聚力和战斗力，贡献团队的目标和文化，并最终圆满的完成任务。 Problem 问题在项目管理里表现为流程不清楚或控制不严密，应用领域知识不足，需求不断变化和不一致，沟通不流畅等，其解决办法是找出引起问题的根本原因在哪里，然后针对问题本质找到解决办法，以求彻底解决问题，如果项目管理者具有缺陷预防意识，对问题具有预见性，能够避免问题的发生，防范风险，防患于未然，项目的成本就会大大降低，项目成功的机会就会更大。 Process 过程必须适应于人员的需求和问题的解决，人员的需求主要体现在能力、沟通、协调等上，问题能够在整个项目实施过程中得到预防、跟踪、控制和解决，也就是说一套规范且有效的流程是保证项目平稳顺利运行的基础。 项目管理成功要素1. 制定计划：预估和确定项目的工作量大小、所需资源和进度、风 险应对措施等； 2. 建立组织：建立项目组，并有明确的角色定义和任务分工； 3. 配备资源：任用各种层次的技术人员和管理人员，以及准备所需 的软硬件； 4. 监控执行：协调项目各方人员，监控各种风险，督促项目进展， 随时检查实施情况，确保项目按计划进行，按时、按质完成任务 5. 总结提高：项目完成后，及时进行总结，吸取教训，分享经验， 丰富组织的项目管理数据库或知识库。 项目管理基本方法 阶段化管理 ：将项目的生命周期分为若干个阶段，再根据不同段所具有的不同特点来进行针对性的管理。 量化管理 ：针对影响项目成功的因素制定指标、收集数据、分析数据，从而完成对项目的控制和优化。 优化管理：分析项目每部分所蕴涵的知识，不断吸取教训、总结经验，将知识和实践更好地融合在一起，从而对项目的计划、实施办法等进行优化，获得项目的最佳效益。 项目管理基本模型1. 组队模型用于解决人力资源管理，包括明确相互依赖的角色和责任、沟通机制等；2.过程模型为了解决软件开发过程管理，包括时间管理、基于里程碑的阶段划分、阶段性成果及其基线的管理，保障项目的顺利实施；3.应用模型是具体应用领域的需求管理和变更管理等，并在用户、业务和数据三个层面上，定义协作的、分布的、可重用的业务逻辑网络。 软件项目管理的知识体系 PMBOK PRINCE2 WWPMM 软件项目管理的不同之处 软件项目是设计型项目 软件过程模型 需求变化频繁 难以估算工作量 主要的成本是人力成本 以人为本的管理 项目角色和职能 软件项目的分类 按规模划分比较简单，可分为大型项目、中小型项目等。 按软件开发模式划分，可分为组织内部项目、直接为用户开发的外部项目和软件外包项目。 按产品不同的交付类型可分为产品型项目、一次型项目。 按软件商业模式划分，可分为软件产品销售、在线服务两种模式，或者分为随需（on\u0002demand/SaaS）服务模式和内部部署(on-premise/on-Site)模式。 按软件发布方式可分为新项目、重复项目（旧项目），也可分为完整版本、次要版本或服务包(service pack)、修正补丁包 (patch)等。 按项目待开发的产品进行分类，如COCOMO模型中，可分为组织型、嵌入型和半独立型。 按系统架构分，可分B/S、C/S多层结构，也可分集中式系统和分布式系统，或者分为面向对象、面向服务、面向组件等类型。 按技术划分，可分为Web应用、客户端应用、系统平台软件等，也可分为J2EE、.Net 等不同平台之上的项目。 第二章：项目准备和启动项目建议书项目建议书 (project proposal )，顾名思义，就 是项目立项申请报告。它可 以比较简要，也可以比较详 尽，而重点是如何向有关的 投资方或上级阐述立项的必 要性。 项目建议书的内容 项目的背景 项目的意义和必要性 项目产品或服务的市场预测 项目规模和期限 项目建设必需的条件、已具备和尚不具备的条件分析 投资估算和资金筹措的设想 市场前景及经济效益初步分析 其它需要说明的情况 可行性分析因素 可行性分析方法 投标两个阶段 第一个阶段是参加竞标的供应商在规定的时间内提交投标书。 第二个阶段是需求方（客户）对投标书进行评估，得出竞标结果。 合同种类 固定总价合同 费用偿还合同 时间和材料合同 功能点计费合同 合同评审过程 制定合同 评审合同 签订合同 软件开发模型 瀑布模型 开发过程是通过一系 列软件活动顺序展开 的，从系统需求分析 开始直到产品发布和 维护，每个活动都会 产生循环反馈。 快速原型实现模型 增量模型到敏捷方法 极限编程 是一种软件工程方法图，是敏捷软件开发中最有成效的集中方法学之一。基本思想是“沟通、简单、反馈、勇气”，他与传统方法学的不同在于：他更强调可适应性，而不是可预测性，XP项目一开始就是手机用户故事，用户故事由用户编写，是一段与技术无关的文本，其目的在于提供一些特殊场景的详细描述，而不是用于估计系统的复杂性，用户故事的所有细节，必须在她实现之前得到客户的确认，紧接着就是制定发布计划，发布计划确定在系统的哪个发布版本中有哪些用户故事需要实现，每个发布版本都需要经过好几次迭代，每次迭代实现一些用户故事，一次迭代包括如下阶段： 计划 选择要实现的用户故事及其要明确的细则 编码 实现用户故事 测试 至少每个类都要有相应的单元测试 验收测试 如果测试成功，新功能开发完成，如果失败，则进入下一次迭代 行为驱动开发 BDD，是一种敏捷开发的技术，他鼓励软件项目中的开发者QA和非技术人员或商业参与者直接的协作，做法包括：P42 功能驱动开发 PDD，针对中小型软件项目的开发模式，是一个模型驱动的快速开发过程，他强调的是简化、实用，易于被开发团队接受，适用于需求经常变动的项目。开发分为四个阶段： 开发一个全局模型 建立功能列表 依据工农能指定计划 依据功能进行设计和实现 敏捷开发模型Scrum 通过不断迭代开发和增量发布，最终交付符合用户价值的产品。 软件开发模型的特点 敏捷开发的三种角色 产品负责人 负责维护产品需求的人，代表利益相关者的利益 Scrum Master 为Scrum过程负责的人，确保Scrum的正确使用，并使得Scrum的收益最大化，负责扫除阻碍项目进展的问题 开发团队 自我管理开发的人组成的跨职能团队，建议一个Scrum团队5-9人，大于9人，使用SOS（Scrum Of Scrums）模式。 敏捷开发的五个活动 ①计划会( Sprint Planning Meeting ):在每个冲刺之初，由产品负责人讲解需求，并由刑团队进行估算的计划会议。 ②每日立会( Daily Standup Meeting ):团队每天进行沟通的内部短会，因一般只有15分且站立进行而得名。 ③评审会( Review Meeting ):在冲刺结束前给产品负责人演示并接受评价的会议。 ④回顾会( Retrospective Meeting ):在冲刺结束后召开的关于自我持续改进的会议。 ⑤迭代(Sprint):一个时间周期( 通常在2周到1个月之间)，开发团队会在此期间内完成所承诺的一组需求项的开发。 项目组织结构 智能型：经营活动按照职能划分成部门。项目功能都在本职能部 门内部讨论完成再递交到下一个部门。如果完成期间涉及其他职 能部门的问题，只能报告给本职能部门经理，由各职能部门经理 进行协调和沟通。 纯项目型：项目经理拥有领导权，项目内所有成员直接向项目经 理汇报。每个项目就是一个独立自主单位。它就如同一个子公司 那样运作，拥有完整的人员配备-像技术人员，行政人员，财务 人员等。 矩阵型：它是职能型和纯项目型的结合体。但是项目内的成员受 项目经理和职能经理双重领导。 软件项目的组织架构 项目决策层，管理层和执行层之间的关系 QA与QC QA-质量保证，通过建立和维持质量管理体系来确保产品质量没有问题， 是过程质量审计者。在我们软件开发过程中，QA也就是质量组成员。 QA所关注的是软件产品质量保证体系。 QC-质量控制，检验产品的质量，保证产品符合客户的需求；是产品质 量检查者。在我们软件开发过程中，QC其实就是测试组成员。QC所关 注的是产品，而非系统（体系）。 软件项目干系人其实就是软件项目干系人（stakeholders），是指积极参与项目或 其利益在项目执行中或成功后受到积极或消极影响的组织和个人 第三章：项目计划什么是项目计划？计划是事先确定项目的目标和实现目标所需要的原则、方法、 步骤和手段等完整方案的管理活动。 软件项目计划（Software Project Planning）的目的是制 定一套软件项目实施及管理的解决方案，其主要工作包括确 定详细的项目实施范围、定义递交的工作成果、评估实施过 程中主要的风险、制定项目实施的（时间）进度计划、成本 和预算计划、人力资源计划等 软件项目计划的作用 指导软件项目实施 得到项目相关干系人的承诺 获得资源的承诺 明确项目人员的分工和工作责任 及早了解项目存在的问题和风险 获得组织在项目预算上的承诺 是软件项目实施结果评估的依据 软件项目实施过程的文档化 项目计划的内容 目标 策略 流程 标准 质量 进度安排 预算 资源 风险 配置管理 项目计划主要内容说明 目标与范围 ：范围规划、定义及其任务工作分解结构 项目估算：采用恰当的评估技术，完成资源估算、活动持续时间估 算以及费用估算 风险：一般性风险和特定产品的风险都应该被系统化地标识出来， 并建立风险条目检查表 资源 ：人员、硬件、网络、软件等需求和安排，还包括项目组成员 的角色、责任和具体分配的任务 进度安排：任务排序、里程碑设置等 跟踪和控制机制：QA、变更控制、项目成员报告等 项目计划的方法 滚动计划方法 按照“近细远粗”的原则制定一定时期内的计划，然后按照计划的执 行情况和环境变化，逐步细化、调整。 滚动计划方法的要点： 分而治之：分为多个阶段，针对不同的阶段制定不同的计划。 逐步求精：随着时间的推移，预测计列逐步变成实施计划。 动态规划：以计划的“变（调整）”来主动适应用户需求和软件开 发环境的变化，即“以变应变”。 和谐过渡：可以解决生产的连续性与计划的阶段性之间的矛盾 WBS方法 WBS方法是（Work Breakdown Structure，工作分解结构）一 种将复杂的问题分解为简单的问题，然后再根据分解的结果进行计划的方法。 WBS步骤 分解工作任务 定义各项活动/任务之间的依赖关系 安排进度和资源 网络计划技术 网络计划方法是一种应用网络模型直观地表示软件开发众多工 作（工序）之间的逻辑关系与时间关系，对完成软件工程项目所需时 间、费用、资源进行求解和优化的计划方法，其基本类型是关键路线 法/计划评审技术（CPM／PERT）。 敏捷开发的滚动计划方法 产品愿景（Vision），相当于产品最终要实现的目标，是一个长期努力的目标，可 以理解为商业战略上的目标。 产品路线图（Roadmap）：是一个中长期（3-5年）的产品规划，通过这个路线 图分阶段来实现上述的产品愿景。 发布计划（Release Planning）：短期（如一年）产品发布计划，根据产品路线图， 通过发布计划实现其第一个关键的里程碑。 迭代计划（Sprint Planning）：根据发布计划，来规划当前迭代要完成的目标和任 务，包括具体的人员和进度安排。 每日计划（Daily Planning）：就是第二章介绍的Scrum站立会 软件项目的特点 软件开发是在不断探索、研究中进行 最佳实践还不够成熟 软件的自动化对工具的依赖性也非常突出 软件构造过程实际是一设计过程，每一个软件产品都不同 由于软件是设计过程，自动化程度比较低 软件变化不容易实现，而软件变化又是不可避免的 软件的变化，进一步引起相关文档的频繁修改 软件项目的问题 时间紧迫性 项目独特性 软件项目的不确定性 软件项目管理可视性差 软件项目生产力依赖于软件人员的潜力挖掘 软件计划的错误倾向 对计划不重视 片面计划 计划没有考虑足够的风险 计划过于粗糙 计划的原则 目标性原则 预防性原则 客观性原则 系统性原则 适应性原则 制定计划的要点 目标导向。如果一开始对项目的目标没有理解清楚，项目计划就会出现 偏离，而项目实施时偏离就更厉害 重视与客户的沟通，为最后项目验收打下良好的基础 收集足够的信息，掌握信息越多，制定计划更科学、更客观 客观且实用，只有“知已知彼”才能做出合理的、客观的项目计划 先从下至上计划，然后再从上向下计划，构成一个完整的循环过程 关注计划过程，随机应变，因势利导，不断调整和修改计划，以保证 完成项目的目标 计划的层次性，如分为主计划、子计划 软件项目范围 软件产品规范，即一个软件产品应该包含哪些功能特性，这就是产品 需求文档（Product requirement document，PRD）所描述的。 更具体的要求就是功能规格说明书， 但这是在计划过程中或之后产生。一般在确定PRD的过程中，就开始 进行项目计划。 项目工作范围，即为了交付具有上述功能特性的产品所必须要做的工 作。工作范围在一定程度上是产生项目计划的基础。 资源计划 项目资源计划，是指通过分析和识别项目的资源需求， 确定出项目需要投入的资源。 资源计划包括人力资源计划、软硬件资源计划。 项目资源计划重点在人力资源计划，采用有效的方法 进行人力资源计划。 进度计划制定原则 项目的实际参与人员制定进度 尽可能地先安排难度高的任务，后安排难度低的事 进度前面紧，后面松，比较好 项目进度中都会设置若干个里程碑 进度表中必须留有缓冲时间 发现项目应交付的期限不合理，应调整进度 当需求发生变化时，就要重新评估进度表 成本构成按费用分类： 力资源成本 资产类成本 管理费用 项目特别费用 软件项目 按成本： 直接成本是项目本身的任务所引起的成本，包括为该项目购买的设 备和软件工具、参与该项目工作的人员工资等。 间接成本是许多项目共享的成本，例如办公楼的租金、水电费用、 公司管理费用、网络环境和邮件服务等各种间接费用。 成本计划 费用预算，在成本估算基础之上，针对各项成本来估算可能产生 的其他费用，从而确定费用预算 费用控制是为了保证实际发生的费用低于预算。一般会采用阶段 性控制和单项费用控制相结合的方法，更关键是需求变更控制和 质量控制。 风险计划 风险识别、风险评估和风险对策计划 风险计划并不是在资源计划、进度计划和成本计划之后再制定，而是 和这些计划同时进行，因为软件项目的风险会来自于各个方面，包括 人力资源风险、进度风险和成本风险等，而且在如何应对风险或针对 风险采取相应的对策时，对资源计划、进度计划都有影响 质量计划内容 质量目标，包括功能特性和非功能性特性的质量要求； 质量目标分解，总体质量目标分解到各个阶段或各项任务 相关标准和规范 组织保证机制，包括确定责任人、质量保证人或管理人员 质量属性满足的优先级和成本效益分析 质量控制策略，包括测试覆盖率、代码评审的频率等； 质量特性的相互依赖关系的分析，确定质量特性的优先级 潜在的质量问题分析，并找出应对策略 流程评审、测试计划和测试用例评审等方面的具体要求； 其它质量保证或控制措施、质量相关活动。 项目计划工具 P3 DotProject 第四章：项目估算项目估算的基本内容 规模估算 (size estimation)：如代码行数、功能点数、对象点或特征 点等 工作量估算(workload ～)：任务分解并结合人力资源水平来估算 进度估算(schedule ～)：通过工作量估算、有效资源分配等对项目 进度给出正确的评估。 风险估算(risk ～)：一般通过 风险发生的“概率和所带来的损失”来 评估风险。 其他估算，如需求稳定因子、资源利用效率、文档复审水平等 估算的基本内容及其关系 基本估算方法 分解方法：采用“分而治之”的策略，对软件项目进行分 解，再采用逐步求精的方式进行估算，最后通过累加获得 整体的估算结果 算术模型，通过估算模型来产生估算 专家判断或经验法，如德尔菲法(Delphi technique) 比例法是基于类比的估算技术，根据过去类似的项目，直 接进行类比获得当前项目的估算结果。 WBS估算法 自顶向下估算模式，首先估算出项目一级的工作量，然后层层往下分 摊，把上一层工作量分摊到下一层的阶段、活动或任务。通常使用 FPA方法或 COCOMO II 来估算项目一级的工作量 自底向上估算模式，要求先估算出底层任务/活动一级的工作量，然后 层层向上汇总到阶段和项目级。通常使用 QIF 估算方法或专家判断来 估算项目低层 WBS 元素的工作量 软件规模估算 德尔菲法 代码行估算方法 LOC指所有可执行的源代码行数，包括控制语句、数据 定义、数据类型声明、等价声明、格式声明等 功能点分析方法 功能点分析法(FPA)是在需求分析阶段基于系 统功能的一种规模估算方法，其国际标准 功能点计算元素 外部输入数(EI)：计算每个用户输入 外部输出数(EO)：计算每个用户输出(报表、屏幕、出错信息 等) 内部逻辑文件(ILF)：计算每个逻辑的主文件，如数据的一个 逻辑组合 外部接口文件(EIF)：计算所有机器可读的接口，如磁带或磁 盘上的数据文件。 外部查询数(EQ)：一个查询被定义为一次联机输入，它导致 软件以联机输出的方式产生实时的响应 标准构件法 软件由若干不同的“标准构件”组成，这些构件对于一个特定的应用领域而言是通用的。项目计划者估算每一个标准构件的出现次数，然后使用历史项目数据来确定每个标准构件交付时的大小。 综合讨论 一般在项目层次上，缺少可比性，但在模块或组件层次 上、阶段性任务上具有可比性，可以基于历史数据来进 行比较来获得数据 在实际估算工作中，一般先采用分解的方法，将项目分 解到某个层次上，然后再采用对比分析方法和经验方法 任何估算方法都要结合实际来考虑 工作量估算 COCOMO方法 构造性成本模型(COCOMO：constructive cost model)是一种精确、易 于使用的基于模型的成本估算方法： 基本COCOMO模型，静态单变量模型，用已估算出来的源代码行数 (LOC)为自变量的函数来计算软件开发工作量。 中间COCOMO模型，在用LOC为自变量的函数计算软件开发工作量的 基础上，再用涉及产品、硬件、人员、项目等方面属性的影响因素 来调整工作量的估算。 详细COCOMO模型，包括中间COCOMO模型的所有特性，但用上述各种 影响因素调整工作量估算时，还要考虑对软件工程过程中分析、设 计等各步骤的影响。 COCOMO基本变量 DSI(源指令条数)，定义为代码行数，包括除注释行 以外的全部代码。若一行有两个语句，则算做一条 指令。KDSI即为千代码行数。 MM(估算单位为人月)表示开发工作量。 TDEV(估算单位为月)表示开发进度，由工作量决定。 COCOMO模型影响因素 产品因素：软件可靠性、数据库规模、产品复杂性。 硬件因素：执行时间限制、存储限制、虚拟机易变性、环境周 转时间。 人的因素：分析员能力、应用领域实际经验、程序员能力、虚 拟机使用经验、程序语言使用经验。 项目因素：现代程序设计技术、软件工具的使用、开发进度限 制 多变量模型 通过用例来描述系统的需求更清楚，可以在功能点和用例之间 建立良好的映射关系，项目的估算会更准确些。 基于用例的工作量估计 用例的层次 集成系统，由多个系统构成综合系统； 独立的系统，由多个子系统组成； 子系统，由多个模块或组件构成； 模块/组件，由多个类组成，例如可假定平均8个类构成一个组件。 类，无需用例来描述。 用例估算方法 基于用例的估算，最好还是和 WBS方法结合起来使用 一般认为用例的数量在10－50 个范围比较合适，而每个用例可 以带有几十个相关场景 假定每一层的每一个组件平均有 10 个用例 考虑总的工作量规模时，需要对个别用例的小时数做进一步调整 IBM RMC估算方法 RMC 的工作量估算采用的是 QIF（定量影响因子）估算方法和 自底向上估算模式，对项目的任务、活动、阶段、子项目、项目 等进行自底向上的层层估算 可以定义多个估算模型 每个估算模型可以定义任意数量的估算因子 每个估算因子都会关联估算公式 使用估算公式来计算该估算因子对应的工作量 IBM RMC估算步骤 创建估算模型，定义相关的估算因子； 把估算模型的估算因子应用到 WBS 底层元素，计算出它 们的工作量； 层层向上汇总，计算出项目 WBS 上层元素（包括项目本 身）的工作量。 不同场景的估算法 合同签订之前，了解的需求比较有限，只能了解到项目的总 体需求，主要采用“类比分析和经验判断”等方法 基于WBS估算的多维验证，获得类似项目的历史数据、软件 生命周期的生产率数据和详细需求，从而可以从不同的路径 来估算工作量，获得多个结果，这些结果可以互相印证，以 发现估算过程中的不合理之处，使估算 更准确。 需求变更的工作量估计，关键是需求变更的波及范围分析 软件项目类型 组织型：指项目需要有丰富的专业经验，同时需求具有灵活性。 这样的项目可以由小团队进行开发。如开发业务系统和数据处 理系统的项目都是组织型项目。 嵌入型：指要求较少的专业知识，但对接口、可靠性等有严格 的要求，并有外部条件的限制。例如开发实时系统或大型操作 系统的项目就是嵌入型项目。 半独立型：指需要适中的专业知识，与嵌入型项目相比外部限 制相对较为宽松的项目。如开发数据库管理系统和库存产品控 制系统的项目就是半独立型项目 资源估算基本过程 根据WBS进行估算 由工作量和开发周期来估算 资源特征描述 资源分配给任务 定义项目角色 人员分配 工期估算方法 常用方法是专家（经验）估算法、基于历史数据的类比法 当面临高度不确定性任务时，可以采用三点估算法来进行 工期估算 计划时间 =（T乐观 + 4×T可能 + T悲观）/6 工期估算中还要预留一定比例作为冗余时间以应付 项目风险。随着项目进展，冗余时间可以逐步减少。 在分析标识项目活动的时候，活动资源和历时的分 析其实是同时进行的。 特殊场景工期估算（日） = 工作量估算（人日） / 人员数量（人） 使用这个公式时，避免人月估算的错误。要对每个人的能力进 行分析，确定他们自己的等价关系，这样，“人员数量”不是 人员的自然数量，而是更客观反映人力的等价数量 按照历史数据来估算开发周期，其准确度是可以接受的 在实际使用历史数据估算法时，组织应建立一个历史项目数据 库是必要的 成本估算方法同样可以使用专家评估办法、经验法、比例法和WBS方法等 成本估算过程中，要紧密结合项目进度计划。 避免过于乐观或者过于保守的估算。 在费时较长的大型项目中，还应考虑到今后的职工工资结 构、设备费用以及管理费用是否发生较大变化等 在有新员工的项目中，还应考虑其培训成本 人力资源成本是随着团队开发效率的变化而变化的","categories":[{"name":"软件项目管理","slug":"软件项目管理","permalink":"http://www.octber.xyz/categories/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"软件项目管理","slug":"软件项目管理","permalink":"http://www.octber.xyz/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"}]},{"title":"软件测试-基于问题驱动模式","slug":"软件测试-基于问题驱动模式","date":"2019-06-11T05:16:57.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/11/软件测试-基于问题驱动模式/","link":"","permalink":"http://www.octber.xyz/2019/06/11/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95-%E5%9F%BA%E4%BA%8E%E9%97%AE%E9%A2%98%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%BC%8F/","excerpt":"前言《软件测试-基于问题驱动模式》课本复习","text":"前言《软件测试-基于问题驱动模式》课本复习 第一章:软件测试入门软件测试的概念软件测试是贯穿整个软件开发生命周期对软件产品进行验证和确认的活动过程。尽快尽早的发现软件中的缺陷，也是对软件产品质量的评估从而提供质量有关的信息。 软件缺陷的概念软件缺陷，即软件中存在的任何一种破坏正常运行能力的问题、错误，其结果会导致软件产品在某种程度上不能满足用户的需要，软件缺陷分为程序内部的错误和程序外部的失效；软件缺陷不仅是程序的错误，还应该包括需求、设计中存在的问题。 软件质量的概念系统、组件或过程满足特定需求的程度，和满足客户/用户需求或期望的程度。质量分为内部质量、外部质量和使用质量。 产品/使用质量模型及其属性 内部/外部质量模型及其属性 使用质量模型及其属性 软件测试的价值与定义辩证的理解测试狭义/广义狭义的软件测试只有动态的执行软件时进行测试 广义的软件测试包括静态测试和动态测试在内的各种测试的总称 静态/动态静态测试包括需求、设计和代码等的评审。引入静态测试意义重大，能够尽早的发现问题，极大地降低软件开发成本。不需要运行软件系统，而是对软件的半成品（如需求文档、设计文档、代码）进行评审，即开展需求评审、设计评审、代码评审等活动。 动态测试需要运行软件才能完成测试的一种形式 软件测试的层次一共有四层： 单元测试 集成测试 系统测试 验收测试 软件测试的类型 按测试的对象或范围分类，如单元测试、文档测试、系统测试等） 按测试目的分类，如功能测试、回归测试、性能测试、可靠性测试、安全性测试和兼容性测试等 根据测试过程中被测软件是否被执行，分为静态测试和动 态测试 根据是否针对系统的内部结构和具体实现算法来完成测试 ，可分为白盒测试和黑盒测试 软件测试和SQA的区别和联系 第二章：需求与设计评审静态测试（评审）形式及其流程评审的形式：互为评审、走查和会议评审等不同形式 软件需求的层次 其中业务层次又包括： 业务需求：解决什么关键问题，核心的诉求是什么，达到什么目标，相当于产品的愿景。 用户角色需求/干系人需求：相关利益者的需求，每个用户角色有什么特定的需求。从用户行为去分析，即对应用例和用户故事，运维、技术支持等相关人员的需求，一般也可以并入用户角色的需求。 功能性和非功能需求：软件为了满足上述也无需求，及相关利益者的需求，而具备的功能和非功能性（系统）的能力。 需求与设计评审标准正确性检查在任意条件下软件系统需求定义，以及其说明的正确性 完备性涵盖系统需求的功能，性能，输入/输出，条件限制、应用范围等的程度，覆盖率越高，完备性越好 易理解性文档的描述性被理解的容易程度，包括清晰性。 一致性所定义的需求之间没有相互排斥、冲突和矛盾，前后一致 易测试性容易进行相关测试 易追溯性每一项需求定义可确定其来源 设计评审的层次 设计评审方法 从高层到底层 不断从测试角度去问开发 借助UML等建模工具 第三章：单元测试单元测试的概念和主要形式单元测试是针对软件的基本工作单元，进行正确性检验的 测试工作。 单元测试中类测试的分类 动态测试 方法内测试 方法间测试 在测试类功能实现时，应该首先保证类成员方法的正确性，类方法的正确行为只是类能够实现要求的功能基础。 静态测试 首先需要保证要测试的类有完整和正确的说明，并且已经在模型环境下进行了测试，类的规格说明使用对象约束语言、自然语言或状态图表示，不同语言的规范进行相应代码规范的评审，这是类的静态代码评审。 单元测试的方法测试用例实现设计好的测试数据、执行条件以及预期执行结果称为测试用例 白盒测试通过被测单元的内部结构来设计测试用例来进行的测试 黑盒测试不关注内部代码，仅从程序功能和性能上考量是否满足需求而设计测试用例来进行的测试，一般为接口测试或集成测试 单元代码的自动化测试的步骤 设计测试用例 从单纯分析程序结构入手，画出或者直接从详细设计文档中得到程序流程图，尝试设计测试用例（选用某种覆盖方法）覆盖所有的代码行。 覆盖方法： 语句覆盖 需要设计足够多的测试用例，使得程序将会执行被测方法中所有的语句，覆盖该方法的所有语句，比如程序中的if/else分支，要全部执行测试到。 语句覆盖是逻辑覆盖中的一种，逻辑覆盖就是通过对程序逻辑结构的遍历，实现程序覆盖的一种白盒测试技术。 条件覆盖 对判定条件也要进行分解，当一个判定条件中有&amp;&amp;或者||其他时要进行分解，对每个条件都进行测试覆盖。 如：if(x&gt;=3&amp;&amp;y==0)分解为 x&gt;=3为真/假 y==0为真/假 分支覆盖(判定覆盖) 通过设计执行足够多的测试用例，使得程序中的每个判定表达式的值为真和为假的分支都要至少执行依次测试 多重条件覆盖(条件组合覆盖) 是为了解决短路操作符，使得每个条件都执行到，参照下面备注的例子，就是让y==0也能执行到，此时x&gt;=3是成立的，也就是x&gt;=3能否成立都要安排测试用例，以保证y==0能够被测试到，进行条件的全覆盖测试。 路径覆盖 比如有两个if/else条件，那么就是2×2=4中路径，每一条路径与后边路径的组合都要覆盖到。 编写测试代码 编写测试脚本 执行测试 执行测试代码即可 123451.备注：回归测试：是指修改了旧代码后重新进行测试，测试代码不变，以确认修改后的代码没有产生新的错误，或导致其他代码发生错误，就叫回归测试2.备注：短路操作符出现类似if(x&gt;&#x3D;3 &amp;&amp; y&#x3D;&#x3D;0)这样的判断条件时，当编译器执行到x&gt;&#x3D;3不成立时，就不会去判断y&#x3D;&#x3D;0这一条件，直接跳过，即便有错，也检查不到了。 第四章：持续集成测试集成测试的概念一种旨在暴露单元接口之间、组件/系统间交互或协同工作时所存在的缺陷的测试。 集成测试的层次 软件单元与软件单元的集成测试 软件子系统和子系统的集成测试 软件系统和第三方系统的集成测试 软件系统和硬件的集成测试 集成测试的模式非渐增式测试模式（已完成测试的模块）先分别测试每个模块，再把所有模块按设计 要求放在一起组成所要的程序，如大棒模式(Big-bang Integration) 渐增式测试模式（已完成测试的模块）把下一个要测试的模块同已经测试好的模块结合起 来进行测试，测试完以后再把下一个已测试的模块结合进来测试… 持续集成（针对新增的代码）每日新增的代码，集成到最新的项目中时，就会进行测试，使得项目在每天都会有一次或多次的测试过程。 集成测试的特点集成测试侧重于对接口的测试，数据驱动脚本。 接口之间传递的参数是否 一致(个数、属性、量纲) 全局变量引用是否一致 数据流一致性处理 缓冲区数据的处理 接口测试要点 接口中所有的参数的不同类型的有效值都要被测试 参数的每个错误类型都要准备一个异常用例 如缺省值、类型错误、范围错误、参数超过最大位数、无效值、 参数的关联性检查等 把每个参数单独作为条件来进行测试，再进行多条件 关联组合测试 集成测试发展历程 持续集成的内涵（内容） 持续检查（用工具扫描分析代码） 持续构建（Build） 持续部署 持续验证、测试 持续集成环境（基础设施） 持续报告 测试金字塔 自动化测试的过程 自动部署 方法： 借助插件：deploy plugin 编写脚本：shell脚本、winsows批处理、python脚本等 构建前实现自动静态分析 方法和自动部署一样，自动静态测试报告- Sonar工具生成报告 构建后实现自动验证 系统功能 性能测试 完成测试要依赖相应的测试工具，还需要做相应的配置。 持续集成过程使用到的工具 代码库/版本管理工具： Git SVN CVS 构建工具 Ant Maven Gradle 代码静态分析工具 - FindBugs - PMD 测试工具 JUnit Selenium 持续集成调度工具 Jenkins Travis CI 第五章：系统功能测试系统功能测试的内容 功能 逻辑 接口 界面 数据 操作 平台 软件需求的层次 业务需求： 测试用例设计方法等价类划分方法等价类是某个输入域的子集，在该子集中每个输入数据的作用是等效的。将输入数据分成若干个子集，从每个子集选取一个代表性的数据作为测试用例。 基于对输入或输出的情况的评估，然后划分成两个或更多的子集来进行测试，即他所有可能的输入数据（有效的或者无效的）划分成若干个等价类，从每个等价类中选择一定的代表值进行测试，如果用这个等价类中的代表值作为测试用例未发现程序错误，那么该类中其他的数据（测试用例）也不会发生程序的错误。 有效等价类 完全满足程序规格说明、有意义的输入数据所构成的集合。 意义：检验程序是否满足规格说明所规定的功能和性能。 无效等价类 不满足程序规格说明、无效的输入数据所构成的集合 意义：可以测试程序/系统的容错性——对异常输入情况的处理。 在程序设计中，不仅要保证所有有效的数据输入能产生正确的输出，还要保证错误的输入或者无效输入中能够有异常保护 边界值分析方法取边界值进行测试分析，取最靠近边界的两个值作为测试的数据。 决策表方法借助表格方式完成对输入条件的组合设计，已达到完全组合覆盖的测试效果。 比如在某一网页登录过程中： 上述判定表可以看出来用户名、密码、验证码有一个输入错误就和标准版没有关系了，所以我们还可以进行判定表判定条件的优化： 继续看，我们发现用户名或密码有一个错误，只需要考虑验证码，于是我们还可以优化： 决策表测试爆炸时的优化方法两两组合方法（Pairwise）正交试验设计法 基于用例/场景的测试方法基于一个核心场景，考虑不同的条件，或者不同的测试数据，进行分析设计用例观察对应的结果。 如：用户登录时，是否是第一次登录，密码长度，用户名长度等等 回归测试的策略基于风险策略来选择回归测试用例优先变动大的代码进行测试 即判断哪些区域受修改的代码影响的可能性大，受到影响的可能性越大，越要优先考虑。如果测试用例没有收到影响，这些用例就不选择。 基于操作剖面选择测试优先测试较为重要的，使用频繁的功能 如果测试用例的构造是基于用户功能特性组织的，测试用例的分布情况反映了系统的实际使用情况，则选择这种策略。优先选择那些最重要的，或者最频繁使用的功能所关联的测试用例，有助于尽早发现那些对质量有明显影响的故障，而放弃次要功能关联的测试用例。 采用代码相依性（相互依赖的关系）分析优先测试和变动代码有关联的代码 了解代码依赖的关系，建立代码和测试用例的映射关系，这样但某些代码做了修改时，就能过根据代码的相依性了解到哪些代码收到了影响，再根据代码和测试用例的映射关系来选择回归测试用例，这样的策略（方法），更客观更准确。 最常用的功能测试工具组合测试的工具 CTE-XL ACTS 面向接口的Web测试工具 JMeter：一般是性能测试用具，也可以做面向接口的功能测试 SoapUI：面向接口的功能测试工具 Web自动化测试工具 Selenium+WebDriver工具 第六章：系统性能测试性能测试的概念和目标性能测试（performance test）就是为了发现系统性能问题或获 取系统性能相关指标而进行的测试。一般在真实环境、特定负载 条件下，通过工具模拟实际软件系统的运行及其操作，同时监控性能各项指标，最后对测试结果进行分析以确定系统的性能状况。 获取系统性能某些指标数据 为了验证系统是否达到用户提出的性能指标 发现系统中存在的性能瓶颈，优化系统的性能 性能测试的类型性能基准测试在系统标准配置下获得有关的性能指标数据，作为将来性能改进的基线(Baseline) 性能验证测试验证系统是否达到事先已定义的系统性能 指标、能否满足系统的性能需求 性能规划测试在多种特定的环境下，获得不同配置的系统性能指标，从而决定系统部署的软硬件配置选型 容量测试可以看作性能的测试一种，因为系统的容量可以看作是系统性能指标之一 压力/负载测试压力测试 (Stress test)，也称为强度测试、负载测试。压力测试是模拟实际应用的软硬件环境 及用户使用过程的高负载、异常负载、超长时间运行，以检查程序对异常情况的抵抗能力，找出 性能瓶颈、不稳定或不可靠等问题 并发性能测试 （ramp-up） 稳定性压力测试 在选定的高负载下，持续运行24H以上的压力测试。这类测试可以归为性能测试范围内，其质量标准是各项性能指标在指定范围内，而且无内存泄漏，无系统崩溃，无功能性故障。 破坏性压力测试 通过不断加载的手断，快速造成系统的崩溃，让问题尽快的暴露出来，具有明显的破快特征，是对稳定性压力测试的补充，更容易暴露导致系统问题的真正原因，可以喝容量测试结合起来进行，另一个目的是使得系统出故障，然后检验系统是否能够恢复，如果能恢复，其恢复的时间有多长，根据这个结果可以分析出系统的可恢复性是否满足设计的要求。 疲劳强度测试 渗入测试（soak test） 通过长时间运行，使问题逐渐渗透出来，从而发现内存泄漏、垃圾收集（GC）或系统的其他问题，以检验系统的健壮性。 峰谷测试（peak-rest test） 采用高低突变加载方式进行，先加载到高水平的负载，然后急剧降低负载，稍微平息一段时间， 再加载到高水平的负载，重复这样过程，容易发现问题的蛛丝马迹，最终找到问题的根源。 大数据量测试 独立的数据量测试 针对某些系统存储、传输、统计、查询等业务进行大数据量测试 综合数据量测试 和压力性能测试、负载性能测试、并发性能测试、疲劳性能测试相结合的综合测试方案 负载 每次请求发送的数据量 (Request Per Second, RPS) 并发连接数 (Simultaneous Connections, SC) 思考时间（thinking time），用户发出请求之间的间隔时间 RPS + SC + Thinking Time = Concurrent users 负载/加载模式 主要性能指标 系统/事务平均响应时间（Average System/Transaction Response Time） 事务/交易处理效率（Transactions per second，TPS） Page View (PV): 用户向Server发送请求，Server处理这样一次真实的请求 连接时间（Connect Time）、发送时间（Sent Time） 处理时间（Process Time）、页面下载时间 吞吐率（Throughput）每秒服务器处理的HTTP申请数 每秒点击次数(Hits per Second) 每秒SSL连接数 (SSLs Per Second) 内存和CPU使用率 性能测试设计和执行过程首先确定模拟并发的用户数量（往往根据详细设计Base Line），选定加载方式（一次加载，递增加载，高低突变，随机加载），模拟用户操作（使用BadBoy录制脚本可以导出成JMeter的测试脚本），使用性能测试工具（JMeter）设计脚本，在工具中配置并发的线程数（模拟的用户数），配置加载方式，进行测试，得到测试报告（吞吐量，异常率等等）。 性能测试工具JMeter (http://jmeter.apache.org) 性能测试工具 Apache Flood （http://httpd.apache.org/test/flood/）Web性能测试工具 Gatling(http://gatling-tool.org )Scala－based的Web性能测试工具 Grinder（http://grinder.sourceforge.net/）分布式Web性能测试工具 nGrinder（http://naver.github.io/ngrinder/ ）企业级Web性能测试工具 Siege（http://www.joedog.org/JoeDog/Siege）Web压力测试和评测工具。 DBMonster (http://sourceforge.net/projects/dbmonster/ )数据库压力测试工具 第七章：系统安全性测试安全性测试的概念这里的“安全性”是指信息安全，指计算机系统或网络保护用户数据隐秘，完整，保护数据正常传输和抵御黑客、病毒的能力，而不是指系统整体的安全性。 安全测试的基本方法安全漏洞测试方法SAST静态应用安全测试只不运行被测试程序，仅仅通过分析检查应用软件源代码或字节码，以发现应用软件的安全性漏洞。 DAST动态应用安全测试通过运行程序来检查应用软件的安全性问题，侧重从系统外部接口来进行针对性的测试，暴露应用程序接口的安全性漏洞，测试发现的问题，一般能够直观的展示出来，测试手段包括：手工的渗透测试，DAST的工具的动态扫描检查和两者的结合。 IAST交互式应用安全测试前两者有一定局限性，如SAST误报率比较高，无法进行业务逻辑的相关安全性测试。IAST整合了前两者的方法，降低了误报率，发送更多安全漏洞，提高测试效率。操作难度比较大。 RASP运行时应用自我保护重写软件让软件可以在运行时被监控，可以检测到应用程序在运行时可能遇到的安全风险（如试图往内存中写入大量数据、未经授权试图访问数据库），从而自动发送警告信息，或实时中止会话。 模糊测试方法使用大量半随机的数据（对数据进行变异或由模糊控制器自动产生数据），作为应用程序的输入，以程序是否出现异常行为/结果为标志，来发现应用程序中可能存在的安全漏洞。 安全性功能测试方法参考第五章 静态代码分析方法动态渗透测试方法安全软件开发生命周期（7个接触点） 滥用案例 安全需求 体系结构风险分析 基于风险的安全性测试 代码评审 渗透测试（OWASP ZAP） 安全运维 五个安全级别中各级别要做哪些安全测试 第八章：移动APP的测试移动应用的特点 Android/iOS native &amp; Web View 混合 更新很快 对用户体验要求高 网络连接不稳定 降低流量 降低功耗 移动应用主要做哪些测试 兼容性测 交互性测试 用户体验测试 耗电量测试 网络流量测试 网络连接测试 性能测试 稳定性测试 移动应用的专项测试 耗电量测试 流量测试 移动应用端的性能测试 web前端的性能测试 移动App端native性能测试 后台服务器性能测试 移动应用端测试工具自动化测试工具Android Calabash Robotium Appium UI AutoMator IOS UI Automation Frank 专项测试工具Android GSam Battary Monitor Pro 电量测试 IOS Xcode Instruments的两个工具 性能测试工具略 第九章：基于模型的软件测试基于模型的测试方法（MBT）的概念通过构建能够正确描述被测软件系统功能特性的模型，然后基于这个模型，产生测试用例，并执行这些测试用例的过程。 基本原理 为被测试系统（SUT）建模 基于模型产生测试用例 将抽象的测试具体化使得测试用例具有可执行性 执行测试 分析测试结果 有限状态机有限状态机（ Finite State Machine ，FSM）是对象行为建 模的工具，以描述对象在其生命周期内所经历的状态序列， 以及如何响应来自外界的各种事件 因果图不能根据输入条件的组合，直接确定所产生的结果，需要进行因果分析因果分析是通过因果图来完成因果图就是逻辑分析的图形化方法。 因果图的基本关系： 第十章：测试与缺陷管理测试计划包括哪些内容 明确测试目标 分析与确定测试范围 识别测试项及其优先级 识别测试风险，采取相应对策 测试工作量估算 测试资源、进度等安排 测试阶段出入准则 前三者是测试需求分析 测试套件/用例的概念缺陷的生命周期软件缺陷的生命周期 一个软件缺陷被 发现、报告到这个缺陷被修复、验证 直至最后关闭的完整过程 缺陷生命周期是各类开发人员一起参 与、协同测试的过程 软件缺陷一旦发现，应进入严密监控 之中，直至其关闭，及时修正缺陷， 缩短软件测试的进程，提高软件质量、 减少成本 基本的缺陷生命周期 缺陷的基本属性 严重性（severity）衡量缺陷对客户满意度的影响程度 示例：致命的/fatal、严重的/critical、一般的/major、微小的/minor 优先级 (Priority)：指缺陷被修复的紧急程度 其他属性： 缺陷标识（ID） 缺陷类型（type），如功能、UI、性能、文档 缺陷产生可能性（frequency）/可再现的概率 缺陷来源（source）：需求、设计、编码 缺陷原因（cause）：数据格式、计算错误、接口参数、 变量定义与引用等 附加信息：Trace Log／图片／录制这个操作过程 缺陷的两类（不同维度）基本分析 测试对象剖面的风险 测试对象比较复杂，在测试的广度和深度。 测试操作剖面的风险 测试操作过程中存在的各种风险，如测试环境和真实环境差异较大，测试流程不够完善导致测试执行难以控制、回归测试中以空间换时间的策略等。 风险识别的有效方法是通过头脑风暴、缺陷分析等方法把存在的风险都列出来，建立风险项目检查表。在测试过程中按照风险内容进行逐项检查、逐个确认，确定当前项目存在的潜在风险。 控制风险的对策 消除执行风险 降低进度风险 减少人员风险","categories":[{"name":"软件测试","slug":"软件测试","permalink":"http://www.octber.xyz/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"软件测试","slug":"软件测试","permalink":"http://www.octber.xyz/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"}]},{"title":"FamilyManage-Springboot注解-RequestMapping详解","slug":"FamilyManage-Springboot注解-RequestMapping详解","date":"2019-06-10T07:41:16.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/10/FamilyManage-Springboot注解-RequestMapping详解/","link":"","permalink":"http://www.octber.xyz/2019/06/10/FamilyManage-Springboot%E6%B3%A8%E8%A7%A3-RequestMapping%E8%AF%A6%E8%A7%A3/","excerpt":"前言上一次详解了@RestController注解,其中包括重要的@Controller等注解,这次来研究一下常用的@RequestMapping注解","text":"前言上一次详解了@RestController注解,其中包括重要的@Controller等注解,这次来研究一下常用的@RequestMapping注解 @RequestMapping This annotation can be used both at the class and at the method level. In most cases, at the method level applications will prefer to use one of the HTTP method specific variants 这个注释可以在类级和方法级使用。在大多数情况下，在方法级别上，应用程序更愿意使用HTTP方法特定的变体之一,这表明了我们使用的场景 类头 方法头 它一共有5种请求的方式: 12345* @see GetMapping* @see PostMapping* @see PutMapping* @see DeleteMapping* @see PatchMapping 源码分析1234@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Mapping 它包含以上注释 他是方法级别,或者类/接口级别 他是在运行时由VM保留的 他会被记录到javadoc种,作为公共api接口 他是一个Mapping name现在我们继续看RequestMapping的源代码 123456789/** * Assign a name to this mapping. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used on both levels, a combined name is derived by concatenation * with &quot;#&quot; as separator. * @see org.springframework.web.servlet.mvc.method.annotation.MvcUriComponentsBuilder * @see org.springframework.web.servlet.handler.HandlerMethodMappingNamingStrategy */String name() default &quot;&quot;; 简单来说就是给你的RequestMapping起个名字,在类型级别和方法级别都支持!当在这两个级别上使用时，组合名称由“#”作为分隔符连接派生。 value1234567891011/** * The primary mapping expressed by this annotation. * &lt;p&gt;This is an alias for &#123;@link #path&#125;. For example * &#123;@code @RequestMapping(&quot;/foo&quot;)&#125; is equivalent to * &#123;@code @RequestMapping(path=&quot;/foo&quot;)&#125;. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this primary mapping, narrowing it for a specific handler method. */@AliasFor(&quot;path&quot;)String[] value() default &#123;&#125;; 通过注解知道它和path是同一个意思,,可以是一个数组,默认是{} This is an alias for path(). For example @RequestMapping(&quot;/foo&quot;) is equivalent to @RequestMapping(path=&quot;/foo&quot;). path1234567891011121314/** * The path mapping URIs (e.g. &quot;/myPath.do&quot;). * Ant-style path patterns are also supported (e.g. &quot;/myPath/*.do&quot;). * At the method level, relative paths (e.g. &quot;edit.do&quot;) are supported * within the primary mapping expressed at the type level. * Path mapping URIs may contain placeholders (e.g. &quot;/$&#123;connect&#125;&quot;). * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this primary mapping, narrowing it for a specific handler method. * @see org.springframework.web.bind.annotation.ValueConstants#DEFAULT_NONE * @since 4.2 */@AliasFor(&quot;value&quot;)String[] path() default &#123;&#125;; 这里比较重要,path的书写方式很丰富,应当注意积累 method123456789/** * The HTTP request methods to map to, narrowing the primary mapping: * GET, POST, HEAD, OPTIONS, PUT, PATCH, DELETE, TRACE. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this HTTP method restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). */RequestMethod[] method() default &#123;&#125;; 方法一共有一下集中可以指定: 12345public enum RequestMethod &#123; GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS, TRACE&#125; 这些都应该详细了解一下,在实战中具体应用 params12345678910111213141516171819/** * The parameters of the mapped request, narrowing the primary mapping. * &lt;p&gt;Same format for any environment: a sequence of &quot;myParam=myValue&quot; style * expressions, with a request only mapped if each such parameter is found * to have the given value. Expressions can be negated by using the &quot;!=&quot; operator, * as in &quot;myParam!=myValue&quot;. &quot;myParam&quot; style expressions are also supported, * with such parameters having to be present in the request (allowed to have * any value). Finally, &quot;!myParam&quot; style expressions indicate that the * specified parameter is &lt;i&gt;not&lt;/i&gt; supposed to be present in the request. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this parameter restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;Parameter mappings are considered as restrictions that are enforced at * the type level. The primary path mapping (i.e. the specified URI value) * still has to uniquely identify the target handler, with parameter mappings * simply expressing preconditions for invoking the handler. */String[] params() default &#123;&#125;; 映射请求的参数，缩小主映射。 适用于任何环境的相同格式:“myParam=myValue”样式表达式序列，只有在发现每个参数都具有给定值时才映射请求。表达式可以通过使用“!”=”运算符，如”myParam!=myValue”。还支持“myParam”样式表达式，这些参数必须出现在请求中(允许有任何值)。最后,”!“myParam”样式表达式表示指定的参数不应该出现在请求中。 在类型级别和方法级别都支持!当在类型级使用时，所有方法级映射都继承这个参数限制(即在解析处理程序方法之前检查类型级限制)。 参数映射被认为是在类型级别强制执行的限制。主路径映射(即指定的URI值)仍然必须惟一地标识目标处理程序，参数映射只是表示调用处理程序的先决条件。 header12345678910111213141516171819202122/** * The headers of the mapped request, narrowing the primary mapping. * &lt;p&gt;Same format for any environment: a sequence of &quot;My-Header=myValue&quot; style * expressions, with a request only mapped if each such header is found * to have the given value. Expressions can be negated by using the &quot;!=&quot; operator, * as in &quot;My-Header!=myValue&quot;. &quot;My-Header&quot; style expressions are also supported, * with such headers having to be present in the request (allowed to have * any value). Finally, &quot;!My-Header&quot; style expressions indicate that the * specified header is &lt;i&gt;not&lt;/i&gt; supposed to be present in the request. * &lt;p&gt;Also supports media type wildcards (*), for headers such as Accept * and Content-Type. For instance, * &lt;pre class=&quot;code&quot;&gt; * &amp;#064;RequestMapping(value = &quot;/something&quot;, headers = &quot;content-type=text/*&quot;) * &lt;/pre&gt; * will match requests with a Content-Type of &quot;text/html&quot;, &quot;text/plain&quot;, etc. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this header restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * @see org.springframework.http.MediaType */String[] headers() default &#123;&#125;; 支持媒体类型通配符(*)，用于Accept和Content-Type等头部,比如: 1@RequestMapping(value = &quot;/something&quot;, headers = &quot;content-type=text/*&quot;) consumes123456789101112131415161718/** * The consumable media types of the mapped request, narrowing the primary mapping. * &lt;p&gt;The format is a single media type or a sequence of media types, * with a request only mapped if the &#123;@code Content-Type&#125; matches one of these media types. * Examples: * &lt;pre class=&quot;code&quot;&gt; * consumes = &quot;text/plain&quot; * consumes = &#123;&quot;text/plain&quot;, &quot;application/*&quot;&#125; * &lt;/pre&gt; * Expressions can be negated by using the &quot;!&quot; operator, as in &quot;!text/plain&quot;, which matches * all requests with a &#123;@code Content-Type&#125; other than &quot;text/plain&quot;. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings override * this consumes restriction. * @see org.springframework.http.MediaType * @see javax.servlet.http.HttpServletRequest#getContentType() */String[] consumes() default &#123;&#125;; 在注视中也给出了用法 12consumes = &quot;text/plain&quot;consumes = &#123;&quot;text/plain&quot;, &quot;application/*&quot;&#125; produces1234567891011121314151617181920/** * The producible media types of the mapped request, narrowing the primary mapping. * &lt;p&gt;The format is a single media type or a sequence of media types, * with a request only mapped if the &#123;@code Accept&#125; matches one of these media types. * Examples: * &lt;pre class=&quot;code&quot;&gt; * produces = &quot;text/plain&quot; * produces = &#123;&quot;text/plain&quot;, &quot;application/*&quot;&#125; * produces = MediaType.APPLICATION_JSON_UTF8_VALUE * &lt;/pre&gt; * &lt;p&gt;It affects the actual content type written, for example to produce a JSON response * with UTF-8 encoding, &#123;@link org.springframework.http.MediaType#APPLICATION_JSON_UTF8_VALUE&#125; should be used. * &lt;p&gt;Expressions can be negated by using the &quot;!&quot; operator, as in &quot;!text/plain&quot;, which matches * all requests with a &#123;@code Accept&#125; other than &quot;text/plain&quot;. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings override * this produces restriction. * @see org.springframework.http.MediaType */String[] produces() default &#123;&#125;; It affects the actual content type written, for example to produce a JSON response with UTF-8 encoding, 它会影响实际编写的内容类型，例如生成一个带有UTF-8编码的JSON响应 综合以上的简介我们常用的其实也就是前面几个,后面的不是很常用 最后我们先来了解一下@Mapping这个注解 @Mapping源码分析12345@Target(&#123;ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Mapping &#123;&#125; 他是RUNTIME的注释类型,很好理解,他的解释是: 1Meta annotation that indicates a web mapping annotation. 表示web映射注释的元注释。","categories":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"}],"tags":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"}]},{"title":"FamilyManage开发-深入Springboot注释","slug":"FamilyManage开发-深入Springboot注释","date":"2019-06-09T07:47:51.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/09/FamilyManage开发-深入Springboot注释/","link":"","permalink":"http://www.octber.xyz/2019/06/09/FamilyManage%E5%BC%80%E5%8F%91-%E6%B7%B1%E5%85%A5Springboot%E6%B3%A8%E9%87%8A/","excerpt":"前言Springboot最关键的就是优秀的注解,平时使用都没有注意底层的原理,虽然我也看不了多么的深,尽量吧","text":"前言Springboot最关键的就是优秀的注解,平时使用都没有注意底层的原理,虽然我也看不了多么的深,尽量吧 注释大全有一个博客记录的比较详细:https://blog.csdn.net/weixin_40753536/article/details/81285046 当然这个没有底层原理,我希望了解的是底层的原理 @RestController 12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Controller@ResponseBody RestController是由@Controller和@ResponseBody组成,也就是它既是一个Controller,也是直接返回结果的,不做路由跳转 我们一个一个了解: @Target 123456789101112@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target &#123; /** * Returns an array of the kinds of elements an annotation type * can be applied to. * @return an array of the kinds of elements an annotation type * can be applied to */ ElementType[] value();&#125; java.lang.annotation.Target 用于设定注解范围 java.lang.annotation.ElementType Target通过ElementType来指定注解适用范围的枚举集合 Target有一个ElementType[]的数组,而RestController中的@Target传入了ElementType中的TYPE类型,ElementType是什么?有哪些类型? 123456789101112131415161718192021222324252627282930313233343536373839public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE&#125; ElementType是一个枚举类型,此枚举类型的常量提供了Java程序中声明的元素的简单分类。 这些常量与Target元注释类型，用于指定使用注释类型的合法位置。 **ANNOTATION_TYPE**注释类型声明 **CONSTRUCTOR**构造函数声明 **FIELD**字段声明(包括枚举常量) **LOCAL_VARIABLE**局部变量声明 **METHOD**方法声明 **PACKAGE**包申报 **PARAMETER**参数声明 **TYPE**类、接口(包括注释类型)或枚举声明 在@RestController中使用@Target(ElementType.TYPE),表明@RestController是一个类/接口(包括注释类型)或枚举声明,规定了这个类的用途 @Retention 12345678910@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention &#123; /** * Returns the retention policy. * @return the retention policy */ RetentionPolicy value();&#125; 指示要保留带注释类型的注释的时间。如果注释类型声明中没有保留注释，则保留策略默认为RetentionPolicy.CLASS 只有当元注释类型直接用于注释时，保留元注释才有效。如果元注释类型在另一个注释类型中用作成员类型，则没有任何效果。 首先它是一个@Target(ElementType.ANNOTATION_TYPE)注释类型声明 默认使用RetentionPolicy,这是一个枚举类型,包括: SOURCE CLASS RUNTIME 而@RestController就是RUNTIME的类型,这三种类型是什么意思了? **CLASS**注释将由编译器记录在类文件中，而不必在运行时由VM保留。 **RUNTIME**注释将由编译器记录在类文件中，并在运行时由VM保留，因此可以反射地读取注释。 **SOURCE**注释将被编译器丢弃。 则表示@RestController是一个在运行时由VM保留的类,通过强大的反射机制进行操作 @Documented 12345@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Documented &#123;&#125; 这是一个很基础很简单的注释,根据之前的注释我们知道它是一个Runtime的Retention,并且是一个ElementType.ANNOTATION_TYPE)注释类型,没有成员方法 他的作用很简单:如果用@Ducumented对类型声明进行注释，则它的注释将成为带注释元素的公共API的一部分, @Controller 123456789101112131415@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Controller &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class) String value() default &quot;&quot;;&#125; @Controller是一个我们经常使用缺不知道原理的注解,我们首先根据他的源代码了解,文档中只说**指示带注释的类是“控制器”(例如web控制器)**。但是我们还需要深究 @Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Component 其中前三个注释我们明白其中的意思,那么第四个是什么意思呢? @Component 1234567891011121314@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface Component &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ String value() default &quot;&quot;;&#125; 被标注的类将会是一个”组件” 常用的几个用来标记stereotype的annotation。 @Component，@Controller，@Repository，@Service。 这四个都在org.springframework.stereotype包下面，后面3个都属于@Component。 可以理解为@Component是@Controller，@Repository，@Service的基类。 @Component是用来标记任何被Spring管理的组件。 @Controller用来标记presentation层（比如web controller）。 @Repository用来标记persistence层（比如DAO）。 @Service用来标记service层。 Annotation Type Description Component Indicates that an annotated class is a “component”.指示带注释的类是“组件”。 Controller Indicates that an annotated class is a “Controller” (e.g.)指示带注释的类是“控制器” Indexed Indicate that the annotated element represents a stereotype for the index.指示带注释的元素表示索引的构造型。 Repository Indicates that an annotated class is a “Repository”, originally defined by Domain-Driven Design (Evans, 2003) as “a mechanism for encapsulating storage, retrieval, and search behavior which emulates a collection of objects”.指示带注释的类是“存储库”，最初由领域驱动设计(Evans，2003)定义为“一种封装存储、检索和搜索行为的机制，该机制模拟对象的集合”。 Service Indicates that an annotated class is a “Service”, originally defined by Domain-Driven Design (Evans, 2003) as “an operation offered as an interface that stands alone in the model, with no encapsulated state.”指示带注释的类是“服务”，最初由领域驱动设计(Evans，2003)定义为“作为独立于模型的接口提供的操作，没有封装状态”。 @AliasFor可以看到在@Controller注解中的String Value() default “”;头上的注解@AliasFor(annotation = Component.class),该值可能表示对逻辑组件名称的建议，在自动检测组件的情况下转换为Spring bean。 AliasFor包含的注释: 123@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Documented 他是一个方法申明 他是一个运行时由VM保留的的类 注释将由javadoc记录 官方的解释:@AliasFor是一个注释，用于声明注释属性的别名。 @AliasFor is an annotation that is used to declare aliases for annotation attributes. 使用场景 **注释中的显式别名:**在单个注释中，可以对一对属性声明@AliasFor，以表明它们是彼此可互换的别名。 **元注释中属性的显式别名:**如果@AliasFor的annotation()属性被设置为与声明它的注释不同的注释，则属性()被解释为元注释中属性的别名(即，显式元注释属性覆盖)。这允许精确地控制注释层次结构中覆盖哪些属性。事实上，使用@AliasFor甚至可以为元注释的value属性声明别名。 **隐式注释中的别名:**如果一个或多个属性在一个声明注释的属性覆盖相同元注释属性(直接或间接)横跨,这些属性将被视为一组隐含的别名为彼此,导致行为类似于在一个注释中明确的别名。 在Spring的众多注解中，经常会发现很多注解的不同属性起着相同的作用，比如@RequestMapping的value属性和path属性，这就需要做一些基本的限制，比如value和path的值不能冲突，比如任意设置value或者设置path属性的值，都能够通过另一个属性来获取值等等。为了统一处理这些情况，Spring创建了@AliasFor标签。 ​ 例子: 1234567891011121314@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface RequestMapping &#123; @AliasFor(&quot;path&quot;) String[] value() default &#123;&#125;; @AliasFor(&quot;value&quot;) String[] path() default &#123;&#125;; //...&#125; 上述代码是RequestMappding的Path和Value,我们在使用过程中知道这两个属性的意思是一样的,通过互相显示的标注,表明这两者不能发生冲突,是唯一的 再比如就在@AliasFor的源代码中有两个属性就是一样的: 1234@AliasFor(&quot;attribute&quot;)String value() default &quot;&quot;;@AliasFor(&quot;value&quot;)String attribute() default &quot;&quot;; 而我们疑惑的@AliasFor(annotation = Component.class),也是表示我们的注解的类型,默认是 Annotation.class 这样我们就全部了解了@Controller了,现在我们来了解一下@ResponseBody @ResponseBodyAnnotation that indicates a method return value should be bound to the web response body. Supported for annotated handler methods. 解释过来就是:这个注解表明这是一个方法用来江”值”返回到网页返回体中,而不是跳转路由 源代码: 123456@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface ResponseBody &#123;&#125; 到此我们九八RestController全部理解完毕,当然还欠缺很多,之后继续学习","categories":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"}],"tags":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"}]},{"title":"关于在杭州滨江区租房的一些建议","slug":"关于在杭州滨江区租房的一些建议","date":"2019-06-09T05:39:35.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/09/关于在杭州滨江区租房的一些建议/","link":"","permalink":"http://www.octber.xyz/2019/06/09/%E5%85%B3%E4%BA%8E%E5%9C%A8%E6%9D%AD%E5%B7%9E%E6%BB%A8%E6%B1%9F%E5%8C%BA%E7%A7%9F%E6%88%BF%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/","excerpt":"前言2019年6月1号-2019年6月2号在杭州滨江区住房记录","text":"前言2019年6月1号-2019年6月2号在杭州滨江区住房记录 概述由于要在恒生电子实习很长一段时间,只能在滨江区住房,提前过去考察一下,有一些心得但愿能帮得上忙 租房渠道一般来说住房渠道有以下这些: 租房APP上找房 社交APP上找房 微信群/QQ群找房 线下找房 他们的特点是: 住房APP上找房: 自如APP:不建议,出名的假房源,甲醛房 58同城APP:不建议,中介很多,他会带你看很多处房源,最后你不得不签,费用杂乱,得不到保障,中介费高,房子品质得不到保障 安居客APP:不建议你看图就知道肯定是假的 zuber:推荐,zuber上绝大多数都是房主自己的原户型,合租偏多,照片真实,有录像,可以直接联系房租看房 其他APP:不知道(比如”闲鱼”,没了解过,感觉不专业) 社交APP上找房: 豆瓣:推荐,上面不仅仅有很多优质房源,而且有对应杭州滨江区的租房群(微信群) 知乎什么的,不推荐,别的不知道 微信群/QQ群找房:推荐,一般都是房主或者二房主,真实可靠,看房比较方便,当然智商得够用,要甄别 线下找房:不建议,你以为会在墙上,玻璃上贴广告,其实都没有 总结:建议在zuber上或者豆瓣上,或者群里找3-5家房主,自己排一个日程,去看房 住房价格 租房APP上找房: 较便宜(小心交了智商税) 社交APP上找房: 中等 微信群/QQ群找房: 偏贵 线下找房: 没找过 总结:一般来说,价格在(1500-3000)可以租到(较差-较好)的卧室(注意是一个卧室,一般可以住1-2人,不是整租) 住房方式 整租:可以考虑,但是比较贵,你作为二房主,需要考虑很多事情,除非身边有很多人一起,不要考虑,出了事情还得自己掏腰包 合租:建议合租,但是要注意: 其他租客:注意他们的身份,工作,年纪,日常习惯,如果有年纪比较大的,半夜工作的,没有工作的之类的,要注意甄别他们的素质 卫生条件:合租大家用一套客厅,如果你没有独卫,你还要考虑和别人一起用卫生间,如果大家没有卫生表打扫卫生,说到底还是素质问题 男生的话注意女生,女生的话注意男生,懂?一个人占用卫生间一小时不出来,你上不上班? 总结: 建议合租,注意舍友素质,注意大家的生活日程 滨江区概述距离一般来说,以恒生大厦为中心,3.5公里以内是比较合理的,亲测2.2两公里骑自行车(共享单车)要将近18分钟,每天这么一趟,真的挺累,建议保持在2.5公里以内,除非里喜欢大早晨锻炼身体 住房点(按照我推荐的顺序)1. 太阳国际/国信嘉园/彩虹豪庭 推荐指数:五颗星 推荐理由: 距离近(1.2公里) 环境好:高档小区,樱花跑道,江景房,安保好 素质高:住户素质好 地铁近 原户型 缺点: 价格贵:2500-3500一个主卧,2000起步其他卧室 物业贵,100左右一个月 2. 江畔云庐 推荐指数:四颗星 推荐理由 价格合理:2000左右 距离适中:2.8公里 中档小区 缺点: 稍微有点远 房间稍差，但是还行，当然没法和第一个推荐的比 卫生稍差 3. 临江花园 推荐指数:三颗星 推荐理由： 价格便宜：2000以下 缺点： 距离远：3公里以上 4.滨江浦沿星汇荣邸小区 推荐指数:两颗星​ 推荐理由： 楼下有地铁 真的便宜：1600左右 缺点： 距离远：4公里 5.宝龙城附近/通策广场附近/碧水豪园 推荐指数:一颗心 推荐理由: 别墅 缺点: 中介 总结: 自己琢磨把,部分地区我有图,私聊我要,QQ:925474088,均属个人意见 细节 距离很重要,不建议超过2.5公里 卫生很重要 舍友很重要 住房1年起步,后续需要自己转租 恒生大厦附近没有地铁站,最近的地铁站有两公里多一点大概,所以那个楼下有地铁的没用,预计2020-2021年能修好路过恒生的地铁","categories":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"FamilyManage开发-SpringShiro","slug":"FamilyManage开发-SpringShiro","date":"2019-06-07T09:22:53.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/07/FamilyManage开发-SpringShiro/","link":"","permalink":"http://www.octber.xyz/2019/06/07/FamilyManage%E5%BC%80%E5%8F%91-SpringShiro/","excerpt":"前言FamilyManage项目的后台部分，最核心的一部分一定是安全控制和权限控制。 这一次，我们就来了解一下什么是Spring Shiro","text":"前言FamilyManage项目的后台部分，最核心的一部分一定是安全控制和权限控制。 这一次，我们就来了解一下什么是Spring Shiro 什么是Spring Shiro Apache Shiro 是 Java 的一个安全（权限）框架。 Shiro 可以非常容易的开发出足够好的应用，其不仅可以用在 JavaSE 环境，也可以用在 JavaEE 环境。 Shiro 可以完成：认证、授权、加密、会话管理、与Web 集成、缓存 等。 下载：http://shiro.apache.org/ 基本功能 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用 户是否能进行什么操作，如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户 对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有 信息都在会话中；会话可以是普通 JavaSE 环境，也可以是 Web 环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储 Web Support：Web 支持，可以非常容易的集成到Web 环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可 以提高效率； Concurrency：Shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能 把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登 录了 Shiro架构 Subject：应用代码直接交互的对象是 Subject，也就是说 Shiro 的对外 API 核心就是 Subject。Subject 代表了当前“用户”， 这个用户不一定 是一个具体的人，与当前应用交互的任何东西都是 Subject，如网络爬虫， 机器人等；与 Subject 的所有交互都会委托给 SecurityManager； Subject 其实是一个门面，SecurityManager 才是实际的执行者； SecurityManager：安全管理器；即所有与安全有关的操作都会与 SecurityManager 交互；且其管理着所有 Subject；可以看出它是 Shiro 的核心，它负责与 Shiro 的其他组件进行交互，它相当于 SpringMVC 中 DispatcherServlet 的角色 Realm：Shiro 从 Realm 获取安全数据（如用户、角色、权限），就是说 SecurityManager 要验证用户身份，那么它需要从 Realm 获取相应的用户 进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色/ 权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource。可以有 1 个或多个 Realm，可以认为是安全实体数据源，即用于获取安全实体 的；可以是JDBC 实现，也可以是内存实现等等；由用户提供；所以一般在应用中都需要 实现自己的 Realm； Authenticator：负责 Subject 认证，是一个扩展点，可以自定义实现；可以使用认证 策略（Authentication Strategy），即什么情况下算用户认证通过了； Authorizer：授权器、即访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能； SessionManager：管理 Session 生命周期的组件；而 Shiro 并不仅仅可以用在 Web 环境，也可以用在如普通的 JavaSE 环境 CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据 基本上很少改变，放到缓存中后可以提高访问的性能 Cryptography：密码模块，Shiro 提高了一些常见的加密组件用于如密码加密/解密。 编写Shiro配置类Shiro配置的最重要的三个就是Subject（用户主体），WebSecurityManager（安全管理器）、Realm（自定义验证）和ShiroFilterFactory（过滤器），安全管理器通过对用户主体进行验证，而验证的方式用户可以进行自定义，如果我们还需要进行加密处理等操作，那么我们需要进行HashedCredentialsMatcher的配置 配置DefaultWebSecurityManager123456789/** * 权限管理，配置主要是Realm的管理认证 */@Bean(name = &quot;securityManager&quot;)public DefaultWebSecurityManager defaultSecurityManager()&#123; DefaultWebSecurityManager defaultWebSecurityManager = new DefaultWebSecurityManager(); defaultWebSecurityManager.setRealm(shiroRealm()); return defaultWebSecurityManager;&#125; 代码中的shiroRealm()就是我们需要自定义的验证方法。 自定义验证方法ShiroRealm1234567891011/** * 自定义验证方法 * @return */@Beanpublic ShiroRealm shiroRealm()&#123; ShiroRealm shiroRealm = new ShiroRealm(); //加入加密算法 shiroRealm.setCredentialsMatcher(shiroHashedCredentialsMatcher()); return shiroRealm;&#125; 这个ShiroRealm就是我们需要自定义的验证方法，那么我现在来编写一个ShiroRealm类定制我们的验证方法，它需要继承自AuthorizingRealm，就需要实现其中的重要方法： 1.doGetAuthenticationInfo(AuthenticationToken token)1234567891011/** * 判断用户是否在缓存记录(即Shiro是否Remember user)和登录 * @param token 该凭证来自客户端传来的用户信息 * @return * @throws AuthenticationException */@Overrideprotected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; ... ... return null;&#125; 我们通过源码进行分析：AuthenticationToken是什么东西呢？ 1public interface AuthenticationToken extends Serializable 通过源码我们知道他是一个可序列化的接口类 我们看它类头的注释 1234567891011121314151617181920212223242526272829303132333435363738/** * &lt;p&gt;An &lt;tt&gt;AuthenticationToken&lt;/tt&gt; is a consolidation of an account&#x27;s principals and supporting * credentials submitted by a user during an authentication attempt. * &lt;p/&gt; * &lt;p&gt;The token is submitted to an &#123;@link Authenticator Authenticator&#125; via the * &#123;@link Authenticator#authenticate(AuthenticationToken) authenticate(token)&#125; method. The * Authenticator then executes the authentication/log-in process. * &lt;p/&gt; * &lt;p&gt;Common implementations of an &lt;tt&gt;AuthenticationToken&lt;/tt&gt; would have username/password * pairs, X.509 Certificate, PGP key, or anything else you can think of. The token can be * anything needed by an &#123;@link Authenticator&#125; to authenticate properly. * &lt;p/&gt; * &lt;p&gt;Because applications represent user data and credentials in different ways, implementations * of this interface are application-specific. You are free to acquire a user&#x27;s principals and * credentials however you wish (e.g. web form, Swing form, fingerprint identification, etc) and * then submit them to the Shiro framework in the form of an implementation of this * interface. * &lt;p/&gt; * &lt;p&gt;If your application&#x27;s authentication process is username/password based * (like most), instead of implementing this interface yourself, take a look at the * &#123;@link UsernamePasswordToken UsernamePasswordToken&#125; class, as it is probably sufficient for your needs. * &lt;p/&gt; * &lt;p&gt;RememberMe services are enabled for a token if they implement a sub-interface of this one, called * &#123;@link RememberMeAuthenticationToken RememberMeAuthenticationToken&#125;. Implement that interface if you need * RememberMe services (the &lt;tt&gt;UsernamePasswordToken&lt;/tt&gt; already implements this interface). * &lt;p/&gt; * &lt;p&gt;If you are familiar with JAAS, an &lt;tt&gt;AuthenticationToken&lt;/tt&gt; replaces the concept of a * &#123;@link javax.security.auth.callback.Callback&#125;, and defines meaningful behavior * (&lt;tt&gt;Callback&lt;/tt&gt; is just a marker interface, and of little use). We * also think the name &lt;em&gt;AuthenticationToken&lt;/em&gt; more accurately reflects its true purpose * in a login framework, whereas &lt;em&gt;Callback&lt;/em&gt; is less obvious. * * @see RememberMeAuthenticationToken * @see HostAuthenticationToken * @see UsernamePasswordToken * @since 0.1 */ 我们可以获得这些信息： AuthenticationToken is a consolidation of an account’s principals and supporting：它是对帐户主体和支持的整合。 credentials submitted by a user during an authentication attempt：用户在身份验证尝试期间提交的凭据。当然通过类名我们也能知道，这是一种凭据Token。 Common implementations of an AuthenticationToken would have username/password pairs, X.509 Certificate, PGP key, or anything else you can think of. The token can be：显而易见，这个类认为实现这个接口的类，应当提供一些比如用户名/密码这种用户登录的凭证，或者是其他你认为可以验证用户的凭据 If your application authentication process is username/password based(like most), instead of implementing this interface yourself, take a look at the &#123;@link UsernamePasswordToken UsernamePasswordToken&#125; class, as it is probably sufficient for your needs. 1234567891011121314151617181920这里就是重点了，既然这个类是一个接口类，实现其类的时候说过了要注意对用户登陆的凭据进行一些处理，那么这一行注释就非常重要：他说如果你的验证过程是基于用户名&#x2F;密码的方式，你可能需要看看UsernamePasswordToken这个类，他可能会给你提供你所需要的。- 再往后还有对RememberMeAuthenticationToken和Callback的陈述，显而易见。回头来看我们的这个类，刚刚我并没有写出这个函数内部的代码，现在来看看我是怎么写的：&#96;&#96;&#96;java@Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; UsernamePasswordToken userToken &#x3D; (UsernamePasswordToken) token; User user &#x3D; IUserService.findByName(userToken.getUsername()); if(user !&#x3D; null) &#123; &#x2F;&#x2F;该对象会记录在Shiro中认为是info,登录和缓存判断时使用 SimpleAuthenticationInfo simpleAuthenticationInfo &#x3D; new SimpleAuthenticationInfo(user, user.getPassword(),EncodeUtil.getSalt(user.getUserId()),getName()); return simpleAuthenticationInfo; &#125; return null; &#125; 我使用了UsernamePasswordToken，上文说过，他实现了AuthenticationToken，我的应用程序中正是使用了这种用户名+密码的验证方式，那么将token强制转化成这种类型也不为奇怪，现在我们来看看UsernamePasswordToken这个类，根据源代码： 1public class UsernamePasswordToken implements HostAuthenticationToken, RememberMeAuthenticationToken 我们知道他实现了HostAuthenticationToken, RememberMeAuthenticationToken这两个类，而第一个又实现了AuthenticationToken，显而易见了。 1public interface HostAuthenticationToken extends AuthenticationToken 它只有一个方法那就是返回客户端的host名字。 123456789101112131415/** * Returns the host name of the client from where the * authentication attempt originates or if the Shiro environment cannot or * chooses not to resolve the hostname to improve performance, this method * returns the String representation of the client&#x27;s IP address. * &lt;p/&gt; * When used in web environments, this value is usually the same as the * &#123;@code ServletRequest.getRemoteHost()&#125; value. * * @return the fully qualified name of the client from where the * authentication attempt originates or the String representation * of the client&#x27;s IP address is hostname resolution is not * available or disabled. */String getHost(); 看看第二个RememberMeAuthenticationToken是什么呢？ 123456789101112public interface RememberMeAuthenticationToken extends AuthenticationToken &#123; /** * Returns &#123;@code true&#125; if the submitting user wishes their identity (principal(s)) to be remembered * across sessions, &#123;@code false&#125; otherwise. * * @return &#123;@code true&#125; if the submitting user wishes their identity (principal(s)) to be remembered * across sessions, &#123;@code false&#125; otherwise. */ boolean isRememberMe();&#125; 显而易见他也继承了AuthenticationToken，他也只有一个方法，那就是“记住我？”，客户在一次登录后将记住，之后可以不用重复登录。或许英文更适合你的口味？ 1234567891011/** * An &#123;@code AuthenticationToken&#125; that indicates if the user wishes their identity to be remembered across sessions. * &lt;p/&gt; * Note however that when a new session is created for the corresponding user, that user&#x27;s identity would be * remembered, but they are &lt;em&gt;NOT&lt;/em&gt; considered authenticated. Please see the * &#123;@link org.apache.shiro.subject.Subject#isRemembered()&#125; JavaDoc for an in-depth explanation of the semantic * differences of what it means to be remembered vs. authenticated. * * @see org.apache.shiro.subject.Subject#isRemembered() * @since 0.9 */ 返回来看我们当前这个类UsernamePasswordToken，他能够处理“记住我”的功能同时能够知道客户端的名字，除去一些基本的构造函数，我们看看他有什么特殊函数呢？ 他有username/password的setter和getter，有清空凭据的clear方法，仅此而已，那么我们想在doGetAuthenticationInfo中判断用户是否在缓存记录中（是否已经“记住我”）的话，我们可以通过getUsername()的方法获得用户名，通过用户名调用Service中的方法获得指定用户。 SimpleAuthenticationInf现在我们需要来看另一个东西AuthenticationInfo，因为他和上述代码中的SimpleAuthenticationInfo有关系，在我们找到对应用户的时候，我们如何处理呢？ 我们看源代码中的注释： 12&lt;code&gt;AuthenticationInfo&lt;/code&gt; represents a Subject&#x27;s (aka user&#x27;s) stored account information relevant to the* authentication/log-in process only. 他代表着一个Subject（客户主体）储存的账号信息和认证/登录过程有关。那么他和AuthenticationToken有什么区别呢？ AuthenticationInfo提供的是represent already-verified and stored account data，就是已经准备好的，储存好的账户信息 AuthenticationToken的作用是： 123AuthenticationToken represents data* submitted for any given login attempt (which may or may not successfully match the verified and stored account* &lt;code&gt;AuthenticationInfo&lt;/code&gt;). 他对任何的登录请求，不管能不能够通过验证进行确认和储存的信息，都会进行处理。 了解了这个，我们回头看这个类： 1public class SimpleAuthenticationInfo implements MergableAuthenticationInfo, SaltedAuthenticationInfo 就是我们刚刚提及的我们使用的这个类他实现的MergableAuthenticationInfo, SaltedAuthenticationInfo有什么特点呢？ MergableAuthenticationInfo： 1public interface MergableAuthenticationInfo extends AuthenticationInfo 他就是继承自AuthenticationInfo这个类，他有什么作用呢？ 1void merge(AuthenticationInfo info); 那就是合并，简而言之不要重复呗，相同的用户不要创建多次，我们还需要记录最新的一个即可。 SaltedAuthenticationInfo： 1public interface SaltedAuthenticationInfo extends AuthenticationInfo 他也是继承自AuthenticationInfo，显而易见这是一个用于“加盐”的工具，他的功能就是： 1ByteSource getCredentialsSalt(); 获得Salt盐，加盐是个非常重要的过程，对于安全性有了进一步的保障，如果我们进行了加盐操作，那么这个类就派得上用场了。 分析过这两个了类及他们的父类，我们就理解了SimpleAuthenticationInfo是做什么的了： 我们可以用他其中的构造方法，对客户配置很多属性，比如： 12345public SimpleAuthenticationInfo(Object principal, Object hashedCredentials, ByteSource credentialsSalt, String realmName) &#123; this.principals = new SimplePrincipalCollection(principal, realmName); this.credentials = hashedCredentials; this.credentialsSalt = credentialsSalt;&#125; 设置用户对象，用户密码，盐，用户名等等，将这个对象作为doGetAuthenticationInfo函数的返回值，我们就做完了本次操作，当然如果查不到用户，返回null即可。 2.doGetAuthorizationInfo(PrincipalCollection principals)这个功能我们做什么呢？定义如何获取用户的角色和权限的逻辑，给shiro做权限判断。 PrincipalCollection 是什么呢？他就是缓存中的用户凭证，你如果问我缓存怎么来的，那么你上边的一定没理解，就是**doGetAuthenticationInfo(AuthenticationToken token)**注入的呀！ 既然这个函数是定义如何获取用户的角色和权限的逻辑的，那么如何获得呢？ 1String username = (String) super.getAvailablePrincipal(principals); 我们通过super中的getAvailablePrincipal方法，获得可用的用户凭据，也就是我们的用户名，有了用户名我们就能得到这个用户的所有信息（或者为null）： 123456789User user = IUserService.findByName(username);if(user != null)&#123; SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); Set&lt;String&gt; roles = user.getRoleList().stream().map(role -&gt; role.getRoleName()).collect(Collectors.toSet()); //存放用户权限 info.setRoles(roles); return info;&#125;return null; 有的话那最好，我们定义他的权限角色，并setRoles设置进去，这里使用的是Set集，也就是不允许重复，返回这个info就拥有了角色，之后我们进行判断的时候就知道这个用户有哪些角色和权限能做什么事情。 好了，到这里，我们就定制化了验证方法，完成了ShiroRealm 配置ShiroFilterFactoryBean过滤器过滤器，顾名思义，设置对应的过滤条件和跳转条件。 12@Beanpublic ShiroFilterFactoryBean shiroFilterFactoryBean(DefaultWebSecurityManager securityManager) 这个函数的返回值是ShiroFilterFactoryBean，我们来看一下源文件中的介绍： To prevent configuration duplication, this implementation provides the following properties to allow you to set relevant values in only one place: 翻译过来就是：为了防止配置重复，这个实现提供了以下属性，允许您只在一个地方设置相关值: 这些属性就是： setLoginUrl(String) 123- &#96;&#96;&#96; setSuccessUrl(String) setUnauthorizedUrl(String) 1234567891011121314使用这三个有什么好处呢？&#96;Then at startup, any values specified via these 3 properties will be applied to all configured Filter instances so you don&#39;t have to specify them individually on each filter instance. To ensure your own custom filters benefit from this convenience, your filter implementation should subclass one of the 3 mentioned earlier.&#96;翻译过来就是：&#96;然后在启动时，通过这3个属性指定的任何值都将应用于所有已配置的过滤器实例，这样您就不必在每个过滤器实例上分别指定它们。为了确保您自己的自定义过滤器能够从这种便利中获益，您的过滤器实现应该继承前面提到的三个过滤器之一。&#96;1. 申请一个ShiroFilterFactoryBean:&#96;&#96;&#96;javaShiroFilterFactoryBean shiroFilterFactoryBean &#x3D; new ShiroFilterFactoryBean();shiroFilterFactoryBean.setSecurityManager(securityManager); 定义一个Map来储存了路由规则 1234567891011Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;();// 比如静态资源map.put(&quot;/*.html&quot;,&quot;anon&quot;);map.put(&quot;/**/*.css&quot;,&quot;anon&quot;);map.put(&quot;/**/*.js&quot;,&quot;anon&quot;);map.put(&quot;/**/*.png&quot;,&quot;anon&quot;);map.put(&quot;/**/*.jpg&quot;,&quot;anon&quot;);map.put(&quot;/**/*.jpeg&quot;,&quot;anon&quot;);map.put(&quot;/**/*.html&quot;,&quot;anon&quot;);shiroFilterFactoryBean.setFilterChainDefinitionMap(map); 设置登录页面 1shiroFilterFactoryBean.setLoginUrl(&quot;/*/login&quot;); 返回return 1return shiroFilterFactoryBean; 配置ShiroRealm的bean上文提到配置自定义的ShiroRealm,我们需要在ShiroConfig中将其作为bean注入 1234567891011121314/** * 自定义验证方法加入到容器中 * 当前使用的不是框架默认的简单密码匹配方法 * 该方是MD5加盐的对称加密算法 * * @return ShiroRealm */ @Bean public ShiroRealm shiroRealm()&#123; ShiroRealm shiroRealm = new ShiroRealm(); //加入加密算法 shiroRealm.setCredentialsMatcher(shiroHashedCredentialsMatcher()); return shiroRealm; &#125; 代码中提到的setCredentialsMatcher,也是下一步要谈到的 配置密码校验规则HashedCredentialsMatcher1234567891011121314151617/** * 密码校验规则HashedCredentialsMatcher * 这个类是为了对密码进行编码的 * 防止密码在数据库里明码保存 ,当然在登陆认证的时候 * 这个类也负责对form里输入的密码进行编码 * 处理认证匹配处理器：如果自定义需要实现继承HashedCredentialsMatcher */ @Bean(&quot;hashedCredentialsMatcher&quot;) public HashedCredentialsMatcher shiroHashedCredentialsMatcher() &#123; HashedCredentialsMatcher credentialsMatcher = new HashedCredentialsMatcher(); //指定加密方式为MD5 credentialsMatcher.setHashAlgorithmName(&quot;MD5&quot;); //加密次数 credentialsMatcher.setHashIterations(1024); credentialsMatcher.setStoredCredentialsHexEncoded(true); return credentialsMatcher; &#125; 来了解一下HashedCredentialsMatcher是什么?官网地址 实现的之类: Md2CredentialsMatcher, Md5CredentialsMatcher, Sha1CredentialsMatcher, Sha256CredentialsMatcher, Sha384CredentialsMatcher, Sha512CredentialsMatcher 证书散列是保护用户私有凭据(密码、密钥等)时最常见的安全技术之一。大多数开发人员从来不想以普通的形式存储用户的凭据，任何人都可以查看，因此他们通常会在将用户的凭据保存到数据存储区之前对其进行散列。 这个类(及其子类)功能如下： 散列AuthenticationToken用户在登录期间提供的凭据。 将此散列值直接与AuthenticationInfo存储在系统中的凭据(存储帐户凭据预计已经以散列形式出现)。 如果这两个值是equal，则提交的凭据匹配，否则不匹配。 过程很好理解,但是我们还应当继续使用”加盐” 盐渍和多重散列迭代 因为简单的散列通常对安全的应用程序不够好，这个类也支持‘盐析’和多个散列迭代。请读这篇精彩的文章 散列Java文章 若要了解盐渍和多次迭代，以及您可能需要使用它们的原因，请执行以下操作。(注：第5条“为何加盐？”和6“加强对抗攻击者的攻击”)。我们还应该注意到，Shiro的所有Hash实现(例如，Md5Hash``Sha1Hash等)通过重载构造函数支持盐析和多个散列迭代。 来看一下我使用到的Api void setHashAlgorithmName(String hashAlgorithmName)设置Hash algorithmName在为凭据匹配执行散列时使用。 void setHashIterations(int hashIterations)设置提交的次数。AuthenticationToken在与系统中存储的凭据进行比较之前，将对其凭证进行散列。 void setStoredCredentialsHexEncoded(boolean storedCredentialsHexEncoded)如果系统存储的凭据散列是否已编码，则设置指示符。 我们使用这样的加密方式,配置到ShiroRealm中去 这样,最基本的配置就告一段落,很多地方还是需要修改的,日后再谈","categories":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"}],"tags":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"}]},{"title":"FamilyManage开发-Springboot后端","slug":"FamilyManage开发-Springboot后端","date":"2019-06-07T09:01:44.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/07/FamilyManage开发-Springboot后端/","link":"","permalink":"http://www.octber.xyz/2019/06/07/FamilyManage%E5%BC%80%E5%8F%91-Springboot%E5%90%8E%E7%AB%AF/","excerpt":"前言本项目的后端采用Springboot框架进行开发。","text":"前言本项目的后端采用Springboot框架进行开发。 开发的IDE我采用InteliJ IDEA，使用Maven作为版本控制工具，没有使用Gradle是因为虽然Gradle更为简洁，但是灵活性太高，虽然Maven写的更为繁琐，但是逻辑性更强，看起来结构更为清晰。 附录我创建时的pom.xml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;onlypear&lt;/groupId&gt; &lt;artifactId&gt;familygrow&lt;/artifactId&gt; &lt;version&gt;1.0.0-FAMILY&lt;/version&gt; &lt;name&gt;familygrow&lt;/name&gt; &lt;description&gt;family grow web server&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-web-starter&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 目前使用到的 Spring Shiro 安全控制（权限控制） Mybatis 定制化处理SQL MySQL 使用腾讯云主机配置的MySQL Lombok 编译时生成，简化代码 将来使用的 RabbitMQ 消息队列 Redis 缓存 Spring Cloud Mail 邮件服务 OSS 对象储存 。。。","categories":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"}],"tags":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"}]},{"title":"FamilyManage开发-Vue创建项目","slug":"FamilyManage开发-Vue创建项目","date":"2019-06-06T12:38:41.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/06/06/FamilyManage开发-Vue创建项目/","link":"","permalink":"http://www.octber.xyz/2019/06/06/FamilyManage%E5%BC%80%E5%8F%91-Vue%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE/","excerpt":"前言本节通过Vue-cli v3.6.3创建Vue项目。","text":"前言本节通过Vue-cli v3.6.3创建Vue项目。 创建nrm首先我们使用nrm设置，开发的npm registry 管理工具 nrm, 能够查看和切换当前使用的registry。nrm的安装及基本操作： 12345npm install -g nrmnrm lsnrm use [name] # 我使用nrm use taobaonrm helpnrm home [name] # 查看对应源的官网 第一步创建Vue项目我们只需要 1vue create family-manage 第一次会让我们选择please pick a preset，使用默认或者手动配置 这里就有必要一一看一下都是些什么东西了。 Babel 官网走一波：https://babeljs.io 推荐一波优秀博文：https://www.cnblogs.com/gg1234/p/7168750.html 搬运工： babel官网正中间一行黄色大字写着“babel is a javascript compiler”，翻译一下就是babel是一个javascript转译器。为什么会有babel存在呢？原因是javascript在不断的发展，但是浏览器的发展速度跟不上。以es6为例，es6中为javascript增加了箭头函数、块级作用域等新的语法和Symbol、Promise等新的数据类型，但是这些语法和数据类型并不能够马上被现在的浏览器全部支持，为了能在现有的浏览器上使用js新的语法和新的数据类型，就需要使用一个转译器，将javascript中新增的特性转为现代浏览器能理解的形式。babel就是做这个方面的转化工作。 显而易见我们应当选择Balbel TypeScript一下内容来自于 Hongten。 TypeScript是JavaScript类型的超集，并且可以编译为纯JavaScript。在任何浏览器，集群（服务器），操作系统上面都可以运行，而且还开源。TypeScript的来源于微软的团队。 TypeScript 是 JavaScript 的强类型版本。然后在编译期去掉类型和特有语法，生成纯粹的 JavaScript 代码。由于最终在浏览器中运行的仍然是 JavaScript，所以 TypeScript 并不依赖于浏览器的支持，也并不会带来兼容性问题。 TypeScript 是 JavaScript 的超集，这意味着他支持所有的 JavaScript 语法。并在此之上对 JavaScript 添加了一些扩展，如 class / interface / module 等。这样会大大提升代码的可阅读性。使用过Java的同学就更能够明白这个道理。 强类型语言的优势在于静态类型检查，概括来说主要包括以下几点： 静态类型检查 静态类型检查可以避免很多不必要的错误， 不用在调试的时候才发现问题 。 IDE 智能提示 在 TypeScript 这一类语言之前， JavaScript 的智能提示基本完全依赖 IDE 提供的猜测 (在猜测的质量上， Visual Studio 和 brackets 是我见过的最好的)。 局限性就是， 这种猜测可能并不正确， 并且也缺乏更多的辅助信息， 所以要正确使用一个类库， 得不断地在文档和 IDE 之间切换， 影响心情和效率。 而 TypeScript 不仅自己写的类库有丰富的类型信息， 也可以对其他纯 JS 项目进行类型标注 (DefinitelyTyped)， 便于使用者直接在 IDE 中浏览 API， 效率大增。 而对于自己的或者团队的代码， 好处也很明显。 团队的代码自己不一定能把各种接口记得滚瓜烂熟， 自己的代码如果规模大了也很难记全， 这个时候再去翻源文件。。。 代码重构 且不说我这种经常纠结变量名的会时不时看某个变量名不顺眼， 改之的情况。 有时候的确需要修改一些变量/属性/方法名， 牵涉到属性和方法的时候， 很多改动是跨文件的， 不像普通变量可以简单定位 scope， 属性方法名的重命名对于 JS 来说异常痛苦， 一方面是修改本身就不方便， 另一方面是改了还不确定该改的是不是改了， 不该改的是不是也改了。 而 TypeScript 的静态类型系统就可以较为完美的解决这个问题 (这个地方还牵涉到一些最佳实践， 就暂不深入了)。 可读性 对于阅读代码的人来讲， 各种便利的类型一目了然， 更容易明白作者的意图。TypeScript 虽然是强类型语言，但是如果对象被声明为了 any 类型，就会忽略所有的类型检查。这种灵活的结构保证了他可以在保证整体有强类型检查优势的同时，在一些细节问题上保持弱类型的灵活。TypeScript 本身是开源的，这意味着开发者可以自由修改其源代码，同时 TypeScript 的架构设计也很优秀，提供了充分的 API 接口方便开发者进行进一步扩展。顺便说一下，TypeScript 编译器本身是用 TypeScript 开发的。构建流程是先用旧版本的 TypeScirptCompiler。js 将新版本的 TypeScript Language 的 TypeScript源代码编译成新的 TypeScriptCompiler。js，听起来很厉害的样子。由于其开源性，通过 TypeScript Compiler API，开发者可以自己实现编译器（比如添加增量编译和自动编译，大幅提升编译速度），自定义语法检查，以及自定义输出结构等。 由于编译器核心灵活的结构，开发者只需要简单的添加一些代码，就可以在 IDE 中支持 TypeScript 的诸多特性。白鹭引擎是基于 TypeScript 的开源 HTML5 游戏引擎。白鹭引擎的后续版本会利用这些特性不断完善引擎自身。举例，我们的 IDE Egret Wing 就利用了 TypeScript Service API 实现了了代码智能提示等功能。文档生成工具也是通过扩展 TypeScript Compiler API 实现的。 我认为 TypeScript 是一项非常值得学习的新技术，由于他是 JavaScript 的超集，对 JavaScript 开发者来说入门门槛很低（相对于 Dart / CoffeeScript 等其他 JavaScript 变种来说 ）。 PWAPWA：Progressive Web App，为什么我们要使用PWA呢？ 搬运工：https://www.jianshu.com/p/098af61bbe04 PWA是Progressive Web App的英文缩写， 翻译过来就是渐进式增强WEB应用， 是Google 在2016年提出的概念，2017年落地的web技术。目的就是在移动端利用提供的标准化框架，在网页应用中实现和原生应用相近的用户体验的渐进式网页应用。 简单来说，如果你的项目，打算包装成一个APP，你可能需要这个技术。 Router 官方：https://router.vuejs.org/zh/ Vue Router 是 Vue.js 官方的路由管理器。它和 Vue.js 的核心深度集成，让构建单页面应用变得易如反掌。包含的功能有： 嵌套的路由/视图表 模块化的、基于组件的路由配置 路由参数、查询、通配符 基于 Vue.js 过渡系统的视图过渡效果 细粒度的导航控制 带有自动激活的 CSS class 的链接 HTML5 历史模式或 hash 模式，在 IE9 中自动降级 自定义的滚动条行为 这个比较基础了，我们肯定需要勾选的。 Vuex每一个 Vuex 应用的核心就是 store（仓库）。“store”基本上就是一个容器，它包含着你的应用中大部分的**状态 (state)**。Vuex 和单纯的全局对象有以下两点不同： Vuex 的状态存储是响应式的。当 Vue 组件从 store 中读取状态的时候，若 store 中的状态发生变化，那么相应的组件也会相应地得到高效更新。 你不能直接改变 store 中的状态。改变 store 中的状态的唯一途径就是显式地提交 (commit) mutation。这样使得我们可以方便地跟踪每一个状态的变化，从而让我们能够实现一些工具帮助我们更好地了解我们的应用。 我们需要对用户的权限进行区别的话，在全局范围内进行标识，那么肯定需要用的到Vuex。 Css Pre-processorsCss预处理，我们常用的就是，三个 CSS 预处理器：Sass、LESS 和 Stylus CSS预处理器定义了一种新的语言，基本的思想是用一种专门的编程语言，开发者只需要使用这种语言进行编码工作，减少枯燥无味的CSS代码的编写过程的同时，它能让你的CSS具备更加简洁、适应性更强、可读性更加、层级关系更加明显、更易于代码的维护等诸多好处。 Linter / Formatter我们一般使用ESLint来进行代码规范的设置 Testing选择测试方式 选择Unit测试方式 选择E2E测试方式 这两者有什么区别呢？ 前端实现自动化就要借助到unit和e2e端到端[测试]了(javascript:;) 一.unit测试 站在程序员的角度测试 unit测试是把代码看成是一个个的组件。从而实现每一个组件的单独测试，测试内容主要是组件内每一个函数的返回结果是不是和期望值一样。 例如： 而代码覆盖率是指代码中每一个函数的每一中情况的测试情况，上述测试的代码覆盖率是100% 这样代码覆盖率是50%，因为else情况没有测试到 二.e2e测试 站在用户角度的测试 e2e测试是把我们的程序堪称是一个黑盒子，我不懂你内部是怎么实现的，我只负责打开浏览器，把测试内容在页面上输入一遍，看是不是我想要得到的结果。 两者的存在都是很有意义的。 unit测试是程序员写好自己的逻辑后可以很容易的测试自己的逻辑返回的是不是都正确。 e2e代码是测试所有的需求是不是都可以正确的完成，而且最终要的是在代码重构，js改动很多之后，需要对需求进行测试的时候测试代码是不需要改变的，你也不用担心在重构后不能达到客户的需求。 第二步 提示我们“Use class-style component syntax”，那么这是是否使用class风格的组件语法 是否使用babel做转义，我们选择是 官方：https://router.vuejs.org/zh/guide/essentials/history-mode.html vue-router` 默认 hash 模式 —— 使用 URL 的 hash 来模拟一个完整的 URL，于是当 URL 改变时，页面不会重新加载。 vue-route有两种模式：history模式和hash模式。 hash模式（vue-router默认hash模式）hash模式背后的原理是onhashchange事件。 1234window.onhashchange=function()&#123; let hash=location.hash.slice(1); document.body.style.color=hash;&#125; （localtion是js里管理地址栏的内置对象，是window对象的一部分，可通过window.localtion访问，在w3cshool里的详细介绍)由于hash发生变化的url都会被浏览器记录下来，使得浏览器的前进后退都可以使用了，尽管浏览器没有亲求服务器，但是页面状态和url关联起来。后来人们称其为前端路由，成为单页应用标配。 比如http://www.abc.com/#/index，hash值为#/index。hash模式的特点在于hash出现在url中，但是不会被包括在HTTP请求中，对后端没有影响，不会重新加载页面。 history模式history模式利用了HTML5 History Interface中新增的pushState()和replaceState()方法。MDN相关介绍（需要特定浏览器支持）。这两个方法应用于浏览器的历史记录栈，提供了对历史记录进行修改的功能。只是当他们进行修改时，虽然修改了url，但浏览器不会立即向后端发送请求。当使用history模式时，url就像正常的url,例如http://abc.com/user/id相比hash模式更加好看。特别注意，history模式需要后台配置支持。如果后台没有正确配置，访问时会返回404。通过history api，我们丢弃了丑陋的#，但是有一个缺点，当刷新时，如果服务器中没有相应的相应或者资源，会分分钟刷出一个404来（刷新需要请求服务器）。所以history模式不怕前进，不怕后退，就怕刷新。 hash模式和history模式对比pushState()设置新的url可以是和当前url同源的任意url;hash只可修改#后面的部分，只能设置当前url同文档的url。pushState()设置的新url可与当前url一致，这样也会把记录添加到栈中；hash必须设置与当前url不同的url的，才会触发动作将记录添加到栈中。pushState()通过stateObject参数可以添加任意类型的数据到记录中；hash只可添加短字符串。pushState()可额外设置title属性供后续使用。不过，hash模式也有比history模式优势的地方。 hash模式下，仅hash符号之前的url会被包含在请求中，后端如果没有做到对路由的全覆盖，也不会返回404错误。history模式下，前端的url必须和实际向后端发起请求的url一致，如http://abc.com/user/id,后端如果没有对user/id的路由处理，将返回404错误。history模式官方文档4.应用场景对于一般的Vue+Vue-router+Webpack+XXX形式1的Web开发场景，用history模式即可，后端用Apach或Nginx进行路由的简单配置，同时搭配前端路由的404页面支持。上述区别来自于E_li_na 如果不想要很丑的 hash，我们可以用路由的 history 模式，这种模式充分利用 history.pushState API 来完成 URL 跳转而无须重新加载页面。 据说Sass推荐使用dart-sass，最新的更新会放在这个里面，但是使用node-sass的也很多。 询问项目的什么时候校验格式(1是保存时，2是提交时)。 询问项目的测试框架，我就是用Jest了，因为我做测试不多，也不是很了解。 选择E2E的测试方式，注意第一个只能在Chrome上进行 询问项目的配置文件存放在哪儿（1是独立文件，2是在package.json）这里选择独立的文件，选择2在后续配置postcs适配时存在问题。 随后回车我们进行项目的构建","categories":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"}],"tags":[{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"}]},{"title":"JMeter介绍及使用","slug":"JMeter的介绍和具体用法","date":"2019-05-20T11:04:35.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/20/JMeter的介绍和具体用法/","link":"","permalink":"http://www.octber.xyz/2019/05/20/JMeter%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%85%B7%E4%BD%93%E7%94%A8%E6%B3%95/","excerpt":"什么是JMeterApache JMeter是Apache组织开放源代码的项目，是一个纯Java的桌面应用，用于压力测试和性能测试，他最初被设计用于web应用测试，但后来扩展到其他测试领域，用于分析不同压力条件下的总体性能情况。","text":"什么是JMeterApache JMeter是Apache组织开放源代码的项目，是一个纯Java的桌面应用，用于压力测试和性能测试，他最初被设计用于web应用测试，但后来扩展到其他测试领域，用于分析不同压力条件下的总体性能情况。 获取JMeter JDK &gt; 1.8 官方下载 首先设置语言为中文 options-&gt;select language-&gt;Chinese JMeter目录 bin：可执行文件 jmeter.bat是windows的启动文件 jmeter.log是日志文件 jmeter.sh是Linux的启动文件 jmeter.propertis是配置文件 jmeter-server.bat是windows分布式测试要用到的服务器配置 jmeter-serve是linux分布式测试要用到的服务器配置 docs：接口文档目录 extras：拓展插件目录 lib：所用到的插件目录，里面全是jar包，jmeter会自动在JMETER_HOME/lib和ext目录下寻找需要的类。 Licenses：jmeter的证书目录 printable_docs：用户使用手册 JMeter工具组成部分 资源生成器：用于生成测试过程中服务器，负载机的资源代码 用户运行器：通常是一个脚本运行引擎，根据脚本要求模拟指定用户行为 报表生成器：根据测试中实时的数据生成报表，提供可视化数据显示 负载发生器：用于产生负载，通常以多线程或是多进程的方式模拟用户行为 Test Plan 测试计划用来描述一个性能测试，包含与本次性能测试所有相关的功能。也就是说性能测试的所有内容是基于一个计划的。 Threads（Users）线程 用户 Test Plan-&gt;添加-&gt;线程（用户）-&gt;setUp线程组 setup thread group一种特殊类型的ThreadGroup，可用于执行预测试操作，这些线程的行为完全想一个正常的线程组远见。不同的是，这些类型的线程执行测试前进行定期线程组的执行，类似init()的功能。 Test Plan-&gt;添加-&gt;线程（用户）-&gt;tearDown线程组 tearDown thread group一种特殊类型的ThreadGroup，可用于执行测试后动作，类似于end() Test Plan-&gt;添加-&gt;线程（用户）-&gt;线程组 thread group这个就是我们通常添加运行的线程，可以看做一个虚拟用户组，线程组中的每一个线程都可以理解为一个虚拟用户，线程组中包含的线程数量在测试执行过程中是不会发生改变的，类似action() 添加线程组后的界面： 测试片段 Test Fragment Test Plan-&gt;添加-&gt;测试片段-&gt;测试片段 测试片段元素是控制器上的一个特殊的线程组，他与线程组的不同的是他不被执行，除非他是一个木块控制器或者是被控制器被引用才会执行 配置元件 Config Element Test Plan-&gt;添加-&gt;配置元件 用于提供对静态数据配置的支持，如CSV Data Set Config 可以将本地数据文件形成数据池Data Pool 定时器 Timer Test Plan-&gt;添加-&gt;定时器 定时器用于操作之间设置等待时间，等待时间是性能测试中常用的控制客户端QPS的手段，类似于“思考时间”，比如我们设置在1000个线程没有启动完之前不进行操作等。 前置处理器 Per Processors Test Plan-&gt;添加-&gt;前置处理器 用于在实际的请求发出之前对即将发出的请求进行特殊处理。比如对HTTP URL重写修复符这可以实现URL重写。 后置处理器 Post Processors Test Plan-&gt;添加-&gt;后置处理器 用于对发出请求后得到的响应数据进行处理，一般用来提取相应中的特定数据。 断言 Assertions Test Plan-&gt;添加-&gt;断言 断言用于检查测试中得到的响应数据是否符合预期，一般用来设置检查点，用以保证性能测试过程中的数据交互是否与预期一致。 监听器 Listener Test Plan-&gt;添加-&gt;监听器 是用来对测试结果数据进行处理和可视化展示的一系列元件。比如图形结果，查看结果树，聚合报告等。 取样器 Sample 线程组-&gt;添加-&gt;取样器 性能测试中向服务器发送请求，记录响应信息，记录响应时间的最小单元，JMeter原生支持多种不同的sampler，如HTTP Request Sampler，FTP，TCP，JDBC等。 逻辑控制器 线程组-&gt;添加-&gt;逻辑控制器 控制test plan中sampler节点发送请求的逻辑顺序的控制器，常用的有if控制器，switch controller等控制器 还有一类，用于控制sampler来节点的，如事务控制器，吞吐量控制器 Jmeter脚本录制使用BadBoy录制官方下载地址： http://www.badboy.com.au/download/ BadBoy是什么？他是一个强大的工具，旨在帮助测试和开发复杂的动态应用。 我们可以方便的开始录制，输入url地址，回车访问，就开始录制你所有的动作。 使用我们可以在file-&gt;export为jmeter的格式（.jmx），随后jmeter导入进来，就可以看到之前操作的所有step。并且可以进行相应的回放。 BadBoy 检查点与参数化检查点（断言）设置选择要检查的文字，然后再Tools-&gt;step1里添加断言，再回放 Tools-&gt;Add Assertion for Selection 添加断言，会生成一个check for XXX 录制问题在录制过程中如果报这个错误： 其实这不是什么问题，并不影响录制，如果想要关闭这个，我们可以找到对应的浏览器，进入Internet配置中在高级中选上下面的两个属性即可 录制界面 导入JMeter 我们可以看到我们录制操作时候的step完全呈现在了Jmeter中 参数化","categories":[{"name":"软件测试","slug":"软件测试","permalink":"http://www.octber.xyz/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"JMeter","slug":"JMeter","permalink":"http://www.octber.xyz/tags/JMeter/"}]},{"title":"Hexo插件使用","slug":"Hexo插件使用","date":"2019-05-19T12:46:08.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/19/Hexo插件使用/","link":"","permalink":"http://www.octber.xyz/2019/05/19/Hexo%E6%8F%92%E4%BB%B6%E4%BD%BF%E7%94%A8/","excerpt":"前言想优雅的使用Hexo这个博客还是很不容易的，需要学会使用一些插件，而有的插件之间有一定的冲突，我们需要进行一些修改，才能完美的适配我们的博客。","text":"前言想优雅的使用Hexo这个博客还是很不容易的，需要学会使用一些插件，而有的插件之间有一定的冲突，我们需要进行一些修改，才能完美的适配我们的博客。 hexo-abbrlink原生的Hexo博客生成的目录是:year/:month/:day/:title，这就使得我们的url中携带大量中文，有些人通过hexo new title使用英文的title，这当然可行的，但是这不代表你的title就一定是唯一确定的，这也不方便日后对文章进行整理，也不方便我们推广，比如推广到百度站上，进行SEO是非常不方便的。 而这一款插件就可以为我们的文章生一个固定不变而且唯一的地址，就算你修改文章的title，也不会对url发生变化的插件。 我们只需要npm install hexo-abbrlink --save即可 随后在我们的主配置文件中进行相应的配置： 1234permalink: :year/:month/:day/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 在使用了这个插件后，需要执行一次hexo clean &amp;&amp; hexo g，否则之前的博文可能会变为undefined，需要先clean一下。 hexo-asset-image这一款插件是为我们为文章中插入图片提供方便的，我们需要在配置文件中启用： 1post_asset_folder: true 安装方法是一样的: 1npm install --save hexo-asset-image 安装好后当我们新建博文的时候，就会为我们在同级目录下生成一个名字为title的文件夹，存放在这个文件夹里面的图片，在我们部署后可以顺利显示。 hexo-generator-index-pin-top如果你想置顶某一篇博文的话，就用的上这个插件了，安装方式不说了，直接说怎么用： 最后在适当的地方，比如说我是在aiticles的标题处加上了置顶的代码： 12345&lt;% if (post.top) &#123; %&gt;&lt;i class=&quot;fa fa-thumb-tack&quot;&gt;&lt;/i&gt;&lt;font color=7D26CD&gt;置顶&lt;/font&gt;&lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&lt;% &#125; %&gt; 最终效果： hexo-wordcount这是用于统计文章字数和阅读市场的插件，因为icarus已经有了这样的功能，所以我只提一下， 配置可以这样： 1234post_wordcount: item_text: true wordcount: true min2read: true hexo-baidu-url-submit有一位大神写的特别好，我就看他配置的妥妥的，不说了，传送门： Hexo插件之百度主动提交链接 hexo-blog-encrypt文章加密的插件，非常好用，也非常简单： 以下内容来自官方文档： 具体的使用方法首先，你需要在 _config.yml 中启用该插件1234# Security##encrypt: enable: true 给文章添加密码：12345678910---title: hello worlddate: 2016-03-30 21:18:02tags: - fdsfadsfa - fdsafsdafpassword: Mikeabstract: Welcome to my blog, enter password to read.message: Welcome to my blog, enter password to read.--- password: 是该博客加密使用的密码 abstract: 是该博客的摘要，会显示在博客的列表页 message: 这个是博客查看时，密码输入框上面的描述性文字 对 TOC 进行加密如果你有一篇文章使用了 TOC，你需要修改模板的部分代码。这里用 landscape 作为例子： 你可以在 hexo/themes/landscape/layout/_partial/article.ejs 找到 article.ejs。 然后找到 &lt;% post.content %&gt; 这段代码，通常在30行左右。 使用如下的代码来替代它: 1234567891011&lt;% if(post.toc &#x3D;&#x3D; true)&#123; %&gt; &lt;div id&#x3D;&quot;toc-div&quot; class&#x3D;&quot;toc-article&quot; &lt;% if (post.encrypt &#x3D;&#x3D; true) &#123; %&gt;style&#x3D;&quot;display:none&quot; &lt;% &#125; %&gt;&gt; &lt;strong class&#x3D;&quot;toc-title&quot;&gt;Index&lt;&#x2F;strong&gt; &lt;% if (post.encrypt &#x3D;&#x3D; true) &#123; %&gt; &lt;%- toc(post.origin, &#123;list_number: true&#125;) %&gt; &lt;% &#125; else &#123; %&gt; &lt;%- toc(post.content, &#123;list_number: true&#125;) %&gt; &lt;% &#125; %&gt; &lt;&#x2F;div&gt;&lt;% &#125; %&gt;&lt;%- post.content %&gt; 修改加密模板 如果你对默认的主题不满意，或者希望修改默认的提示和摘要内容，你可以添加如下配置在 _config.yml 中。 1234567891011121314151617181920# Security##encrypt: enable: true default_abstract: the content has been encrypted, enter the password to read.&lt;&#x2F;br&gt; default_message: Please enter the password to read. default_template: &lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdnjs.cloudflare.com&#x2F;ajax&#x2F;libs&#x2F;jquery&#x2F;3.3.1&#x2F;jquery.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;div id&#x3D;&quot;hbe-security&quot;&gt; &lt;div class&#x3D;&quot;hbe-input-container&quot;&gt; &lt;input type&#x3D;&quot;password&quot; class&#x3D;&quot;hbe-form-control&quot; id&#x3D;&quot;pass&quot; placeholder&#x3D;&quot;&#123;&#123;message&#125;&#125;&quot; &#x2F;&gt; &lt;label for&#x3D;&quot;pass&quot;&gt;&#123;&#123;message&#125;&#125;&lt;&#x2F;label&gt; &lt;div class&#x3D;&quot;bottom-line&quot;&gt;&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;&quot;decryptionError&quot; style&#x3D;&quot;display:none;&quot;&gt;&#123;&#123;decryptionError&#125;&#125;&lt;&#x2F;div&gt; &lt;div id&#x3D;&quot;noContentError&quot; style&#x3D;&quot;display:none;&quot;&gt;&#123;&#123;noContentError&#125;&#125;&lt;&#x2F;div&gt; &lt;div id&#x3D;&quot;encrypt-blog&quot; style&#x3D;&quot;display:none&quot;&gt; &#123;&#123;content&#125;&#125; &lt;&#x2F;div&gt; 可以看见，和上面的配置文件对比来看，多了 default_template 和 default_abstract 和 default_message 配置项。 default_abstract : 这个是指在文章列表页，我们看到的加密文章描述。当然这是对所有加密文章生效的。 default_message : 这个在文章详情页的密码输入框上方的描述性文字。 default_template : 这个是指在文章详情页，我们看到的输入密码阅读的模板，同理，这个也是针对所有文章的 开始的解密部分需要由 div 包裹，而且 div 的 id 必须 是 ‘hbe-security’，解密后以便于隐藏。 最后的 content 显示 div 的 id 必须 是 ‘encrypt-blog’，同时为了好看，也希望进行隐藏。 同时，必须要有一个 input 输入框，id 必须是”pass”，用来供用户输入密码。 输入密码之后，务必要有一个触发器，用来调用 ‘decryptAES’ 函数。样例中以 button 来触发。 如果你希望对某一篇特定的文章做特殊处理，这有两种方法可以达到这个效果, 在博客的源文件添加 template 配置: 123456789101112131415161718192021222324---title: hello worlddate: 2016-03-30 21:18:02tags: - fdsfadsfa - fdsafsdafpassword: Mikeabstract: Welcome to my blog, enter password to read.message: Welcome to my blog, enter password to read.template: &lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdnjs.cloudflare.com&#x2F;ajax&#x2F;libs&#x2F;jquery&#x2F;3.3.1&#x2F;jquery.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;div id&#x3D;&quot;hbe-security&quot;&gt; &lt;div class&#x3D;&quot;hbe-input-container&quot;&gt; &lt;input type&#x3D;&quot;password&quot; class&#x3D;&quot;hbe-form-control&quot; id&#x3D;&quot;pass&quot; placeholder&#x3D;&quot;&#123;&#123;message&#125;&#125;&quot; &#x2F;&gt; &lt;label for&#x3D;&quot;pass&quot;&gt;&#123;&#123;message&#125;&#125;&lt;&#x2F;label&gt; &lt;div class&#x3D;&quot;bottom-line&quot;&gt;&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;&quot;decryptionError&quot; style&#x3D;&quot;display:none;&quot;&gt;&#123;&#123;decryptionError&#125;&#125;&lt;&#x2F;div&gt; &lt;div id&#x3D;&quot;noContentError&quot; style&#x3D;&quot;display:none;&quot;&gt;&#123;&#123;noContentError&#125;&#125;&lt;&#x2F;div&gt; &lt;div id&#x3D;&quot;encrypt-blog&quot; style&#x3D;&quot;display:none&quot;&gt; &#123;&#123;content&#125;&#125; &lt;&#x2F;div&gt;--- 回调如果您需要在文章解密之后调用一些代码，您可以参考以下配置： 123456encrypt: enable: true callback: |- initLightGallery() initImageResize() initTocBot() 在callback 之后的这个符号|-代表多行的yaml值 如果您在其他js文件里面定义了函数，您可以在这里调用它们，或者您也可以在callback这里写上您自己的代码逻辑，比如$(&#39;#someId&#39;).lightGallery()，上面的initXXX()只是示例，您不应该直接复制上面的配置。 卜算子ip计数统计这个很简单，只需要加几行代码，不过我发现每次在打开网站时候都会卡这么一下，和这个貌似有关系，emmmm，所以我不是很喜欢这个。 传送门：卜算子教程 leancloud-storage这个比较麻烦，是添加comment评论的：Valine评论 请移步查看官方文档：http://www.zhaojun.im/hexo-valine-admin/ 效果就是这样的： 好看是挺好看，不过没人评论就很尴尬emmm。。。 hexo-abbrlink和hexo-asset-image冲突怎么办在这两个同时使用的时候，图片会因为图片路由包含了文章名而无法显示，这就很难受，通通过修改/node_modules/hexo-asset-image/index.js修改了路由获取方式，成功显示了图片，因为修改的是依赖文件，所以当你删除了/node_modules或者你还了电脑重新拉了项目进行npm install的时候，这部分代码就没有了，记得备份好，那么我修改的内容是： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&#x27;use strict&#x27;;var cheerio = require(&#x27;cheerio&#x27;);// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) &#123; return str.split(m, i).join(m).length;&#125;hexo.extend.filter.register(&#x27;after_post_render&#x27;, function(data)&#123; var config = hexo.config; if(config.post_asset_folder)&#123; var link = data.permalink; // 第一处改动 link = link.replace(&#x27;.html&#x27;, &#x27;/&#x27;); var beginPos = getPosition(link, &#x27;/&#x27;, 3) + 1; // In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;. var endPos = link.lastIndexOf(&#x27;/&#x27;) + 1; link = link.substring(beginPos, endPos); var toprocess = [&#x27;excerpt&#x27;, &#x27;more&#x27;, &#x27;content&#x27;]; for(var i = 0; i &lt; toprocess.length; i++)&#123; var key = toprocess[i]; var $ = cheerio.load(data[key], &#123; ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false &#125;); $(&#x27;img&#x27;).each(function()&#123; // For windows style path, we replace &#x27;\\&#x27; to &#x27;/&#x27;. var src = $(this).attr(&#x27;src&#x27;).replace(&#x27;\\\\&#x27;, &#x27;/&#x27;); if(!/http[s]*.*|\\/\\/.*/.test(src))&#123; // For &quot;about&quot; page, the first part of &quot;src&quot; can&#x27;t be removed. // In addition, to support multi-level local directory. var linkArray = link.split(&#x27;/&#x27;).filter(function(elem)&#123; return elem != &#x27;&#x27;; &#125;); var srcArray = src.split(&#x27;/&#x27;).filter(function(elem)&#123; return elem != &#x27;&#x27;; &#125;); if(linkArray[linkArray.length - 1] == srcArray[0]) &#123; srcArray.shift(); &#125; // 第二处改动 srcArray.shift(); src = srcArray.join(&#x27;/&#x27;); $(this).attr(&#x27;src&#x27;, &#x27;/&#x27; + link + src); &#125; &#125;); data[key] = $.html(); &#125; &#125;&#125;); 一共两处修改，第一处是将路由中的.html变为/，这是因为我在设置文章访问路由的时候设置为了permalink: :year/:month/:day/:abbrlink.html，所以要去掉html换为/，气候添加了一个srcArray.shift()这个的作用是删除数组中的第一个元素，删除的正是中文标题的名字，这一层目录是多余的。 如果你存在问题，请在下面评论，或者联系我的邮箱：&#57;&#50;&#53;&#52;&#x37;&#x34;&#48;&#x38;&#56;&#x40;&#113;&#x71;&#x2e;&#x63;&#x6f;&#109;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"}]},{"title":"将Hexo部署在CentOs服务器上","slug":"将Hexo部署在CentOs服务器上","date":"2019-05-18T14:26:54.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/18/将Hexo部署在CentOs服务器上/","link":"","permalink":"http://www.octber.xyz/2019/05/18/%E5%B0%86Hexo%E9%83%A8%E7%BD%B2%E5%9C%A8CentOs%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A/","excerpt":"前言将Hexo部署在CentOs服务器上，之后写。","text":"前言将Hexo部署在CentOs服务器上，之后写。","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"}]},{"title":"配置CentOs的git以及部署SSH公钥","slug":"配置CentOs的git以及部署SSH公钥","date":"2019-05-18T12:41:15.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/18/配置CentOs的git以及部署SSH公钥/","link":"","permalink":"http://www.octber.xyz/2019/05/18/%E9%85%8D%E7%BD%AECentOs%E7%9A%84git%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2SSH%E5%85%AC%E9%92%A5/","excerpt":"前言在自己的服务器上部署Git服务器，是一件非常重要的事情，当你有项目需要自动部署到服务器上的时候，在服务器上建立仓库，一键push上去，而不是手动打包文件夹复制咱去，这是一个非常便捷的过程，本节内容服务于“如何将Hexo上传到服务器上并实现自动部署”。","text":"前言在自己的服务器上部署Git服务器，是一件非常重要的事情，当你有项目需要自动部署到服务器上的时候，在服务器上建立仓库，一键push上去，而不是手动打包文件夹复制咱去，这是一个非常便捷的过程，本节内容服务于“如何将Hexo上传到服务器上并实现自动部署”。 服务器环境我使用的是CentOs 7.X版本 64位，6.X版本已经放弃维护，不建议大家使用。 因为CentOs已经内置了OpenSSH，如果你的系统没有，需要自行下载，查看ssh的版本的方式是ssh -V，请注意，在linux中大小写是敏感的，如果你的V小写，是不能正确得出结果的。下面是我的输出结果： 课件我已经有了OpenSSL环境。 安装Git首先我要说的是Git，Github，GitLab的区别，并不是所有人都知道这个区别的。 Git：是一个版本控制系统，版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。有了版本控制系统，就可以不用担心文件丢失，不小心误修改文件等等“事故”，而且你可以随便回到历史记录的某个时刻。 SVN, CVS这类早期的集中式版本控制系统，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 为什么选用分布式版本控制系统？ 我们现在使用的大多都是像Git这样的分布式版本控制系统，因为客户端并不只是获取最新的版本文件，而是吧代码仓库完整的镜像下来。一旦服务器发生故障，事后可以使用任何一个镜像出来的本地仓库进行回复，因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。 记住一个人 Linus Torvalds，他不当开创了Linux操作系统，还开发了Git，而现在的Android底层就是基于更改过的Linux系统。这是他的github地址：https://github.com/torvalds 上面有Linux的源码！你难道不感兴趣？ GitHub：这个大家就更熟悉了，他是在线的基于Git的打码托管服务，大家几乎每天都在用。 Gitlab：很多人把这个和GitHub混为一谈，难以区分，其实很简单，首先他们都是基于Web的版本控制界面，服务于互联网，github可以直接注册使用，二gitlab需要部署到服务器，一个是别人的，一个是自己的。 讲了这么多，我们可以开始安装Git了。 1yum install -y git 如此简单，验证是否安装成功，我们只需要输入 1git --version 这是我实际操作的截图 既然是版本控制，那么就涉及谁去进行这个控制，我们就需要设置专门管理git的账号。 12345678910# 添加git账户adduser git# 修改git的密码passwd git# 需要根据提示输入两次# 查看是否安装成功cd /homels -al 我的效果图： git的权限管理这就是我们重点要讲的，因为我是个人开发，我在一个小的外包公司做开发的时候，由于团队不大，使用的也都是SSH公钥进行管理，但是如果大一点的团队，就建议使用gitolite或者gitosis进行管理，一个是Perl开发，一个是Python开发，这里就不赘述了，因为我们用到的是SSH公钥部署。 我们进行一下操作： 12345678910111213# 进入到git账户的主目录cd /home/git# 创建.ssh目录，当然如果你已经有了，当我没说mkdir .sshcd .ssh# 创建权限keys文件touch authorized_keys# 5. 设置权限，此步骤不能省略，而且权限值也不要改，不然会报错。$ chmod 700 /home/git/.ssh/$ chmod 600 /home/git/.ssh/authorized_keys 随后我们需要把本地的id_rsa.pub文件的内容复制到authorized_keys，如何生成本地SSH秘钥我已经介绍过了，在我之前的博客，关于Hexo如何部署到Github Pages的内容中建国，可以参考。 文件传输到服务器上后如何复制内容到权限keys文件中可以参考命令： cat id_rsa.pub &gt;&gt; authorized_keys 我们在本地使用ssh git@服务器地址的方式就可以使用git账号登录服务器，当然这并不安全。 允许使用这种方式登录服务器这很不安全，一定要关闭，这一点我之后会讲 创建Git仓库如果我们要创建一个git仓库那么很简单，使用–bare表示创建一个裸仓库，工作区没有文件。 1git init --bare 本地就可以通过一下方式进行clone等操作 1git cline git@服务器地址ip 禁止客户端shell登录修改/etc/passwd文件 1vim /etc/passwd 找到这句话： 123456git:x:1000:1000::/home/git:/bin/bash# 改成git:x:1000:1000::/home/git:/bin/git-shell# ! :wq 即可 为什么不直接用GitLab没说不可以，而且很好，不过建议2G一下内存的服务器不要使用，博主我就是因为穷买不起好的服务器，所以才这样过的。 疯狂暗示打赏？？","categories":[{"name":"环境部署","slug":"环境部署","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://www.octber.xyz/tags/Git/"}]},{"title":"CentOs下配置node.js全局环境","slug":"CentOs下配置node-js全局环境","date":"2019-05-18T12:21:15.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/18/CentOs下配置node-js全局环境/","link":"","permalink":"http://www.octber.xyz/2019/05/18/CentOs%E4%B8%8B%E9%85%8D%E7%BD%AEnode-js%E5%85%A8%E5%B1%80%E7%8E%AF%E5%A2%83/","excerpt":"前言之后填坑： 参考博文： https://www.cnblogs.com/wandiao/p/7237231.html https://www.cnblogs.com/baby123/p/6955396.html","text":"前言之后填坑： 参考博文： https://www.cnblogs.com/wandiao/p/7237231.html https://www.cnblogs.com/baby123/p/6955396.html","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://www.octber.xyz/tags/node-js/"}]},{"title":"CentOS配置MySQL填坑-Linux防火墙和外部访问","slug":"CentOS配置MySQL填坑-Linux防火墙和外部访问","date":"2019-05-18T10:48:44.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/18/CentOS配置MySQL填坑-Linux防火墙和外部访问/","link":"","permalink":"http://www.octber.xyz/2019/05/18/CentOS%E9%85%8D%E7%BD%AEMySQL%E5%A1%AB%E5%9D%91-Linux%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8C%E5%A4%96%E9%83%A8%E8%AE%BF%E9%97%AE/","excerpt":"前言在拥有个人服务器后，非常重要的一件事就是部署自己的MySQL，我选用了MySQL5.7的版本，相比MySQL5.5及以下版本，5.7使用Innodb数据库存储引擎，增添了事务的机制，这两者非常重要。安装MySQL可以通过两种方式，一种使用yum源，或者使用Docker安装MySQL容器，这两者我都使用过，不过这次我使用了宝塔Linux面板虽然无脑安装，但是省事不少。","text":"前言在拥有个人服务器后，非常重要的一件事就是部署自己的MySQL，我选用了MySQL5.7的版本，相比MySQL5.5及以下版本，5.7使用Innodb数据库存储引擎，增添了事务的机制，这两者非常重要。安装MySQL可以通过两种方式，一种使用yum源，或者使用Docker安装MySQL容器，这两者我都使用过，不过这次我使用了宝塔Linux面板虽然无脑安装，但是省事不少。 MySQL填坑安装好外部无法访问？我之前一直以为是没有grant相关权限给root，root只有localhost的权限，也就是只有本机才能访问，但是我在本机赋予权限后，发现在我自己的电脑上海市访问不到，这就很难受。当然grant权限是必要的步骤，但是还有一个非常重要的操作。 设置Linux防火墙我们需要对3306端口进行设置： 防火墙设置 1service iptables status 结果： 显然，提示我们iptables.service不存在，CentOS7默认的防火墙不是iptables，而是firewalle ######停止firewalld服务 1systemctl stop firewalld 结果： 没有提示错误就是对咯，我们继续 ######禁用firewalld服务 1systemctl mask firewalld 你可能会好气，停止后为什么还要禁用，有什么意义？ 注销服务意味着： 该服务在系统重启的时候不会启动 该服务无法进行做systemctl start/stop操作 该服务无法进行systemctl enable/disable操作 结果： 如果我们要开启的话，开启命令为： 1systemctl unmask firewalld 执行结果为： 随后我们就需要安装iptables-services 1yum install iptables-services 结果为： 期间需要输入一个y即可，表示yes！ 设置开机启动 1systemctl enable iptables 结果为： 然后查看状态 1service iptables status iptables：未运行防火墙。 我们可以看到，并未启动。开启防火墙 1service iptables start 我们现在需要，关闭防火墙，来开放端口： 1service iptables stop Linux 防火墙开放3306端口 开放端口命令： 1/sbin/iptables -I INPUT -p tcp --dport 3306 -j ACCEPT 到此我们就结束了本次操作 设置MySQL的Root权限在本地进入MySQL： 1mysql -h localhost -u root -p 随后输入密码进入，结果： 输入赋予权限的代码即可 1GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;password&#x27; WITH GRANT OPTION; 这句话意思很简单，赋予root所有权限到*.*也就是所有访问，而不是localhost，通过一个password验证就可以登录。 显示Query OK, 0 rows affected, 1 warning (0.01 sec)大功告成 这样我们的MySQL就算完全部署好了。我们在自己的电脑上连接成功： 转载一篇优秀的博文转自：http://blog.csdn.net/huxu981598436/article/details/54864260 开启端口命令输入firewall-cmd –query-port=6379/tcp，如果返回结果为no，那么证明6379端口确实没有开启。 输入firewall-cmd –add-port=6379/tcp，将6379端口开启，返回success。 1、firewalld的基本使用解除屏蔽 （mask）systemctl unmask firewalld.service 启动： systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl –failed 3.配置firewalld-cmd查看版本： firewall-cmd –version 查看帮助： firewall-cmd –help 显示状态： firewall-cmd –state 查看所有打开的端口： firewall-cmd –zone=public –list-ports 更新防火墙规则： firewall-cmd –reload 查看区域信息: firewall-cmd –get-active-zones 查看指定接口所属区域： firewall-cmd –get-zone-of-interface=eth0 拒绝所有包：firewall-cmd –panic-on 取消拒绝状态： firewall-cmd –panic-off 查看是否拒绝： firewall-cmd –query-panic 那怎么开启一个端口呢 添加firewall-cmd –zone=public –add-port=80/tcp –permanent （–permanent永久生效，没有此参数重启后失效） 重新载入firewall-cmd –reload 查看80/tcp 删除 firewall-cmd –zone= public –remove-port=80/tcp –permanent ====================================================== iptables是linux下的防火墙，同时也是服务名称。 service iptables status 查看防火墙状态 service iptables start 开启防火墙 service iptables stop 关闭防火墙 service iptables restart 重启防火墙 防火墙开放特定端口： ①文件/etc/sysconfig/iptables ②添加： -A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT ★数字8080代表开放8080端口，也可以改成其他的端口★ ③重启防火墙保存对防火墙的设置 serivce iptables save 查看iptables规则及编号 iptables -nL –line-number 关闭所有的INPUT FORWARD（转发） OUTPUT的所有端口 iptables -P INPUT DROP iptables -P FORWARD DROP iptables -P OUTPUT DROP 只打开22端口 iptables -A INPUT -p tcp –dport 22 -j ACCEPT iptables -A OUTPUT -p tcp –sport 22 -j ACCEPT 参数讲解：–A 参数就看成是添加一条规则 –p 指定是什么协议，我们常用的tcp 协议，当然也有udp，例如53端口的DNS –dport 就是目标端口，当数据从外部进入服务器为目标端口 –sport 数据从服务器出去，则为数据源端口使用 –j 就是指定是 ACCEPT -接收 或者 DROP 不接收 禁止某个IP访问iptables -A INPUT -p tcp -s 192.168.1.2 -j DROP –s 参数是来源（即192.168.1.2） 后面拒绝就是DROP 删除规则iptables -D INPUT 2 删除INPUT链编号为2的规则 题外话服务器使用两年了，MySQL的部署也搞过很多次，其实建议大家使用Docker进行部署，是最好的，之前的博客使用wordpress也记录过，可惜由于数据库没有备份好，丢失了数据，现在再一次进行记录。","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.octber.xyz/tags/MySQL/"}]},{"title":"变量命名小工具","slug":"变量命名小工具","date":"2019-05-18T05:15:50.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/18/变量命名小工具/","link":"","permalink":"http://www.octber.xyz/2019/05/18/%E5%8F%98%E9%87%8F%E5%91%BD%E5%90%8D%E5%B0%8F%E5%B7%A5%E5%85%B7/","excerpt":"前言我们在日常生活中经常遇到变量名不知道怎么起的情况，中国的程序员日常准备一个有道词典也是很正常的事情，大神就另当别论了，尤其是遇到同样的意思需要多个变量的时候","text":"前言我们在日常生活中经常遇到变量名不知道怎么起的情况，中国的程序员日常准备一个有道词典也是很正常的事情，大神就另当别论了，尤其是遇到同样的意思需要多个变量的时候 CODELF这是一个神奇的网站，不多说了，传送门：https://unbug.github.io/codelf/","categories":[{"name":"工具集","slug":"工具集","permalink":"http://www.octber.xyz/categories/%E5%B7%A5%E5%85%B7%E9%9B%86/"}],"tags":[{"name":"Utils","slug":"Utils","permalink":"http://www.octber.xyz/tags/Utils/"}]},{"title":"Hexo主题-Icarus主题","slug":"Hexo主题-Icarus主题","date":"2019-05-18T00:32:14.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/18/Hexo主题-Icarus主题/","link":"","permalink":"http://www.octber.xyz/2019/05/18/Hexo%E4%B8%BB%E9%A2%98-Icarus%E4%B8%BB%E9%A2%98/","excerpt":"特别鸣谢作者：Aokilin来源：CSDN原文：https://blog.csdn.net/marvine/article/details/89816846 Hexo主题说起主题，这里首先看官方的主题商店https://hexo.io/themes/","text":"特别鸣谢作者：Aokilin来源：CSDN原文：https://blog.csdn.net/marvine/article/details/89816846 Hexo主题说起主题，这里首先看官方的主题商店https://hexo.io/themes/ 不得不说，使用最广泛的主题并不是博主我用的主题，而是nexT： 官方地址 他的一个功能我非常喜欢，那就是左边显示文章的目录，并且点击可以跳转过去。 主题大气，耐看，确实是一个好的选择。 而我使用的是一个名为伊卡洛斯（Icarus）的主题：官方地址 我喜欢他的原因也很简单： 文章主图很美观 布局扁平化布局很好看 小工具比较多，很丰富 字体也很好看 配置文件如果你和我一眼选用的伊卡洛斯，那么你可以继续往下看，看看我的主题配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129...# 注意：language不知道为什么不起作用，需要改一些地方，请看**备注 1**language: ch...# 注意：此处的menu本来是英文，不要指望他会按照语言变成中文，手动写成中文即可，请看**备注 1**navbar: # Navigation bar menu links menu: 主页: / 归档: /archives 分类: /categories 标签: /tags 关于: /about # Navigation bar links to be shown on the right links: My Github: icon: fab fa-github url: &#x27;https://github.com/OctoberTian&#x27;...# 注意：如果你想让你的文章在new的时候有自动生成thumbnail等，可以在此设置。请看**备注 2**article: # Code highlight theme # https://github.com/highlightjs/highlight.js/tree/master/src/styles highlight: atom-one-light # Whether to show article thumbnail images thumbnail: true # Whether to show estimate article reading time readtime: true...# 注意：这是开启评论功能，这一部分我会单独一篇博客讲Hexo中的插件和小功能，请持续关注comment: # Name of the comment plugin type: valine app_id: *** app_key: *** notify: false verify: false placeholder: 看了这么久不评价一下吗？ guest_info: nick,mail,link pagesize: 10 shortname: 不能为空...# 注意：这是打赏功能，images文件夹是主题文件夹source下的imagesdonate: - # Donation entry name type: alipay # Qrcode image URL qrcode: &#x27;/images/wechat.png&#x27; - # Donation entry name type: wechat # Qrcode image URL qrcode: &#x27;/images/wechat.png&#x27; -...# 注意：这里是侧边栏的设置，sticky表示在你滑动文章时，左右侧边栏是否一起滑动sidebar: # left sidebar settings left: # Whether the left sidebar is sticky when page scrolls sticky: false # right sidebar settings right: # Whether the right sidebar is sticky when page scrolls sticky: false...# 注意：两遍的小组件，由于三列显示会把文章列搞得太小，于是我把所有的部件都移动到了右边，会美观一点。widgets: - # Widget name type: profile # Where should the widget be placed, left or right position: right # Author name to be shown in the profile widget author: October 十 月 # Title of the author to be shown in the profile widget author_title: Coding Man # Author&#x27;s current location to be shown in the profile widget location: China # Path or URL to the avatar to be shown in the profile widget avatar: &#x27;http://file.octber.xyz/avatar.png&#x27; # Email address for the Gravatar to be shown in the profile widget gravatar: &#x27;https://github.com/OctoberTian&#x27; # Whether to show avatar image rounded or square avatar_rounded: true # Path or URL for the follow button follow_link: &#x27;https://github.com/OctoberTian&#x27; # Links to be shown on the bottom of the profile widget social_links: Github: icon: fab fa-github name: &#x27;Github&#x27; url: &#x27;https://github.com/OctoberTian&#x27; Coding: icon: fab fa-github name: &#x27;Coding&#x27; url: &#x27;https://dev.tencent.com/u/OctCoding&#x27; - # Widget name type: toc # Where should the widget be placed, left or right position: right - # Widget name type: category # Where should the widget be placed, left or right position: right - # Widget name type: tagcloud # Where should the widget be placed, left or right position: right - # Widget name type: recent_posts # Where should the widget be placed, left or right position: right - # Widget name type: archive # Where should the widget be placed, left or right position: right - # Widget name type: tag # Where should the widget be placed, left or right position: right 其他配置暂时设为默认，有兴趣可以自己调试一下。 备注 1: 关于语言的问题语言的坑我踩了很久，首先找到language文件夹，就在主题文件的根目录，我们可以看到，中文的对应yml是zh_Ch,英文是en，但是我在配置文件里修改了language为’zh_Ch’却怎么都不起作用，最后我发现这么一处代码： 打开layout下的layout.ejs: 1&lt;html &lt;%- has_config(&#x27;language&#x27;) ? &#x27; lang=&quot;&#x27; + get_config(&#x27;language&#x27;).substring(0, 2) + &#x27;&quot;&#x27; : &#x27;&#x27; %&gt;&gt; 可以看到，他从配置文件中取出对应language的配置，但是却subString(0, 2)，那么取出zh_Ch就会变成zh，于是我把language文件下的zh_Ch.yml文件名改成了ch.yml。 打开common/scripts.ejs看到 1&lt;script&gt;moment.locale(&quot;&lt;%= get_config(&#x27;language&#x27;, &#x27;en&#x27;) %&gt;&quot;);&lt;/script&gt; 我把en改成ch 但是发现仍然不能变为中文，于是我直接把配置文件中Menu的内容手动改成中文，大功告成。 备注 2： article如何为我们的每篇文章添加主图呢？这个问题一直查不到，困扰了很久，其实就是配置thumbnail为true，我们只需要在文章的配置里，添加thumbnail还有图片目录，就可以生成文章主图，效果就是： 这样就非常的美观，但是你可能会遇到一个问题，图片无法加载，这确实是一个问题，路径如何选择，这个主题在生成静态文件的时候，按照时间/year/month/day/name/picture来找，所以我们需要手动加上前缀时间前缀，比如我这篇文章： 你可能还有一个问题，那就是每次都来写title，date，tags这些标签，非常的费劲，关于如何快速的写一篇博文我会单独作为一个博文来讲，请持续关注。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"}]},{"title":"鸟哥的Linux私房菜(零)计算器概论","slug":"鸟哥的Linux私房菜-零-计算器概论","date":"2019-05-17T12:13:58.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/17/鸟哥的Linux私房菜-零-计算器概论/","link":"","permalink":"http://www.octber.xyz/2019/05/17/%E9%B8%9F%E5%93%A5%E7%9A%84Linux%E7%A7%81%E6%88%BF%E8%8F%9C-%E9%9B%B6-%E8%AE%A1%E7%AE%97%E5%99%A8%E6%A6%82%E8%AE%BA/","excerpt":"0.1 计算机：辅助人脑的好工具0.1.1 计算机硬件的五大单元 首先我们需要知道什么叫计算器 ： 接受用户输入指令与数据，经由中央处理器的数学与逻辑单元运算处理后， 以产生或储存成有用的信息。 计算机硬件的5大单元 计算机是由几个单元所组成的，包括输入单元、 输出单元、CPU 内部的控制单元、算数逻辑单元与主存储器五大部分。","text":"0.1 计算机：辅助人脑的好工具0.1.1 计算机硬件的五大单元 首先我们需要知道什么叫计算器 ： 接受用户输入指令与数据，经由中央处理器的数学与逻辑单元运算处理后， 以产生或储存成有用的信息。 计算机硬件的5大单元 计算机是由几个单元所组成的，包括输入单元、 输出单元、CPU 内部的控制单元、算数逻辑单元与主存储器五大部分。 整部主机的重点在于中央处理器 (Central Processing Unit, CPU)，CPU 为一个具有特定功能的芯片，里头含有微指令集，如果你想要让主机进行什么特异的功能，就得要参考这颗 CPU 是否有相关内建的微指令集才可以。 由于 CPU 的工作主要在于管理与运算，因此在 CPU 内又可分为两个主要的单元，分别是： 算数逻辑单元与控制单元。 其中算数逻辑单元主要负责程序运算与逻辑判断，控制单元则主要在协调各周边组件与各单元间的工作。 CPU读取的数据都是从主储存器中来的 看下图的计算机五大单元结构图，就非常好理解： 输入单元也就是我们常见的外部设备，比如鼠标键盘等等，输入的信号都会进入主储存区，而我们硬件中的数据要想进入CPU运算，也要先进入主储存区，可见这一部分是多么的重要。 0.1.2 CPU架构 前面说过CPU会包含一些微指令集，所以按照微指令是否复杂分为了两种CPU架构： 精简指令集 RISC 微指令集较为精简，每个指令的运行时间都很短，完成的动作也很单纯，指令的执行效能较佳； 但是若要做复杂的事情，就要由多个指令来完成。常见的 RISC 微指令集 CPU 主要例如甲骨文 (Oracle) 公司的 SPARC 系列、 IBM 公司的 Power Architecture (包括 PowerPC) 系列、与安谋公司 (ARM Holdings) 的 ARM CPU 系列等。，目前世界上使用范围最广的 CPU 可能就是 ARM 这种架构的呢 复杂指令集 CISC 与 RISC 不同的，CISC 在微指令集的每个小指令可以执行一些较低阶的硬件操作，指令数目多而且复杂， 每条指令的长度并不相同。因为指令执行较为复杂所以每条指令花费的时间较长， 但每条个别指令可以处理的工作较为丰富。常见的 CISC 微指令集 CPU 主要有 AMD、Intel、VIA 等的 x86 架构的 CPU。由于 AMD、Intel、VIA 所开发出来的 x86 架构 CPU 被大量使用于个人计算机(Personal computer)用途上面， 因此，个人计算机常被称为 x86 架构的计算机！那为何称为 x86 架构(注 8)呢？ 这是因为最早的那颗 Intel 发展出来的 CPU 代号称为 8086，后来依此架构又开发出 80286, 80386…， 因此这种架构的 CPU 就被称为 x86 架构了。在 2003 年以前由 Intel 所开发的 x86 架构 CPU 由 8 位升级到 16、32 位，后来 AMD 依此架构修改新一代的 CPU 为 64 位， 为了区别两者的差异，因此 64 位的个人计算机 CPU 又被统称为 x86_64 的架构喔！一般 32 位的 CPU 所能读写的最大数据量，大概就是 4GB 左右。 0.1.3 其他单元的设备 系统单元：系统单元包括 CPU 与内存及主板相关组件。而主板上头其实还有很多的连接界面与相关的适配卡，包括鸟哥近期常使用的 PCI-E 10G 网络卡、 磁盘阵列卡、还有显示适配器等等。尤其是显示适配器，这东西对于玩 3D 游戏来说是非常重要的一环，他与显示的精致度、色彩与分辨率都有关系。 记忆单元：包括主存储器 (main memory, RAM) 与辅助内存，其中辅助内存其实就是大家常听到的『储存装置』啰！包括硬盘、软盘、光盘、磁带等等的。 输入、输出单元：同时涵盖输入输出的设备最常见的大概就是触摸屏了。至于单纯的输入设备包括前面提到的键盘鼠标之外，目前的体感装置也是重要的输入设备喔！ 至于输出设备方面，除了屏幕外，打印机、音效喇叭、HDMI 电视、投影机、蓝芽耳机等等，都算喔！ 0.1.4 运作流程我们形象的按照人的机制来比喻一下： CPU=脑袋瓜子：每个人会作的事情都不一样(微指令集的差异)，但主要都是透过脑袋瓜子来进行判断与控制身体各部分的活动； 主存储器=脑袋中放置正在被思考的数据的区块：在实际活动过程中，我们的脑袋瓜子需要有外界刺激的数据 (例如光线、环境、语言等) 来分析，那这些互动数据暂时存放的地方就是主存储器，主要是用来提供给脑袋瓜子判断用的信息。 硬盘=脑袋中放置回忆的记忆区块：跟刚刚的主存储器不同，主存储器是提供脑袋目前要思考与处理的信息，但是有些生活琐事或其他没有要立刻处理的事情， 就当成回忆先放置到脑袋的记忆深处吧！那就是硬盘！主要目的是将重要的数据记录起来，以便未来将这些重要的经验再次的使用； 主板=神经系统：好像人类的神经一样，将所有重要的组件连接起来，包括手脚的活动都是脑袋瓜子发布命令后， 透过神经(主板)传导给手脚来进行活动啊！ 各项接口设备=人体与外界沟通的手、脚、皮肤、眼睛等：就好像手脚一般，是人体与外界互动的重要关键！ 显示适配器=脑袋中的影像：将来自眼睛的刺激转成影像后在脑袋中呈现，所以显示适配器所产生的数据源也是 CPU 控制的。 电源供应器 (Power)=心脏：所有的组件要能运作得要有足够的电力供给才行！这电力供给就好像心脏一样。如果心脏不够力， 那么全身也就无法动弹的！心脏不稳定呢？那你的身体当然可能断断续续的～不稳定！ 0.1.5 计算机用途的分类 超级计算机(Supercomputer)超级计算机是运作速度最快的计算机，但是他的维护、操作费用也最高！主要是用于需要有高速计算的计划中。 例如：国防军事、气象预测、太空科技，用在模拟的领域较多。详情也可以参考： 国家高速网络与计算中心 http://www.nchc.org.tw 的介绍！ 至于全世界最快速的前 500 大超级计算机，则请参考：http://www.top500.org。 大型计算机(Mainframe Computer)大型计算机通常也具有数个高速的 CPU，功能上虽不及超级计算机，但也可用来处理大量资料与复杂的运算。 例如大型企业的主机、全国性的证券交易所等每天需要处理数百万笔数据的企业机构， 或者是大型企业的数据库服务器等等。 迷你计算机(Minicomputer)迷你计算机仍保有大型计算机同时支持多用户的特性，但是主机可以放在一般作业场所， 不必像前两个大型计算机需要特殊的空调场所。通常用来作为科学研究、工程分析与工厂的流程管理等。 工作站(Workstation)工作站的价格又比迷你计算机便宜许多，是针对特殊用途而设计的计算机。在个人计算机的效能还没有提升到目前的状况之前， 工作站计算机的性能/价格比是所有计算机当中较佳的，因此在学术研究与工程分析方面相当常见。 微电脑(Microcomputer)个人计算机就属于这部份的计算机分类，也是我们本章主要探讨的目标！体积最小，价格最低，但功能还是五脏俱全的！ 大致又可分为桌上型、笔记型等等。 0.1.6 计算机上面常用的计算单位 ( 容量、速度等) 容量单位 1 Byte = 8 bit 1 k = 1024 Byte 1 M = 1024 K 速度单位 Hz 其实就是秒分之一，CPU 的指令周期常使用 MHz 或者是 GHz 之类的单位，网络使用的是 bit 为单位，因此网络常使用的单位为 Mbps 是 Mbits per second，亦即是每秒多少 Mbit Tips： 0.2 个人计算机架构与相关设备组件0.2.1 执行脑袋运算与判断的 CPU什么是频率呢？ 简单的说， 频率就是 CPU 每秒钟可以进行的工作次数。 所以频率越高表示这颗 CPU 单位时间内可以作更多的事情。举例来说，Intel 的 i7-4790 CPU 频率为 3.6GHz， 表示这颗 CPU 在一秒内可以进行 3.6x10 9 次工作，每次工作都可以进行少数的指令运作之意。 什么是外频？什么是倍频？ 所谓的外频指的是 CPU 与外部组件进行数据传输时的速度，倍频则是 CPU 内部用来加速工作效能的一个倍数， 两者相乘才是 CPU 的频率速度 什么是字组大小（Word Size） CPU 每次能够处理的数据量称为字组大小(word size)， 字组大小依据 CPU 的设计而有 32 位与 64 位。我们现在所称的计算机是 32 或 64 位主要是依据这个 CPU 解析的字组大小而来的！早期的 32 位 CPU 中，因为 CPU 每次能够解析的数据量有限， 因此由主存储器传来的数据量就有所限制了。这也导致 32 位的 CPU 最多只能支持最大到 4GBytes 的内存。 什么是超线程（Hyper-Threading, HT） 在每一个 CPU内部将重要的缓存器 (register) 分成两群， 而让程序分别使用这两群缓存器。也就是说，可以有两个程序『同时竞争 CPU 的运算单元』，而非透过操作系统的多任务切换！ 这一过程就会让 CPU 好像『同时有两个核心』的模样！因此，虽然大部分 i7 等级的 CPU 其实只有四个实体核心，但透过HT 的机制， 则操作系统可以抓到八个核心！并且让每个核心逻辑上分离，就可以同时运作八个程序了。 0.2.2 内存主储存器的作用？ CPU 所使用的数据都是来自于主存储器(main memory)，不论是软件程序还是数据，都必须要读入主存储器后 CPU 才能利用。 个人计算机的主存储器主要组件为动态随机存取内存(DynamicRandom Access Memory, DRAM)， 随机存取内存只有在通电时才能记录与使用，断电后数据就消失了。因此我们也称这种 RAM 为挥发性内存。 所以主储存器的容量是非常重要的，以服务器来说，主存储器的容量有时比 CPU 的速度还要来的重要的。 什么是第二层快取？ CPU 内的第二层高速缓存。 我们现在知道 CPU 的数据都是由主存储器提供，但 CPU 到主存储器之间还是得要透过内存控制器啊！ 如果某些很常用的程序或数据可以放置到 CPU 内部的话，那么 CPU数据的读取就不需要跑到主存储器重新读取了！ 这对于效能来说不就可以大大的提升了？这就是第二层快取的设计概念。第二层快取与主存储器及 CPU 的关系如下图所示： 简而言之，CPU的储存是非常珍贵的，我们不能把应用数据常驻在CPU中，但是每次透过控制器取数据到CPU中就会出现时间全耗费在这个过程，相比CPU的速度，这个过程更为耗时，我们使用第二层快取的设计，设计二层高速缓存区，就可以平衡这种速度不匹配的问题。 那为什么不全部做成高速缓存呢？ 因为第二层快取(L2 cache)整合到 CPU 内部，因此这个 L2 内存的速度必须要 CPU 频率相同。 使用DRAM 是无法达到这个频率速度的，此时就需要静态随机存取内存(Static Random Access Memory,SRAM)的帮忙了。 SRAM 在设计上使用的晶体管数量较多，价格较高，且不易做成大容量，不过由于其速度快， 因此整合到 CPU 内成为高速缓存以加快数据的存取是个不错的方式喔！新一代的 CPU都有内建容量不等的 L2 快取在 CPU 内部， 以加快 CPU 的运作效能。 其实原因还是因为贵，如果对于对速度要求非常高的应用，全部使用高速缓存实现，通过提高成本的方式，还是值得的。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.octber.xyz/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.octber.xyz/tags/Linux/"}]},{"title":"Hexo常用命令","slug":"Hexo常用命令","date":"2019-05-17T01:03:16.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/17/Hexo常用命令/","link":"","permalink":"http://www.octber.xyz/2019/05/17/Hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"前言学习一个东西，一门语言也好，一个框架也好，最好的方式就是查看官方文档与自己阅读源代码，其次是查阅优秀博文，再次是查阅相关学习课程与视频，独立学习能力是一个程序员适应时代发展最重要的能力。 本节，我结合实际使用，和官方文档，来讲一下Hexo的常用指令。","text":"前言学习一个东西，一门语言也好，一个框架也好，最好的方式就是查看官方文档与自己阅读源代码，其次是查阅优秀博文，再次是查阅相关学习课程与视频，独立学习能力是一个程序员适应时代发展最重要的能力。 本节，我结合实际使用，和官方文档，来讲一下Hexo的常用指令。 文档本体官方文档地址： https://hexo.io/zh-cn/docs/ init1$ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new1$ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1$ hexo new &quot;post title with whitespace&quot; 这是我的配置文件中关于写博客的一些配置 123456789101112131415# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: truerelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: 我规定在生成新博客的时候采用标题加md的方式作为文件名，默认的layout为post，也就是在_post文件夹内创建我的markdown文件，Layout就是布局的意思，每个文件使用默认的布局又是什么意思呢？ 打开Hexo根目录下的themes文件，你就会看到你所有的主题，打开你现在正在使用的主题，比如我的主题是伊卡洛斯（icarus），里面有一个名为Layout的文件夹，顾名思义，这就是布局文件了，打开下面的layout.ejs文件，我们可以看到它由这几个部分组成： 123&lt;head&gt; &lt;%- partial(&#x27;common/head&#x27;) %&gt;&lt;/head&gt; 头部，引入了common的head文件 1&lt;%- partial(&#x27;common/navbar&#x27;, &#123; page &#125;) %&gt; navbar也就是导航栏部分 12&lt;%- partial(&#x27;common/widget&#x27;, &#123; position: &#x27;left&#x27; &#125;) %&gt;&lt;%- partial(&#x27;common/widget&#x27;, &#123; position: &#x27;right&#x27; &#125;) %&gt; 中间部分，分为左边和右边 1&lt;%- partial(&#x27;common/footer&#x27;) %&gt; 页面尾部，他们都在common目录下 这些部分共同组成一个html文件，也就是说我们通过不同时间向Layout注入不同的内容来实现页面的跳转，这种单页面实现所有功能的结构并不少见，比如Vue也相类似。 每个Hexo站点基本上分为index（首页）、post（文章详情页）、page（导航标签页）、archive（归档页）、category（类别页）以及tag（标签页），没错就是Layout文件夹下的几个文件。它们每个都代表一种布局，将它们用来替换掉layout.ejs文件里的&lt;%- body %&gt;就得到了各个布局的页面代码。 index首页布局最后来看看index.ejs，它是首页布局，跟其他的布局还是不一样的。代码如下： 123456&lt;% page.posts.each(function(post)&#123; %&gt; &lt;%- partial(&#x27;common/article&#x27;, &#123; post, index: true &#125;) %&gt;&lt;% &#125;); %&gt;&lt;% if (page.total &gt; 1) &#123; %&gt; &lt;%- partial(&#x27;common/paginator&#x27;) %&gt;&lt;% &#125; %&gt; 这一块什么意思？首先是一个循环语句，因为首页要显示出近期发布的几篇文章，引入局部模块的时候使用了Local Variables（本地变量）的相关内容，这里是将post页面变量赋值给了本地变量item，换句话说，在_partial/article.ejs这个文件中所有的item变量都指的是post页面变量，里面使用了很多页面变量的一些键值，参考这里页面变量看article.ejs的代码就容易多了。 布局（Layout）Hexo 有三种默认布局：post、page 和 draft，它们分别对应不同的路径，而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。 默认为post布局，page是页面，draft是草稿。 generate1$ hexo generate 生成静态文件。我们常常简写为hexo g，因为Coding/Github Pagas帮我们部署的正是静态文件，所以我们在每一次发布的时候都需要生成静态文件。 选项 描述 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为 1$ hexo g 我们可以通过hexo g -d在生成后制动部署，部署也就是按照配置文件中的deploy自动推到Coding/Github或者你的服务器上，推上去的便是你生成的静态文件。 publish1$ hexo publish [layout] &lt;filename&gt; 发表草稿。 server1$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。可以本地预览你的博客。 在你需要调整很多内容的时候你就可以通过这种方式快速看到你代码更改后的效果。 选项 描述 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 deploy1$ hexo deploy 部署网站。 参数 描述 -g, --generate 部署之前预先生成静态文件 该命令可以简写为： 1$ hexo d 和之前的用法相似，我们使用hexo d -g也是可以的 render1$ hexo render &lt;file1&gt; [file2] ... 渲染文件。将我们的文章渲染成单个html文件。 最终打开hexo.html是这样的 效果并不是很好，没有很多css的包装，只是阅读还是可以的。 参数 描述 -o, --output 设置输出路径 migrate1$ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。不赘述，这个命令往往在我们需要迁移内容的时候再考虑学习。 clean1$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 毒比较大的时候，建议clean一下 list1$ hexo list &lt;type&gt; 列出网站资料。这个就很有意思了，可以选用的type有page, post, route, tag, category version1$ hexo version 显示 Hexo 版本。 选项安全模式1$ hexo --safe 在安全模式下，不会载入插件和脚本。当您在安装新插件遭遇问题时，可以尝试以安全模式重新执行。 调试模式1$ hexo --debug 在终端中显示调试信息并记录到 debug.log。当您碰到问题时，可以尝试用调试模式重新执行一次，并 提交调试信息到 GitHub。 简洁模式1$ hexo --silent 隐藏终端信息。 自定义配置文件的路径1$ hexo --config custom.yml 自定义配置文件的路径，执行后将不再使用 _config.yml。这一点非常重要，但是要记住一旦执行，你就会发现原来的配置文件不能生效，如果你忘记了这件事，那么你可能始终想不通为什么自己的hexo坏了，只好重装。 显示草稿1$ hexo --draft 显示 source/_drafts 文件夹中的草稿文章。 自定义 CWD1$ hexo --cwd &#x2F;path&#x2F;to&#x2F;cwd 自定义当前工作目录（Current working directory）的路径。 本次博文就先到这里，部分内容摘自官方文档。","categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://www.octber.xyz/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"}]},{"title":"Hexo+Github或Hexo+Coding 配置与部署","slug":"Hexo-Github或Hexo-Coding-配置与部署","date":"2019-05-16T16:22:03.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/17/Hexo-Github或Hexo-Coding-配置与部署/","link":"","permalink":"http://www.octber.xyz/2019/05/17/Hexo-Github%E6%88%96Hexo-Coding-%E9%85%8D%E7%BD%AE%E4%B8%8E%E9%83%A8%E7%BD%B2/","excerpt":"HexoHexo是一个快速、简洁而且高效的博客框架，他的优点也正是官网（https://hexo.io/zh-cn/）所说的： hexo 可以理解为是基于node.js制作的一个博客工具，不是我们理解的一个开源的博客系统。其中的差别，有点意思。 hexo 正常来说，不需要部署到我们的服务器上，我们的服务器上保存的，其实是基于在hexo通过markdown编写的文章，然后hexo帮我们生成静态的html页面，然后，将生成的html上传到我们的服务器。简而言之：hexo是个静态页面生成、上传的工具。 hexo 需要数据库吗？答案是不需要 hexo 一定需要服务器部署吗？答案是我们可以选择Github Pages等工具实现，如果你有高性能的服务器，那一定更好。","text":"HexoHexo是一个快速、简洁而且高效的博客框架，他的优点也正是官网（https://hexo.io/zh-cn/）所说的： hexo 可以理解为是基于node.js制作的一个博客工具，不是我们理解的一个开源的博客系统。其中的差别，有点意思。 hexo 正常来说，不需要部署到我们的服务器上，我们的服务器上保存的，其实是基于在hexo通过markdown编写的文章，然后hexo帮我们生成静态的html页面，然后，将生成的html上传到我们的服务器。简而言之：hexo是个静态页面生成、上传的工具。 hexo 需要数据库吗？答案是不需要 hexo 一定需要服务器部署吗？答案是我们可以选择Github Pages等工具实现，如果你有高性能的服务器，那一定更好。 Hexo的源码结构 Hexo的安装安装前提 Node.js (Should be at least nodejs 6.9) Git 安装命令npm install -g hexo-cli或者 cnpm install -g hexo-cli Hexo建站 创建你的博客文件夹，如：Hexo 进入Hexo文件夹，执行以下命令 12hexo initcnpm install 或者 npm install 这一步完成后你会看到这样的结构目录 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes Hexo基本配置请看我的另一篇博文《Hexo配置文件详解》 Github配置首先创建一个项目 建议生成默认的README文件 随后Create即可，进入Settings页面 我们可以看到一个强大的功能：Github Pages Github Pages会自动部署我们的静态网页，我们可以通过http://youname.github.io来访问，当然如果你有已经备案过的域名，添加一个CNAME解析便可以使用自己的域名访问，注意我们可以使用一级域名，或者www和blog的二级域名，官方建议使用一级域名。 Coding配置与Github类似，需要注意的是，仓库名为你的coding名.coding.me,其他略。 Hexo配置deploy在项目根目录的_config.yml中配置deploy设置 123456deploy: type: git repo: github: git@github.com:OctoberTian/OctoberTian.github.io.git coding: git@git.dev.tencent.com:OctCoding/OctCoding.coding.me.git branch: master 通过这一层配置，我们可以通过hexo d（等价于hexo deploy）命令将我们修改的内容推送到github上和coding上，这里使用SSH，使用Https也可以，建议使用SSH公钥。 SSH公钥我们以Coding为例，如何在自己的电脑上部署SSH。（详情可查看官方文档：https://coding.net/help/doc/git/ssh-key.html） 进入个人设置，我们可以看到SSH公钥的功能 点击SSH公钥进入我们可以新增公钥： 这就要求我们电脑本地设置SSH公钥，并获取公钥内容 随机位置打开git bash12cd ~/.sshcat id_rsa.pub #查看共要内容 如果看到下图，表明你已经生成过公钥： 直接查看id_rsa.pub复制内容到coding即可完成配置 如果没有目录，我们来创建公钥： 12ssh-keygen -t rsa -C &quot;your global email&quot; cat ~/.ssh/id_rsa.pub 配置好这些，Hexo的安装就接近尾声了 Hexo部署详细的指令我会在之后的博文详细讲解，这里我们输入：hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 可以看到我们的文件被推送到github或者coding或者两者上，值得一提的是，一个域名只能映射一个网址，比如我的是blog.octber.xyz映射到octcoding.coding.me上，coding为我强制转换为HTTPS访问，但是由于只能映射一个，所以没有映射github，在每次部署的时候github都会提示我域名存在问题，所以我选择了部署coding，毕竟github服务器在国外，速度比coding更为缓慢。 最终效果可以通过访问 https://blog.octber.xyz得到博客","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"}]},{"title":"Hexo配置文件详解","slug":"Hexo配置文件详解","date":"2019-05-16T01:04:35.000Z","updated":"2020-03-09T14:50:12.000Z","comments":true,"path":"2019/05/16/Hexo配置文件详解/","link":"","permalink":"http://www.octber.xyz/2019/05/16/Hexo%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"Hexo的配置Hexo的配置还是很好做的，使用了yml的方式，简洁简单，下面我介绍一下根目录下的配置文件，关于主题的配置，请持续关注我的博客。","text":"Hexo的配置Hexo的配置还是很好做的，使用了yml的方式，简洁简单，下面我介绍一下根目录下的配置文件，关于主题的配置，请持续关注我的博客。 配置在Hexo根目录中有一个名为_config.xml的文件，便是我们的配置文件，在这里可以修改大部分的的配置。 网站1234567参数 描述title 网站标题subtitle 网站副标题description 网站描述author 您的名字language 网站使用的语言timezone 网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。 其中需要注意的是description比较重要，它主要用于 SEO，用来告诉搜索引擎关于站点的信息，在其中包含网站的关键词。 什么是SEO呢？（摘自百度百科）SEO（Search Engine Optimization）：汉译为搜索引擎优化。是一种方式：利用搜索引擎的规则提高网站在有关搜索引擎内的自然排名。目的是：为网站提供生态式的自我营销解决方案，让其在行业内占据领先地位，获得品牌收益；SEO包含站外SEO和站内SEO两方面；为了从搜索引擎中获得更多的免费流量，从网站结构、内容建设方案、用户互动传播、页面等角度进行合理规划，还会使搜索引擎中显示的网站相关信息对用户来说更具有吸引力。 网址12345参数 描述 默认值url 网址 root 网站根目录 permalink 文章的永久链接格式 :year/:month/:day/:title/permalink_defaults 永久链接中各部分的默认值 目录12345678source_dir: source 资源文件，用来存放内容，映射到根目录下的source，在其中的_posts存放*.md文件即可完成博客发布 public_dir: public 公共文件夹，生成的站点文件存放在这个地方tag_dir: tags 标签文件夹archive_dir: archives 归档文件架category_dir: categories 分类文件夹code_dir: downloads/code include code文件夹i18n_dir: :lang 国际化i18n文件夹skip_render: 跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 什么是i18n呢？（源自于百度百科）i18n（其来源是英文单词 internationalization的首末字符i和n，18为中间的字符数）是“国际化”的简称。在资讯领域，国际化(i18n)指让产品（出版物，软件，硬件等）无需做大的改变就能够适应不同的语言和地区的需要。对程序来说，在不修改内部代码的情况下，能根据不同语言及地区显示相应的界面。 在全球化的时代，国际化尤为重要，因为产品的潜在用户可能来自世界的各个角落。通常与i18n相关的还有L10n（“本地化”的简称）。 什么是glob表达式呢？请查看microkof的一篇博文，我认为写的很好，地址是：https://www.jianshu.com/p/91eb8d81da64 文章123456789101112参数 描述 new_post_name 新文章的文件名称 default_layout 预设布局 auto_spacing 在中文和英文之间加入空格 titlecase 把标题转换为 title case external_link 在新标签中打开链接 filename_case 把文件名称转换为 (1) 小写或 (2) 大写 render_drafts 显示草稿 post_asset_folder 启动 Asset 文件夹 relative_link 把链接改为与根目录的相对位址 future 显示未来的文章 highlight 代码块的设置 他们的默认值： 123456789101112131415# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: title case 是什么？请看title case的github进行了解：https://github.com/rvagg/titlecase post_asset_folder 是什么？asset是md文件链接图片时存放图片的默认文件夹，由此可知，开启这个选项，我们的博文中可以方便的插入图片，当然还需要一些配置： 第二步：在hexo目录下执行这样一句话npm install hexo-asset-image --save，这是下载安装一个可以上传本地图片的插件，等待一小段时间后，再运行hexo n &quot;xxxx&quot;来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 （当然也可以自己手动建） 第三步：最后在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片：![你想输入的替代文字](xxxx/图片名.jpg) 注意： xxxx是这个md文件的名字，也是同名文件夹的名字。只需要有文件夹名字即可，不需要绝对路径。你想引入的图片就只需要放入xxxx这个文件夹内就好了，很像引用相对路径。 第四步：最后检查一下，hexo g生成页面后，进入public\\2017\\02\\26\\index.html文件中查看相关字段，可以发现，html标签内的语句是&lt;img src=&quot;2017/02/26/xxxx/图片名.jpg&quot;&gt;，而不是&lt;img src=”xxxx/图片名.jpg&gt;。这很重要，关乎你的网页是否可以真正加载你想插入的图片。 分类&amp;标签1234参数 描述 默认值default_category 默认分类 uncategorizedcategory_map 分类别名 tag_map 标签别名 时间日期格式123参数 描述 默认值date_format 日期格式 YYYY-MM-DDtime_format 时间格式 H:mm:ss 分页123参数 描述 默认值per_page 每页显示的文章量 (0 = 关闭分页功能) 10pagination_dir 分页目录 page 拓展123参数 描述theme 当前主题名称。值为false时禁用主题deploy 部署部分的设置 其中deploy部署部分，我们可以选择部署到github也可以选择部署到coding，我选择两个都进行部署，操作步骤请持续关注我的博客。 fork me on Github 目前还没有添加，代码如下123&lt;a href=&quot;https://github.com/OctoberTian&quot;&gt;&lt;img width=&quot;149&quot; height=&quot;149&quot; src=&quot;https://github.blog/wp-content/uploads/2008/12/forkme_right_orange_ff7600.png?resize=149%2C149&quot; class=&quot;attachment-full size-full&quot; alt=&quot;Fork me on GitHub&quot; data-recalc-dims=&quot;1&quot;&gt;&lt;/a&gt; 鸣谢参考一下优秀博文： 作者：saucer-man来源：CSDN原文：https://blog.csdn.net/gyq1998/article/details/78294689","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"}]}],"categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/categories/JVM/"},{"name":"/java","slug":"java","permalink":"http://www.octber.xyz/categories/java/"},{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/categories/Java/"},{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/categories/%E6%97%A5%E8%AE%B0/"},{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/categories/%E7%BC%93%E5%AD%98/"},{"name":"消息队列","slug":"消息队列","permalink":"http://www.octber.xyz/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Redis","slug":"Redis","permalink":"http://www.octber.xyz/categories/Redis/"},{"name":"臭臭专栏","slug":"臭臭专栏","permalink":"http://www.octber.xyz/categories/%E8%87%AD%E8%87%AD%E4%B8%93%E6%A0%8F/"},{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/categories/%E7%BA%BF%E7%A8%8B/"},{"name":"数据库","slug":"数据库","permalink":"http://www.octber.xyz/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"游戏专栏","slug":"游戏专栏","permalink":"http://www.octber.xyz/categories/%E6%B8%B8%E6%88%8F%E4%B8%93%E6%A0%8F/"},{"name":"动漫专栏","slug":"动漫专栏","permalink":"http://www.octber.xyz/categories/%E5%8A%A8%E6%BC%AB%E4%B8%93%E6%A0%8F/"},{"name":"Android","slug":"Android","permalink":"http://www.octber.xyz/categories/Android/"},{"name":"小工具","slug":"小工具","permalink":"http://www.octber.xyz/categories/%E5%B0%8F%E5%B7%A5%E5%85%B7/"},{"name":"Go","slug":"Go","permalink":"http://www.octber.xyz/categories/Go/"},{"name":"Vue专题","slug":"Vue专题","permalink":"http://www.octber.xyz/categories/Vue%E4%B8%93%E9%A2%98/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.octber.xyz/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"Springboot","slug":"Springboot","permalink":"http://www.octber.xyz/categories/Springboot/"},{"name":"Springbooot","slug":"Springbooot","permalink":"http://www.octber.xyz/categories/Springbooot/"},{"name":"English","slug":"English","permalink":"http://www.octber.xyz/categories/English/"},{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/categories/FamilyManage/"},{"name":"软件项目管理","slug":"软件项目管理","permalink":"http://www.octber.xyz/categories/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"软件测试","slug":"软件测试","permalink":"http://www.octber.xyz/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"},{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/categories/Hexo/"},{"name":"环境搭建","slug":"环境搭建","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"环境部署","slug":"环境部署","permalink":"http://www.octber.xyz/categories/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"},{"name":"工具集","slug":"工具集","permalink":"http://www.octber.xyz/categories/%E5%B7%A5%E5%85%B7%E9%9B%86/"},{"name":"Linux","slug":"Linux","permalink":"http://www.octber.xyz/categories/Linux/"},{"name":"技术文档","slug":"技术文档","permalink":"http://www.octber.xyz/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.octber.xyz/tags/JVM/"},{"name":"dl4j","slug":"dl4j","permalink":"http://www.octber.xyz/tags/dl4j/"},{"name":"dl4f","slug":"dl4f","permalink":"http://www.octber.xyz/tags/dl4f/"},{"name":"日报","slug":"日报","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E6%8A%A5/"},{"name":"Redis","slug":"Redis","permalink":"http://www.octber.xyz/tags/Redis/"},{"name":"缓存","slug":"缓存","permalink":"http://www.octber.xyz/tags/%E7%BC%93%E5%AD%98/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.octber.xyz/tags/RabbitMQ/"},{"name":"线程","slug":"线程","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"内存模型","slug":"内存模型","permalink":"http://www.octber.xyz/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"Lambda","slug":"Lambda","permalink":"http://www.octber.xyz/tags/Lambda/"},{"name":"集合框架","slug":"集合框架","permalink":"http://www.octber.xyz/tags/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"},{"name":"饭饭","slug":"饭饭","permalink":"http://www.octber.xyz/tags/%E9%A5%AD%E9%A5%AD/"},{"name":"JUC","slug":"JUC","permalink":"http://www.octber.xyz/tags/JUC/"},{"name":"Java集合框架","slug":"Java集合框架","permalink":"http://www.octber.xyz/tags/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.octber.xyz/tags/MySQL/"},{"name":"线程池","slug":"线程池","permalink":"http://www.octber.xyz/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"崩坏3","slug":"崩坏3","permalink":"http://www.octber.xyz/tags/%E5%B4%A9%E5%9D%8F3/"},{"name":"动漫杂图","slug":"动漫杂图","permalink":"http://www.octber.xyz/tags/%E5%8A%A8%E6%BC%AB%E6%9D%82%E5%9B%BE/"},{"name":"Java","slug":"Java","permalink":"http://www.octber.xyz/tags/Java/"},{"name":"比赛","slug":"比赛","permalink":"http://www.octber.xyz/tags/%E6%AF%94%E8%B5%9B/"},{"name":"收藏","slug":"收藏","permalink":"http://www.octber.xyz/tags/%E6%94%B6%E8%97%8F/"},{"name":"Go","slug":"Go","permalink":"http://www.octber.xyz/tags/Go/"},{"name":"Vue","slug":"Vue","permalink":"http://www.octber.xyz/tags/Vue/"},{"name":"互斥同步","slug":"互斥同步","permalink":"http://www.octber.xyz/tags/%E4%BA%92%E6%96%A5%E5%90%8C%E6%AD%A5/"},{"name":"Servlet","slug":"Servlet","permalink":"http://www.octber.xyz/tags/Servlet/"},{"name":"Shiro","slug":"Shiro","permalink":"http://www.octber.xyz/tags/Shiro/"},{"name":"六级考试","slug":"六级考试","permalink":"http://www.octber.xyz/tags/%E5%85%AD%E7%BA%A7%E8%80%83%E8%AF%95/"},{"name":"FamilyManage","slug":"FamilyManage","permalink":"http://www.octber.xyz/tags/FamilyManage/"},{"name":"软件项目管理","slug":"软件项目管理","permalink":"http://www.octber.xyz/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"软件测试","slug":"软件测试","permalink":"http://www.octber.xyz/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"},{"name":"日记","slug":"日记","permalink":"http://www.octber.xyz/tags/%E6%97%A5%E8%AE%B0/"},{"name":"JMeter","slug":"JMeter","permalink":"http://www.octber.xyz/tags/JMeter/"},{"name":"Hexo","slug":"Hexo","permalink":"http://www.octber.xyz/tags/Hexo/"},{"name":"Git","slug":"Git","permalink":"http://www.octber.xyz/tags/Git/"},{"name":"node.js","slug":"node-js","permalink":"http://www.octber.xyz/tags/node-js/"},{"name":"Utils","slug":"Utils","permalink":"http://www.octber.xyz/tags/Utils/"},{"name":"Linux","slug":"Linux","permalink":"http://www.octber.xyz/tags/Linux/"}]}